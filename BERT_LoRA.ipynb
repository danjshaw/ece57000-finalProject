{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danjshaw/ece57000-finalProject/blob/main/BERT_LoRA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Setup"
      ],
      "metadata": {
        "id": "RJc8lRi2sPF3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OOOR51p7nJQb",
        "outputId": "c78c2bb4-a3d0-4afc-deb6-afe19364acfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.10)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip freeze > requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from transformers import set_seed\n",
        "set_seed(0)"
      ],
      "metadata": {
        "id": "_rJOUWbHb7h7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiAkOY-564eO",
        "outputId": "315e0286-a326-47cb-e758-9fff6082df62"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Full Fine-Tuning\n",
        "\n"
      ],
      "metadata": {
        "id": "6pdjddZVsbQN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Followed examples from this [Hugging Face NLP course](https://huggingface.co/learn/nlp-course/chapter3/3?fw=pt#fine-tuning-a-model-with-the-trainer-api) on how to use the trainer API for fine-tuning."
      ],
      "metadata": {
        "id": "xM1jwv_maqfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "\n",
        "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
        "checkpoint = \"prajjwal1/bert-tiny\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
        "\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191,
          "referenced_widgets": [
            "c86e89190b77403ca47d4ed736385dff",
            "a7e5d72e0a734913908fa1fdbedcc58c",
            "9ed60b2736a845678021ab18b1d17f11",
            "a9dd3e77ed314a28a33d1703ee60e313",
            "3d71f077cbd247c9946fe422a983a433",
            "7a69c54ba2b1454fb7899562ef9f94d5",
            "a8b51a4d2b6e4ecbb94230b6891d9173",
            "08f1a3bea0814bd8bd55f62278704772",
            "12441be770a14fd5b44fb3a19fe4e04c",
            "c7370acd26a94a2282ed03d09419f895",
            "9f84891f80ce40c6aae4b5b033f2083b"
          ]
        },
        "id": "VDqSTwjJilGA",
        "outputId": "329a2094-e867-41ec-8c78-744338cec7fe",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c86e89190b77403ca47d4ed736385dff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    metric = evaluate.load(\"glue\", \"mrpc\")\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "Nogjf_bmjS1_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "ft_model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmkwN2WtjKGn",
        "outputId": "1381df5b-5410-4ea5-b5bd-5b0c0ce59913",
        "collapsed": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters from [google-research/bert](https://github.com/google-research/bert):\n",
        "\n",
        "\n",
        "\n",
        "> For each task, we selected the best fine-tuning hyperparameters from the lists below, and trained for 4 epochs:\n",
        "> * batch sizes: 8, 16, 32, 64, 128\n",
        "> * learning rates: 3e-4, 1e-4, 5e-5, 3e-5\n",
        "\n"
      ],
      "metadata": {
        "id": "aZnBuTehsapX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_runs = 3\n",
        "epochs = 4\n",
        "batch_sizes = [8, 16, 32, 64, 128]\n",
        "learning_rates = [3e-4, 1e-4, 5e-5, 3e-5]"
      ],
      "metadata": {
        "id": "62XZoxhusMhO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "ft_results = []\n",
        "iterations = len(batch_sizes)*len(learning_rates)*num_runs\n",
        "for run in range(1, num_runs+1):\n",
        "  progress = 0\n",
        "  for size in batch_sizes:\n",
        "    for rate in learning_rates:\n",
        "      progress += 1\n",
        "      print(f\"Progress: {progress}/{iterations}\")\n",
        "      ft_result = {\"run\":run, \"batch_size\": size, \"learning_rate\": rate}\n",
        "\n",
        "      training_args = TrainingArguments(\n",
        "          \"ft-trainer\",\n",
        "          eval_strategy=\"epoch\",\n",
        "          per_device_eval_batch_size=size,\n",
        "          per_device_train_batch_size=size,\n",
        "          num_train_epochs=epochs,\n",
        "          learning_rate=rate,\n",
        "          disable_tqdm=True,\n",
        "          report_to=\"none\"\n",
        "      )\n",
        "\n",
        "      trainer = Trainer(\n",
        "          ft_model,\n",
        "          training_args,\n",
        "          train_dataset=tokenized_datasets[\"train\"],\n",
        "          eval_dataset=tokenized_datasets[\"validation\"],\n",
        "          data_collator=data_collator,\n",
        "          processing_class=tokenizer,\n",
        "          compute_metrics=compute_metrics\n",
        "      )\n",
        "\n",
        "      ft_result = ft_result | trainer.train().metrics | trainer.evaluate()\n",
        "      ft_results.append(ft_result)\n",
        "\n",
        "ft_max = ft_results[0]\n",
        "for i, result in enumerate(ft_results):\n",
        "  if result['eval_f1'] > ft_max['eval_f1']:\n",
        "    ft_max = result\n",
        "\n",
        "print(f'\\n\\n================\\\n",
        "        \\nBest Result: \\\n",
        "        \\nbatch_size={ft_max[\"batch_size\"]}, \\\n",
        "        \\nlearning_rate={ft_max[\"learning_rate\"]}, \\\n",
        "        \\neval_f1={ft_max[\"eval_f1\"]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0rtaL56jMN3",
        "outputId": "949aa7ac-2f38-440a-fbc0-f0ce217a826b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 1/60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "with open('ft-results.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=list(ft_results[0].keys()))\n",
        "\n",
        "    writer.writeheader()\n",
        "    for result in ft_results:\n",
        "      writer.writerow(result)"
      ],
      "metadata": {
        "id": "Wch14C4-y74m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Low-Rank Adaptation (LoRA)"
      ],
      "metadata": {
        "id": "fn2hce2EzI11"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MivaCxsh7UKy"
      },
      "outputs": [],
      "source": [
        "class LoraModule(nn.Module):\n",
        "  def __init__(self, in_features, out_features, rank, alpha):\n",
        "    super().__init__()\n",
        "    self.scale = alpha / rank\n",
        "    self.A = nn.Parameter(torch.randn(in_features, rank))\n",
        "    self.B = nn.Parameter(torch.zeros(rank, out_features))\n",
        "\n",
        "  def forward(self, x):\n",
        "    return (self.scale * (x @ self.A @ self.B))\n",
        "\n",
        "class LoraLinear(nn.Module):\n",
        "  def __init__(self, linear, rank, alpha):\n",
        "    super().__init__()\n",
        "    if (isinstance(linear, LoraLinear)):\n",
        "      self.linear = linear.linear\n",
        "      self.lora = LoraModule(self.linear.in_features, self.linear.out_features, rank, alpha)\n",
        "\n",
        "    else:\n",
        "      self.linear = linear\n",
        "      self.lora = LoraModule(self.linear.in_features, self.linear.out_features, rank, alpha)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x) + self.lora(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnum5mxHf-MI"
      },
      "outputs": [],
      "source": [
        "def get_trainable_parameters(model):\n",
        "  trainable_parameters = 0\n",
        "  parameters = 0\n",
        "  for param in model.parameters():\n",
        "    parameters += param.numel()\n",
        "    if param.requires_grad:\n",
        "      trainable_parameters += param.numel()\n",
        "  return parameters, trainable_parameters"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def configure_lora_model(model, rank, alpha):\n",
        "  for i, layer in enumerate(model.bert.encoder.layer):\n",
        "    s = layer.attention.self\n",
        "    s.query = LoraLinear(s.query, rank, alpha)\n",
        "    s.value = LoraLinear(s.value, rank, alpha)\n",
        "\n",
        "  for name, param in model.named_parameters():\n",
        "    if 'A' in name or 'B' in name:\n",
        "      param.requires_grad = True\n",
        "    else:\n",
        "      param.requires_grad = False\n",
        "  params, trainable_params = get_trainable_parameters(model)\n",
        "  print(f\"Total Parameters={params}, Trainable Parameters={trainable_params}\")\n",
        "\n",
        "  return (params, trainable_params)"
      ],
      "metadata": {
        "id": "2dAR1xyMGGMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2).to(device)"
      ],
      "metadata": {
        "id": "HeNFNs4QzF7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use same hyperparameters as full fine-tuning section, but add ranks and alphas."
      ],
      "metadata": {
        "id": "WK2UT9eMZ0Bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_runs = 3\n",
        "epochs = 4\n",
        "ranks = [1, 2, 4, 8, 16]\n",
        "alphas = [1, 2, 4, 8, 16]\n",
        "batch_sizes = [8, 16, 32, 64, 128]\n",
        "learning_rates = [3e-4, 1e-4, 5e-5, 3e-5]"
      ],
      "metadata": {
        "id": "niceYTIvGnz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "results = []\n",
        "iterations = len(batch_sizes)*len(learning_rates)*len(ranks)*len(alphas)*num_runs\n",
        "progress = 0\n",
        "for run in range(1, num_runs+1):\n",
        "  for rank in ranks:\n",
        "    for alpha in alphas:\n",
        "      for size in batch_sizes:\n",
        "        for rate in learning_rates:\n",
        "          progress += 1\n",
        "          print(f\"Progress: {progress}/{iterations}\")\n",
        "          result = {\"run\": run, \"rank\": rank, \"alpha\": alpha, \"batch_size\": size, \"learning_rate\": rate}\n",
        "\n",
        "          params, trainable_params = configure_lora_model(model, rank, alpha)\n",
        "          result[\"parameters\"] = params\n",
        "          result[\"trainable_parameters\"] = trainable_params\n",
        "\n",
        "          training_args = TrainingArguments(\n",
        "              \"lora-trainer\",\n",
        "              eval_strategy=\"epoch\",\n",
        "              per_device_eval_batch_size=size,\n",
        "              per_device_train_batch_size=size,\n",
        "              num_train_epochs=epochs,\n",
        "              learning_rate=rate,\n",
        "              disable_tqdm=True,\n",
        "              report_to=\"none\"\n",
        "          )\n",
        "\n",
        "          trainer = Trainer(\n",
        "              model,\n",
        "              training_args,\n",
        "              train_dataset=tokenized_datasets[\"train\"],\n",
        "              eval_dataset=tokenized_datasets[\"validation\"],\n",
        "              data_collator=data_collator,\n",
        "              processing_class=tokenizer,\n",
        "              compute_metrics=compute_metrics\n",
        "          )\n",
        "\n",
        "          result = result | trainer.train().metrics | trainer.evaluate()\n",
        "          results.append(result)\n",
        "\n",
        "max = results[0]\n",
        "for i, result in enumerate(results):\n",
        "  if result['eval_f1'] > max['eval_f1']:\n",
        "    max = result\n",
        "\n",
        "print(f'\\n\\n================\\\n",
        "        \\nBest Result: \\\n",
        "        \\nrank={max[\"rank\"]}, \\\n",
        "        \\nalpha={max[\"alpha\"]}, \\\n",
        "        \\nparameters={max[\"parameters\"]}, \\\n",
        "        \\ntrainable_parameters={max[\"trainable_parameters\"]}, \\\n",
        "        \\nbatch_size={max[\"batch_size\"]}, \\\n",
        "        \\nlearning_rate={max[\"learning_rate\"]}, \\\n",
        "        \\neval_f1={max[\"eval_f1\"]}')"
      ],
      "metadata": {
        "id": "2sRCUocTD3eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "with open('lora-results.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=list(results[0].keys()))\n",
        "\n",
        "    writer.writeheader()\n",
        "    for result in results:\n",
        "      writer.writerow(result)"
      ],
      "metadata": {
        "id": "LGyzzHVMJHpf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyOykyFDl17taWZEZBjSYfbL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c86e89190b77403ca47d4ed736385dff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7e5d72e0a734913908fa1fdbedcc58c",
              "IPY_MODEL_9ed60b2736a845678021ab18b1d17f11",
              "IPY_MODEL_a9dd3e77ed314a28a33d1703ee60e313"
            ],
            "layout": "IPY_MODEL_3d71f077cbd247c9946fe422a983a433"
          }
        },
        "a7e5d72e0a734913908fa1fdbedcc58c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a69c54ba2b1454fb7899562ef9f94d5",
            "placeholder": "​",
            "style": "IPY_MODEL_a8b51a4d2b6e4ecbb94230b6891d9173",
            "value": "Map: 100%"
          }
        },
        "9ed60b2736a845678021ab18b1d17f11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08f1a3bea0814bd8bd55f62278704772",
            "max": 1725,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12441be770a14fd5b44fb3a19fe4e04c",
            "value": 1725
          }
        },
        "a9dd3e77ed314a28a33d1703ee60e313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7370acd26a94a2282ed03d09419f895",
            "placeholder": "​",
            "style": "IPY_MODEL_9f84891f80ce40c6aae4b5b033f2083b",
            "value": " 1725/1725 [00:00&lt;00:00, 7282.26 examples/s]"
          }
        },
        "3d71f077cbd247c9946fe422a983a433": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a69c54ba2b1454fb7899562ef9f94d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8b51a4d2b6e4ecbb94230b6891d9173": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08f1a3bea0814bd8bd55f62278704772": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12441be770a14fd5b44fb3a19fe4e04c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7370acd26a94a2282ed03d09419f895": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f84891f80ce40c6aae4b5b033f2083b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}