{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danjshaw/ece57000-finalProject/blob/main/lora-bert-tiny/source/lora-bert-tiny.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Setup"
      ],
      "metadata": {
        "id": "RJc8lRi2sPF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "s1zuELS-Znol",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c686a6dd-8f3d-47b9-fee8-137b2f7e933c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.exists('/content/drive/MyDrive/lora-bert-tiny/'):\n",
        "    os.makedirs('/content/drive/MyDrive/lora-bert-tiny/')\n",
        "output_dir = '/content/drive/MyDrive/lora-bert-tiny/'"
      ],
      "metadata": {
        "id": "rmH2TqY1qMYw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OOOR51p7nJQb",
        "outputId": "d510b72d-9cd9-4917-e52a-d52218ed47b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.10)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n",
            "Requirement already satisfied: codecarbon in /usr/local/lib/python3.10/dist-packages (2.7.4)\n",
            "Requirement already satisfied: arrow in /usr/local/lib/python3.10/dist-packages (from codecarbon) (1.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from codecarbon) (8.1.7)\n",
            "Requirement already satisfied: fief-client[cli] in /usr/local/lib/python3.10/dist-packages (from codecarbon) (0.20.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from codecarbon) (2.2.2)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from codecarbon) (0.21.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from codecarbon) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from codecarbon) (9.0.0)\n",
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.10/dist-packages (from codecarbon) (11.5.3)\n",
            "Requirement already satisfied: questionary in /usr/local/lib/python3.10/dist-packages (from codecarbon) (2.0.1)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from codecarbon) (3.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from codecarbon) (2.32.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from codecarbon) (13.9.4)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.10/dist-packages (from codecarbon) (0.13.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from arrow->codecarbon) (2.8.2)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.10/dist-packages (from arrow->codecarbon) (2.9.0.20241003)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from fief-client[cli]->codecarbon) (0.27.2)\n",
            "Requirement already satisfied: jwcrypto<2.0.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from fief-client[cli]->codecarbon) (1.5.6)\n",
            "Requirement already satisfied: yaspin in /usr/local/lib/python3.10/dist-packages (from fief-client[cli]->codecarbon) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas->codecarbon) (1.26.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->codecarbon) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->codecarbon) (2024.2)\n",
            "Requirement already satisfied: prompt_toolkit<=3.0.36,>=2.0 in /usr/local/lib/python3.10/dist-packages (from questionary->codecarbon) (3.0.36)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->codecarbon) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->codecarbon) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->codecarbon) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->codecarbon) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->codecarbon) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->codecarbon) (2.18.0)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich->codecarbon) (4.12.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer->codecarbon) (1.5.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (0.14.0)\n",
            "Requirement already satisfied: cryptography>=3.4 in /usr/local/lib/python3.10/dist-packages (from jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (43.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->codecarbon) (0.1.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt_toolkit<=3.0.36,>=2.0->questionary->codecarbon) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7.0->arrow->codecarbon) (1.16.0)\n",
            "Requirement already satisfied: termcolor<2.4.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from yaspin->fief-client[cli]->codecarbon) (2.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (1.17.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.2.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (2.22)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 5, in <module>\n",
            "    from pip._internal.cli.main import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 11, in <module>\n",
            "    from pip._internal.cli.autocompletion import autocomplete\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n",
            "    from pip._internal.cli.main_parser import create_main_parser\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main_parser.py\", line 9, in <module>\n",
            "    from pip._internal.build_env import get_runnable_pip\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/build_env.py\", line 19, in <module>\n",
            "    from pip._internal.cli.spinners import open_spinner\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/spinners.py\", line 9, in <module>\n",
            "    from pip._internal.utils.logging import get_indentation\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 13, in <module>\n",
            "    from pip._vendor.rich.console import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 594, in <module>\n",
            "    class Console:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 635, in Console\n",
            "    color_system: Optional[\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 309, in inner\n",
            "    return cached(*args, **kwds)\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 403, in __getitem__\n",
            "    return self._getitem(self, parameters)\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 530, in Optional\n",
            "    return Union[arg, type(None)]\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 309, in inner\n",
            "    return cached(*args, **kwds)\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 403, in __getitem__\n",
            "    return self._getitem(self, parameters)\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 520, in Union\n",
            "    return _UnionGenericAlias(self, parameters, name=\"Optional\")\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 1027, in __init__\n",
            "    self._paramspec_tvars = _paramspec_tvars\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 989, in __setattr__\n",
            "    super().__setattr__(attr, val)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install codecarbon\n",
        "!pip freeze > /content/drive/MyDrive/lora-bert-tiny/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from codecarbon import EmissionsTracker"
      ],
      "metadata": {
        "id": "_rJOUWbHb7h7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiAkOY-564eO",
        "outputId": "a4a6e605-3407-4236-bf81-88d31fa9ea9b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Followed examples from this [Hugging Face NLP course](https://huggingface.co/learn/nlp-course/chapter3/3?fw=pt#fine-tuning-a-model-with-the-trainer-api) on how to use the trainer API for fine-tuning."
      ],
      "metadata": {
        "id": "xM1jwv_maqfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "from datasets import load_dataset\n",
        "import evaluate\n",
        "\n",
        "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
        "checkpoint = \"prajjwal1/bert-tiny\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"])\n",
        "\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    metric = evaluate.load(\"glue\", \"mrpc\")\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525,
          "referenced_widgets": [
            "804b53b329504efeb233589079c2ed65",
            "396b380cfdf94988ade70dbff20cf1d5",
            "94b4fba6eb90479fb4312afad8bde284",
            "04a00fc856934552afbbd3139d5169d0",
            "1d25ea923d8c4b719b81fc6eea74a0d1",
            "f789c228671340ae93054f5ff479d311",
            "2ef9c6682df149dba78844ff1016c7de",
            "f69f6f89237941f389552123d2803206",
            "aac4fce82f6143299899757cba7ae048",
            "69eb831fc04345fd835e8ed7836a1286",
            "f86a1a083f54444aa3d62a091d6c4e2b",
            "e1825bf597b4407d895dc24f59fc7fbb",
            "ca30609b4aee40a282cb76b71049b073",
            "8a07bde9e50b40378e0fb9e3cd598641",
            "01843e15de8846fab8639cd670da3013",
            "ff269a6b3e544b618f491c096eee1880",
            "f14de9da40fd40d69f6b436f9331c206",
            "e5cc459b69be4ea6a8e7097981a9925a",
            "c1333795e33d4803af634f1b4da13a3f",
            "ed4068ab1e894bc3a323d4fe62e9fdcb",
            "db5170b092f241e5aca61256ab56fb56",
            "50d4d353925345f4bb7c11d6d3921ec6",
            "0ecad5d0437e4617b4a4f6e08f8eb01d",
            "2d4866d2ce6e4c8bae8fb58cd6d2fd11",
            "e162354030ad4e7ebd5a199feb8cf685",
            "9c6217d4e1e14fca9cd85c9162af4c65",
            "df51cf89f5ef401ab93c10806181ddbf",
            "768ad98eb23e4a4e989d89bc88c52040",
            "2d3850717de64656bef125069a06bece",
            "d791c475485c4da8b082b231e46e20aa",
            "7d90985ba6594c28b56d9aed37f2e2cf",
            "b9bfa850e825499aa89ebb8ed2558cf2",
            "d64ad46a4c984ffc876534688ea19f17",
            "4fe003aecb914f118eff0d26fecb8262",
            "f69b5b6ab3b74036b444fb700b69d1e8",
            "7496dd11e92b4ec79759f087fb19b5c3",
            "0eb27a7e21bf46fbb065c81e7555c227",
            "6bf17e9300784020b362a1cf54b1230b",
            "026cd300f50a4016929e1c343c475fd4",
            "d6597f21cfe14788b3dc4ed469f9343b",
            "2b41f230e5664c38a6be6121abfecd07",
            "598bf45ca0014737babe10f57145e36b",
            "537fd778509c40259ad7045ab5e87b2a",
            "6911a1f9c0d54420a4837024ab90cd59",
            "ce1701d92fd745889ba20dd483573658",
            "98e559bf85c94659b8367ec5f02ff12d",
            "ca6df7952f2941c0b66d6897b94cc905",
            "56e6d95353cd471db726fde6b7b00763",
            "87657695861a42e99587444803e38366",
            "9f19c764a6414475a67bf8421e26e56e",
            "f74df151926d4bfab855628b27bf70aa",
            "7ee46b807c7f4626be081655b1540d33",
            "8d2eaf63de034e149cbdadc733a58549",
            "93f011392d4a41579de29f2990ed35b4",
            "b5b63d09e98b44bda64484ea4832a59f",
            "37df508495df4ece897ee3cd9ce3118a",
            "69f4753709a14ff7be835d120655ae1d",
            "2c58876d7e7344c48576e0268b69110f",
            "770aa953df094b17a05714b3aa6eb20f",
            "1d9d273598f6484ebff3e0df00a79c12",
            "da7fb36a79904acba29e2de9a1e0a1b1",
            "5c5b35d007bb46e7826a19bba3fbd055",
            "482881cc049a4c10ac5ea63565a382c0",
            "edaf269847d54972a49ce50a95c107fa",
            "eaa012f0012b4e8a822ea78d30e95b1d",
            "ef49c17c008d43faa275b3e67d1c9281",
            "292f94028c2b4d7b91d783a76aa159dc",
            "04d6884f9e8a4a75bd69ff808099e4f8",
            "a0c1d06cf4b141df99cc211e244cbb39",
            "9e02431a63bb4b10a7207198c5ed0174",
            "43e10977bf1744f5a0ce43c24b906c56",
            "728ab324b19a4c73ae5808ff8e8ea2e8",
            "38e2a9fb3dc04b6e8caaa7c9a5eddd83",
            "c93760786efc4ba99fa830aa732fb4bb",
            "f30d2e02f9af4a059562d5d92da5b388",
            "efe7214652f54bcbbd1b211251f162de",
            "d88b1e868f354dcc97a2402a2a69b63b",
            "3cb3b64b68f3415ea6b22a35d309601d",
            "6e080d05948f45f29354b9cd594fa7dc",
            "d6ccc2eca81e449493c7e0239748a1bd",
            "9b691433dee74b53ac18961c23b28556",
            "9005bed315264832ab0def8139a8be0d",
            "303bac65625c41b1a0299636413651c3",
            "76462d3f73d043bcba868389fcd34309",
            "096ad02ab12848409b2d330fe663ae0a",
            "1b6bf7ab7812490badd56be4a6a85e8f",
            "77e5fd7eb0d9428591e9a85d5be13e27",
            "b4992a80a3974230a6819beef87f7972",
            "8a6625e2e9c7458eb2a0e14964019233",
            "fdf3abb5388d4a829d587f094fbfa802",
            "0d75f0e6567549cdbeb3d4f35790b112",
            "544623f02e354c459d75c2814ea31d46",
            "cd6ca0f33b204bd7acfbad2de4f2aa3a",
            "5f9a06c11f3e441aa967dfa3a5abe22c",
            "5a2f8ea1e34f439a88ef2241e450625f",
            "4924bd18ade04843bd616daaf617704e",
            "d7a6f65cb84e4e508efa08397ee2a94f",
            "afc8d9b254374df99eb6c83ad921ffd7",
            "186b5f028dab4350a78e5723ccf0d288",
            "21c3933e7e9149998e7826c15cc56f7a",
            "61f277dc7c5949089d657f8f6a4edf66",
            "60687a4363134796829d217b31405954",
            "5c03a916f95d47a1a927213d6797ea2a",
            "7e43f7a554b14c69b8b85e88241baaaa",
            "740c768fe3844738b29b8512a7c2dcd9",
            "39dd1c4ff4d345c6a4ef9e1f4a2f9779",
            "6790abc9363045b8b7a1fa9bffb9b6c5",
            "13aa7b3b188c454eafd6856499454007",
            "7af1cf4362ff461dba4799eac83c1b9c",
            "797f65625b2043f1af0ece3cc1ede67b",
            "854d4a1a596541f188ef4056557e8ee8",
            "0ee9933bd6ca4303a583e7da77b88b95",
            "8d52ffb1a2e94bd58141f07ce05bfd95",
            "f8bf90b227d544f2823a83a2ff6d1357",
            "f9890775891d40a59c577b17da0d7c84",
            "1460c3364a4940df8f47f9f4b607ca01",
            "f4f58d1bfb1e4a7f85e3d92f1f0d29cc",
            "afc31f897bff43f3a74823c1844ff35e",
            "5a5acd83adeb4b9eaad6cce967daf2ba",
            "9f233fd208c343c19a2cbbdf2566e827",
            "63ebfc4053e14e27b6116a32cc994b1c",
            "bab4da1c3d6a41a4bb567e69ffea75e2",
            "7262b9bd0f8348bcb116ad53f8a975bf",
            "a8fd40a1893541f88e25baccb60006b5",
            "158fdc15fbf34667ab5acc6e866af725",
            "9d433bec88e44d949bf1f1451060acce",
            "5c73e73c59bb444d9bdaedc30a1c645c",
            "0bf2aa7acd064c06a702ed625aded2fc",
            "060c092e11964359a586533efcf6b7cb",
            "da7a74c024d641aa94c8babdbe72bd20",
            "ed7a33d877ce436983622c91768e851b",
            "8afa01f06f43477fa3e978aaf56e162b"
          ]
        },
        "id": "VDqSTwjJilGA",
        "outputId": "9c5a7ec7-3a29-4bd6-db42-c3c72f07f680",
        "collapsed": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/35.3k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "804b53b329504efeb233589079c2ed65"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/649k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1825bf597b4407d895dc24f59fc7fbb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "validation-00000-of-00001.parquet:   0%|          | 0.00/75.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ecad5d0437e4617b4a4f6e08f8eb01d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/308k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4fe003aecb914f118eff0d26fecb8262"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/3668 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce1701d92fd745889ba20dd483573658"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/408 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37df508495df4ece897ee3cd9ce3118a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1725 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "292f94028c2b4d7b91d783a76aa159dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/285 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3cb3b64b68f3415ea6b22a35d309601d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a6625e2e9c7458eb2a0e14964019233"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3668 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21c3933e7e9149998e7826c15cc56f7a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "854d4a1a596541f188ef4056557e8ee8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bab4da1c3d6a41a4bb567e69ffea75e2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dnum5mxHf-MI"
      },
      "outputs": [],
      "source": [
        "def get_trainable_parameters(model):\n",
        "  trainable_parameters = 0\n",
        "  parameters = 0\n",
        "  for param in model.parameters():\n",
        "    parameters += param.numel()\n",
        "    if param.requires_grad:\n",
        "      trainable_parameters += param.numel()\n",
        "  return {'total_parameters': parameters, 'trainable_parameters': trainable_parameters}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "def write_results_to_csv(file_name, results):\n",
        "  with open(file_name, 'w', newline='') as csvfile:\n",
        "      writer = csv.DictWriter(csvfile, fieldnames=list(results[0].keys()))\n",
        "      writer.writeheader()\n",
        "      for result in results:\n",
        "        writer.writerow(result)"
      ],
      "metadata": {
        "id": "yexmh39lLLnX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of times to run each section."
      ],
      "metadata": {
        "id": "JN1jXzaKZQsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_runs = 5"
      ],
      "metadata": {
        "id": "xiqIwicGh6Ab"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Full Fine-Tuning\n",
        "\n"
      ],
      "metadata": {
        "id": "6pdjddZVsbQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fine_tune(epochs, batch_size, learning_rate):\n",
        "  # Initialize result\n",
        "  result = {\"batch_size\": size, \"learning_rate\": rate}\n",
        "\n",
        "  # Track emissions\n",
        "  tracker = EmissionsTracker('fine-tuning-bert-tiny', save_to_file=False)\n",
        "  try:\n",
        "    tracker.start()\n",
        "\n",
        "    # Create the model\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2).to(device)\n",
        "\n",
        "    # Setup the trainer\n",
        "    training_args = TrainingArguments(\n",
        "        \"fine-tuning-trainer\",\n",
        "        eval_strategy=\"epoch\",\n",
        "        per_device_eval_batch_size=size,\n",
        "        per_device_train_batch_size=size,\n",
        "        num_train_epochs=epochs,\n",
        "        learning_rate=rate,\n",
        "        disable_tqdm=True,\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "    trainer = Trainer(\n",
        "        model,\n",
        "        training_args,\n",
        "        train_dataset=tokenized_datasets[\"train\"],\n",
        "        eval_dataset=tokenized_datasets[\"validation\"],\n",
        "        data_collator=data_collator,\n",
        "        processing_class=tokenizer,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    result |= trainer.train().metrics\n",
        "\n",
        "    # Stop tracking emissions\n",
        "    tracker.stop()\n",
        "\n",
        "    # Store metrics and delete the tracker\n",
        "    result |= trainer.evaluate() | get_trainable_parameters(model) | tracker.final_emissions_data.values\n",
        "  finally:\n",
        "    del tracker\n",
        "\n",
        "  return result"
      ],
      "metadata": {
        "id": "AQt5byIxFRrJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters from [google-research/bert](https://github.com/google-research/bert):\n",
        "\n",
        "\n",
        "\n",
        "> For each task, we selected the best fine-tuning hyperparameters from the lists below, and trained for 4 epochs:\n",
        "> * batch sizes: 8, 16, 32, 64, 128\n",
        "> * learning rates: 3e-4, 1e-4, 5e-5, 3e-5\n",
        "\n"
      ],
      "metadata": {
        "id": "aZnBuTehsapX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 4\n",
        "batch_sizes = [8, 16, 32, 64, 128]\n",
        "learning_rates = [3e-4, 1e-4, 5e-5, 3e-5]"
      ],
      "metadata": {
        "id": "62XZoxhusMhO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification, set_seed\n",
        "import time\n",
        "\n",
        "ft_results = []\n",
        "progress = 0\n",
        "iterations = len(batch_sizes)*len(learning_rates)*num_runs\n",
        "\n",
        "# Hyperparameter tuning\n",
        "start_time = time.time()\n",
        "for run in range(1, num_runs+1):\n",
        "  set_seed(run)\n",
        "\n",
        "  for size in batch_sizes:\n",
        "    for rate in learning_rates:\n",
        "      # Track progress\n",
        "      progress += 1\n",
        "      print(f\"Progress: {progress}/{iterations}\")\n",
        "\n",
        "      # Fine-tune the model and store the results\n",
        "      ft_result = {\"run\":run}\n",
        "      ft_result |= fine_tune(epochs, size, rate)\n",
        "      ft_results.append(ft_result)\n",
        "\n",
        "  write_results_to_csv(output_dir + 'ft-results.csv', ft_results)\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "runtime_seconds = end_time - start_time\n",
        "runtime_minutes = runtime_seconds / 60\n",
        "\n",
        "# Output the best result\n",
        "max_ft_result = ft_results[0]\n",
        "for _, result in enumerate(ft_results):\n",
        "  if result['eval_f1'] > max_ft_result['eval_f1']:\n",
        "    max_ft_result = result\n",
        "print(f'\\n================ \\\n",
        "        \\nTotal Runtime: {runtime_minutes} minutes \\\n",
        "        \\nBest Result: \\\n",
        "        \\n\\tF1={max_ft_result[\"eval_f1\"]} \\\n",
        "        \\n\\tBatch Size={max_ft_result[\"batch_size\"]} \\\n",
        "        \\n\\tLearning Rate={max_ft_result[\"learning_rate\"]}'\n",
        ")"
      ],
      "metadata": {
        "id": "R0rtaL56jMN3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8193ab7e-6133-4280-e8fa-4ec6e420559f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:11:52] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:11:52] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:11:52] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:11:52] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:11:52] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:11:54] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:11:54] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:11:54] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:11:54]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:11:54]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:11:54]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:11:54]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:11:54]   CPU count: 8\n",
            "[codecarbon INFO @ 00:11:54]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:11:54]   GPU count: 1\n",
            "[codecarbon INFO @ 00:11:54]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5478376746177673, 'eval_accuracy': 0.75, 'eval_f1': 0.840625, 'eval_runtime': 0.8275, 'eval_samples_per_second': 493.06, 'eval_steps_per_second': 61.633, 'epoch': 1.0}\n",
            "{'loss': 0.6001, 'grad_norm': 6.086310863494873, 'learning_rate': 0.00021830065359477123, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.590671181678772, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8124031007751938, 'eval_runtime': 0.7529, 'eval_samples_per_second': 541.931, 'eval_steps_per_second': 67.741, 'epoch': 2.0}\n",
            "{'loss': 0.4803, 'grad_norm': 3.5907392501831055, 'learning_rate': 0.00013660130718954247, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:12:09] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:12:09] Energy consumed for all GPUs : 0.000143 kWh. Total GPU Power : 34.40022061087558 W\n",
            "[codecarbon INFO @ 00:12:09] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:12:09] 0.000400 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7745211720466614, 'eval_accuracy': 0.7156862745098039, 'eval_f1': 0.7935943060498221, 'eval_runtime': 0.7518, 'eval_samples_per_second': 542.725, 'eval_steps_per_second': 67.841, 'epoch': 3.0}\n",
            "{'loss': 0.3164, 'grad_norm': 35.319210052490234, 'learning_rate': 5.4901960784313716e-05, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:12:19] Energy consumed for RAM : 0.000135 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:12:19] Energy consumed for all GPUs : 0.000245 kWh. Total GPU Power : 35.5375371116619 W\n",
            "[codecarbon INFO @ 00:12:19] Energy consumed for all CPUs : 0.000299 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:12:19] 0.000679 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.9235227704048157, 'eval_accuracy': 0.7450980392156863, 'eval_f1': 0.8231292517006803, 'eval_runtime': 0.7564, 'eval_samples_per_second': 539.4, 'eval_steps_per_second': 67.425, 'epoch': 4.0}\n",
            "{'train_runtime': 24.5055, 'train_samples_per_second': 598.722, 'train_steps_per_second': 74.922, 'train_loss': 0.42391776623029853, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:12:20] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:12:20] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:12:20] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:12:20] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:12:20] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.9235227704048157, 'eval_accuracy': 0.7450980392156863, 'eval_f1': 0.8231292517006803, 'eval_runtime': 0.7437, 'eval_samples_per_second': 548.575, 'eval_steps_per_second': 68.572, 'epoch': 4.0}\n",
            "Progress: 2/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:12:21] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:12:21] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:12:21] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:12:21]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:12:21]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:12:21]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:12:21]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:12:21]   CPU count: 8\n",
            "[codecarbon INFO @ 00:12:21]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:12:21]   GPU count: 1\n",
            "[codecarbon INFO @ 00:12:21]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.571905791759491, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8169440242057489, 'eval_runtime': 0.7351, 'eval_samples_per_second': 555.014, 'eval_steps_per_second': 69.377, 'epoch': 1.0}\n",
            "{'loss': 0.5884, 'grad_norm': 4.293759822845459, 'learning_rate': 7.276688453159042e-05, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.5654860734939575, 'eval_accuracy': 0.7352941176470589, 'eval_f1': 0.8285714285714286, 'eval_runtime': 0.7651, 'eval_samples_per_second': 533.234, 'eval_steps_per_second': 66.654, 'epoch': 2.0}\n",
            "{'loss': 0.4993, 'grad_norm': 8.675013542175293, 'learning_rate': 4.5533769063180834e-05, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:12:36] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:12:36] Energy consumed for all GPUs : 0.000149 kWh. Total GPU Power : 35.777496000476845 W\n",
            "[codecarbon INFO @ 00:12:36] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:12:36] 0.000406 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6270501613616943, 'eval_accuracy': 0.7352941176470589, 'eval_f1': 0.8296529968454258, 'eval_runtime': 0.7976, 'eval_samples_per_second': 511.511, 'eval_steps_per_second': 63.939, 'epoch': 3.0}\n",
            "{'loss': 0.4045, 'grad_norm': 26.807472229003906, 'learning_rate': 1.8300653594771242e-05, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:12:45] Energy consumed for RAM : 0.000127 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:12:45] Energy consumed for all GPUs : 0.000238 kWh. Total GPU Power : 35.51153767823761 W\n",
            "[codecarbon INFO @ 00:12:45] Energy consumed for all CPUs : 0.000283 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:12:45] 0.000649 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6656573414802551, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8325508607198748, 'eval_runtime': 0.7523, 'eval_samples_per_second': 542.332, 'eval_steps_per_second': 67.791, 'epoch': 4.0}\n",
            "{'train_runtime': 23.3919, 'train_samples_per_second': 627.227, 'train_steps_per_second': 78.489, 'train_loss': 0.47345523792674077, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:12:46] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:12:46] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:12:46] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:12:46] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:12:46] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6656573414802551, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8325508607198748, 'eval_runtime': 0.737, 'eval_samples_per_second': 553.607, 'eval_steps_per_second': 69.201, 'epoch': 4.0}\n",
            "Progress: 3/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:12:47] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:12:47] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:12:47] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:12:47]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:12:47]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:12:47]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:12:47]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:12:47]   CPU count: 8\n",
            "[codecarbon INFO @ 00:12:47]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:12:47]   GPU count: 1\n",
            "[codecarbon INFO @ 00:12:47]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5733863711357117, 'eval_accuracy': 0.7009803921568627, 'eval_f1': 0.8134556574923547, 'eval_runtime': 0.7481, 'eval_samples_per_second': 545.416, 'eval_steps_per_second': 68.177, 'epoch': 1.0}\n",
            "{'loss': 0.6013, 'grad_norm': 4.323869228363037, 'learning_rate': 3.638344226579521e-05, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.5774785876274109, 'eval_accuracy': 0.7083333333333334, 'eval_f1': 0.8194233687405159, 'eval_runtime': 0.7419, 'eval_samples_per_second': 549.957, 'eval_steps_per_second': 68.745, 'epoch': 2.0}\n",
            "{'loss': 0.5438, 'grad_norm': 5.283394813537598, 'learning_rate': 2.2766884531590417e-05, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:13:02] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:13:02] Energy consumed for all GPUs : 0.000150 kWh. Total GPU Power : 35.99000822862739 W\n",
            "[codecarbon INFO @ 00:13:02] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:13:02] 0.000407 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5611313581466675, 'eval_accuracy': 0.7279411764705882, 'eval_f1': 0.8246445497630331, 'eval_runtime': 0.7443, 'eval_samples_per_second': 548.177, 'eval_steps_per_second': 68.522, 'epoch': 3.0}\n",
            "{'loss': 0.4849, 'grad_norm': 14.096569061279297, 'learning_rate': 9.150326797385621e-06, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:13:11] Energy consumed for RAM : 0.000127 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:13:11] Energy consumed for all GPUs : 0.000237 kWh. Total GPU Power : 35.68325008575824 W\n",
            "[codecarbon INFO @ 00:13:11] Energy consumed for all CPUs : 0.000281 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:13:11] 0.000645 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.587859570980072, 'eval_accuracy': 0.7279411764705882, 'eval_f1': 0.8268330733229329, 'eval_runtime': 0.7504, 'eval_samples_per_second': 543.695, 'eval_steps_per_second': 67.962, 'epoch': 4.0}\n",
            "{'train_runtime': 23.2181, 'train_samples_per_second': 631.92, 'train_steps_per_second': 79.076, 'train_loss': 0.5309766798497285, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:13:12] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:13:12] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:13:12] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:13:12] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:13:12] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.587859570980072, 'eval_accuracy': 0.7279411764705882, 'eval_f1': 0.8268330733229329, 'eval_runtime': 0.738, 'eval_samples_per_second': 552.816, 'eval_steps_per_second': 69.102, 'epoch': 4.0}\n",
            "Progress: 4/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:13:13] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:13:13] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:13:13] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:13:13]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:13:13]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:13:13]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:13:13]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:13:13]   CPU count: 8\n",
            "[codecarbon INFO @ 00:13:13]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:13:13]   GPU count: 1\n",
            "[codecarbon INFO @ 00:13:13]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5838139653205872, 'eval_accuracy': 0.7009803921568627, 'eval_f1': 0.8184523809523809, 'eval_runtime': 0.745, 'eval_samples_per_second': 547.649, 'eval_steps_per_second': 68.456, 'epoch': 1.0}\n",
            "{'loss': 0.6134, 'grad_norm': 2.5178942680358887, 'learning_rate': 2.1830065359477124e-05, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.5830901861190796, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8180451127819549, 'eval_runtime': 0.7419, 'eval_samples_per_second': 549.904, 'eval_steps_per_second': 68.738, 'epoch': 2.0}\n",
            "{'loss': 0.5689, 'grad_norm': 4.079008102416992, 'learning_rate': 1.366013071895425e-05, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:13:28] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:13:28] Energy consumed for all GPUs : 0.000150 kWh. Total GPU Power : 36.07209026408989 W\n",
            "[codecarbon INFO @ 00:13:28] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:13:28] 0.000407 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.568699836730957, 'eval_accuracy': 0.7132352941176471, 'eval_f1': 0.8197226502311248, 'eval_runtime': 0.7846, 'eval_samples_per_second': 520.02, 'eval_steps_per_second': 65.002, 'epoch': 3.0}\n",
            "{'loss': 0.5302, 'grad_norm': 6.041450023651123, 'learning_rate': 5.490196078431373e-06, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:13:37] Energy consumed for RAM : 0.000127 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:13:37] Energy consumed for all GPUs : 0.000238 kWh. Total GPU Power : 35.65995782323203 W\n",
            "[codecarbon INFO @ 00:13:37] Energy consumed for all CPUs : 0.000282 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:13:37] 0.000647 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5771942734718323, 'eval_accuracy': 0.7107843137254902, 'eval_f1': 0.8195718654434251, 'eval_runtime': 0.7876, 'eval_samples_per_second': 518.016, 'eval_steps_per_second': 64.752, 'epoch': 4.0}\n",
            "{'train_runtime': 23.2879, 'train_samples_per_second': 630.028, 'train_steps_per_second': 78.839, 'train_loss': 0.5637553262814458, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:13:38] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:13:38] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:13:38] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:13:38] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:13:38] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5771942734718323, 'eval_accuracy': 0.7107843137254902, 'eval_f1': 0.8195718654434251, 'eval_runtime': 0.7595, 'eval_samples_per_second': 537.177, 'eval_steps_per_second': 67.147, 'epoch': 4.0}\n",
            "Progress: 5/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:13:39] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:13:39] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:13:39] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:13:39]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:13:39]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:13:39]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:13:39]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:13:39]   CPU count: 8\n",
            "[codecarbon INFO @ 00:13:39]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:13:39]   GPU count: 1\n",
            "[codecarbon INFO @ 00:13:39]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5624045133590698, 'eval_accuracy': 0.7230392156862745, 'eval_f1': 0.8231611893583725, 'eval_runtime': 0.6553, 'eval_samples_per_second': 622.638, 'eval_steps_per_second': 39.678, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5531349778175354, 'eval_accuracy': 0.7328431372549019, 'eval_f1': 0.8256, 'eval_runtime': 0.6539, 'eval_samples_per_second': 623.938, 'eval_steps_per_second': 39.761, 'epoch': 2.0}\n",
            "{'loss': 0.5239, 'grad_norm': 15.012598991394043, 'learning_rate': 0.00013695652173913042, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.590812087059021, 'eval_accuracy': 0.7401960784313726, 'eval_f1': 0.8221476510067114, 'eval_runtime': 0.6463, 'eval_samples_per_second': 631.268, 'eval_steps_per_second': 40.228, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:13:53] Energy consumed for RAM : 0.000077 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:13:53] Energy consumed for all GPUs : 0.000157 kWh. Total GPU Power : 38.940459340985974 W\n",
            "[codecarbon INFO @ 00:13:53] Energy consumed for all CPUs : 0.000171 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:13:53] 0.000405 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7519146800041199, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8243021346469622, 'eval_runtime': 0.6741, 'eval_samples_per_second': 605.296, 'eval_steps_per_second': 38.573, 'epoch': 4.0}\n",
            "{'train_runtime': 13.8801, 'train_samples_per_second': 1057.055, 'train_steps_per_second': 66.282, 'train_loss': 0.40669037362803584, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:13:54] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:13:54] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:13:54] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:13:54] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:13:54] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7519146800041199, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8243021346469622, 'eval_runtime': 0.6576, 'eval_samples_per_second': 620.397, 'eval_steps_per_second': 39.535, 'epoch': 4.0}\n",
            "Progress: 6/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:13:55] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:13:55] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:13:55] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:13:55]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:13:55]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:13:55]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:13:55]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:13:55]   CPU count: 8\n",
            "[codecarbon INFO @ 00:13:55]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:13:55]   GPU count: 1\n",
            "[codecarbon INFO @ 00:13:55]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.564354419708252, 'eval_accuracy': 0.7132352941176471, 'eval_f1': 0.8180404354587869, 'eval_runtime': 0.6553, 'eval_samples_per_second': 622.648, 'eval_steps_per_second': 39.679, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5474852919578552, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.831496062992126, 'eval_runtime': 0.6531, 'eval_samples_per_second': 624.707, 'eval_steps_per_second': 39.81, 'epoch': 2.0}\n",
            "{'loss': 0.5577, 'grad_norm': 6.763742923736572, 'learning_rate': 4.565217391304348e-05, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.5569795966148376, 'eval_accuracy': 0.7426470588235294, 'eval_f1': 0.8330683624801272, 'eval_runtime': 0.6972, 'eval_samples_per_second': 585.239, 'eval_steps_per_second': 37.295, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:14:10] Energy consumed for RAM : 0.000077 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:14:10] Energy consumed for all GPUs : 0.000158 kWh. Total GPU Power : 39.035085834340556 W\n",
            "[codecarbon INFO @ 00:14:10] Energy consumed for all CPUs : 0.000172 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:14:10] 0.000406 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5896832346916199, 'eval_accuracy': 0.7328431372549019, 'eval_f1': 0.8299531981279251, 'eval_runtime': 0.7267, 'eval_samples_per_second': 561.466, 'eval_steps_per_second': 35.78, 'epoch': 4.0}\n",
            "{'train_runtime': 13.9089, 'train_samples_per_second': 1054.866, 'train_steps_per_second': 66.145, 'train_loss': 0.5020559891410495, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:14:11] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:14:11] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:14:11] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:14:11] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:14:11] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5896832346916199, 'eval_accuracy': 0.7328431372549019, 'eval_f1': 0.8299531981279251, 'eval_runtime': 0.7498, 'eval_samples_per_second': 544.116, 'eval_steps_per_second': 34.674, 'epoch': 4.0}\n",
            "Progress: 7/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:14:12] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:14:12] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:14:12] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:14:12]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:14:12]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:14:12]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:14:12]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:14:12]   CPU count: 8\n",
            "[codecarbon INFO @ 00:14:12]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:14:12]   GPU count: 1\n",
            "[codecarbon INFO @ 00:14:12]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5816411972045898, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8095952023988006, 'eval_runtime': 0.6623, 'eval_samples_per_second': 616.025, 'eval_steps_per_second': 39.256, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5781240463256836, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8185907046476761, 'eval_runtime': 0.6518, 'eval_samples_per_second': 625.959, 'eval_steps_per_second': 39.89, 'epoch': 2.0}\n",
            "{'loss': 0.5845, 'grad_norm': 4.170251846313477, 'learning_rate': 2.282608695652174e-05, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.568314790725708, 'eval_accuracy': 0.7083333333333334, 'eval_f1': 0.8183206106870229, 'eval_runtime': 0.6876, 'eval_samples_per_second': 593.398, 'eval_steps_per_second': 37.815, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:14:26] Energy consumed for RAM : 0.000077 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:14:26] Energy consumed for all GPUs : 0.000158 kWh. Total GPU Power : 39.2675788395978 W\n",
            "[codecarbon INFO @ 00:14:26] Energy consumed for all CPUs : 0.000171 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:14:26] 0.000406 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.568650484085083, 'eval_accuracy': 0.7205882352941176, 'eval_f1': 0.8246153846153846, 'eval_runtime': 0.6922, 'eval_samples_per_second': 589.432, 'eval_steps_per_second': 37.562, 'epoch': 4.0}\n",
            "{'train_runtime': 13.9034, 'train_samples_per_second': 1055.278, 'train_steps_per_second': 66.171, 'train_loss': 0.5531564961309018, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:14:27] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:14:27] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:14:27] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:14:27] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:14:27] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.568650484085083, 'eval_accuracy': 0.7205882352941176, 'eval_f1': 0.8246153846153846, 'eval_runtime': 0.6707, 'eval_samples_per_second': 608.308, 'eval_steps_per_second': 38.765, 'epoch': 4.0}\n",
            "Progress: 8/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:14:28] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:14:28] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:14:28] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:14:28]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:14:28]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:14:28]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:14:28]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:14:28]   CPU count: 8\n",
            "[codecarbon INFO @ 00:14:28]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:14:28]   GPU count: 1\n",
            "[codecarbon INFO @ 00:14:28]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5934128761291504, 'eval_accuracy': 0.6985294117647058, 'eval_f1': 0.8193832599118943, 'eval_runtime': 0.6617, 'eval_samples_per_second': 616.6, 'eval_steps_per_second': 39.293, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5834196209907532, 'eval_accuracy': 0.6985294117647058, 'eval_f1': 0.8161434977578476, 'eval_runtime': 0.6751, 'eval_samples_per_second': 604.396, 'eval_steps_per_second': 38.515, 'epoch': 2.0}\n",
            "{'loss': 0.6021, 'grad_norm': 2.227717161178589, 'learning_rate': 1.3695652173913042e-05, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.574123740196228, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8114630467571644, 'eval_runtime': 0.659, 'eval_samples_per_second': 619.153, 'eval_steps_per_second': 39.456, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:14:43] Energy consumed for RAM : 0.000077 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:14:43] Energy consumed for all GPUs : 0.000158 kWh. Total GPU Power : 39.32450342687881 W\n",
            "[codecarbon INFO @ 00:14:43] Energy consumed for all CPUs : 0.000171 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:14:43] 0.000406 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5735155940055847, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8126888217522659, 'eval_runtime': 0.6791, 'eval_samples_per_second': 600.815, 'eval_steps_per_second': 38.287, 'epoch': 4.0}\n",
            "{'train_runtime': 13.8898, 'train_samples_per_second': 1056.312, 'train_steps_per_second': 66.236, 'train_loss': 0.580059698353643, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:14:44] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:14:44] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:14:44] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:14:44] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:14:44] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5735155940055847, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8126888217522659, 'eval_runtime': 0.6594, 'eval_samples_per_second': 618.714, 'eval_steps_per_second': 39.428, 'epoch': 4.0}\n",
            "Progress: 9/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:14:45] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:14:45] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:14:45] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:14:45]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:14:45]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:14:45]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:14:45]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:14:45]   CPU count: 8\n",
            "[codecarbon INFO @ 00:14:45]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:14:45]   GPU count: 1\n",
            "[codecarbon INFO @ 00:14:45]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5496113896369934, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.831496062992126, 'eval_runtime': 0.6456, 'eval_samples_per_second': 631.951, 'eval_steps_per_second': 20.136, 'epoch': 1.0}\n",
            "{'eval_loss': 0.552695095539093, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8309636650868878, 'eval_runtime': 0.6131, 'eval_samples_per_second': 665.496, 'eval_steps_per_second': 21.205, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6253054141998291, 'eval_accuracy': 0.7450980392156863, 'eval_f1': 0.8354430379746836, 'eval_runtime': 0.6353, 'eval_samples_per_second': 642.168, 'eval_steps_per_second': 20.461, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:14:55] Energy consumed for RAM : 0.000053 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:14:55] Energy consumed for all GPUs : 0.000132 kWh. Total GPU Power : 47.53697523337507 W\n",
            "[codecarbon INFO @ 00:14:55] Energy consumed for all CPUs : 0.000118 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:14:55] 0.000303 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6537364721298218, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8304278922345484, 'eval_runtime': 0.6134, 'eval_samples_per_second': 665.184, 'eval_steps_per_second': 21.195, 'epoch': 4.0}\n",
            "{'train_runtime': 9.3726, 'train_samples_per_second': 1565.419, 'train_steps_per_second': 49.079, 'train_loss': 0.43501543791397757, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:14:55] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:14:55] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:14:55] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:14:55] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:14:55] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6537364721298218, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8304278922345484, 'eval_runtime': 0.6032, 'eval_samples_per_second': 676.373, 'eval_steps_per_second': 21.551, 'epoch': 4.0}\n",
            "Progress: 10/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:14:57] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:14:57] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:14:57] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:14:57]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:14:57]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:14:57]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:14:57]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:14:57]   CPU count: 8\n",
            "[codecarbon INFO @ 00:14:57]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:14:57]   GPU count: 1\n",
            "[codecarbon INFO @ 00:14:57]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.585704505443573, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.81089258698941, 'eval_runtime': 0.628, 'eval_samples_per_second': 649.698, 'eval_steps_per_second': 20.701, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5598652958869934, 'eval_accuracy': 0.7181372549019608, 'eval_f1': 0.8205928237129485, 'eval_runtime': 0.6114, 'eval_samples_per_second': 667.284, 'eval_steps_per_second': 21.262, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5700249075889587, 'eval_accuracy': 0.7132352941176471, 'eval_f1': 0.8186046511627907, 'eval_runtime': 0.6175, 'eval_samples_per_second': 660.756, 'eval_steps_per_second': 21.054, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:15:07] Energy consumed for RAM : 0.000052 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:15:07] Energy consumed for all GPUs : 0.000134 kWh. Total GPU Power : 48.871005246175194 W\n",
            "[codecarbon INFO @ 00:15:07] Energy consumed for all CPUs : 0.000117 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:15:07] 0.000303 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5717409253120422, 'eval_accuracy': 0.7254901960784313, 'eval_f1': 0.8255451713395638, 'eval_runtime': 0.6066, 'eval_samples_per_second': 672.654, 'eval_steps_per_second': 21.433, 'epoch': 4.0}\n",
            "{'train_runtime': 9.2824, 'train_samples_per_second': 1580.623, 'train_steps_per_second': 49.556, 'train_loss': 0.5322120666503907, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:15:07] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:15:07] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:15:07] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:15:07] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:15:07] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5717409253120422, 'eval_accuracy': 0.7254901960784313, 'eval_f1': 0.8255451713395638, 'eval_runtime': 0.6304, 'eval_samples_per_second': 647.252, 'eval_steps_per_second': 20.623, 'epoch': 4.0}\n",
            "Progress: 11/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:15:08] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:15:08] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:15:08] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:15:08]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:15:08]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:15:08]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:15:08]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:15:08]   CPU count: 8\n",
            "[codecarbon INFO @ 00:15:08]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:15:08]   GPU count: 1\n",
            "[codecarbon INFO @ 00:15:08]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5961236953735352, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8169838945827232, 'eval_runtime': 0.672, 'eval_samples_per_second': 607.126, 'eval_steps_per_second': 19.345, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5710234045982361, 'eval_accuracy': 0.7058823529411765, 'eval_f1': 0.817629179331307, 'eval_runtime': 0.6411, 'eval_samples_per_second': 636.428, 'eval_steps_per_second': 20.278, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5729517340660095, 'eval_accuracy': 0.7083333333333334, 'eval_f1': 0.8199697428139183, 'eval_runtime': 0.6434, 'eval_samples_per_second': 634.105, 'eval_steps_per_second': 20.204, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:15:19] Energy consumed for RAM : 0.000053 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:15:19] Energy consumed for all GPUs : 0.000133 kWh. Total GPU Power : 47.654277556820624 W\n",
            "[codecarbon INFO @ 00:15:19] Energy consumed for all CPUs : 0.000119 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:15:19] 0.000305 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.56805819272995, 'eval_accuracy': 0.7107843137254902, 'eval_f1': 0.8201219512195121, 'eval_runtime': 0.6423, 'eval_samples_per_second': 635.204, 'eval_steps_per_second': 20.239, 'epoch': 4.0}\n",
            "{'train_runtime': 9.4537, 'train_samples_per_second': 1551.983, 'train_steps_per_second': 48.658, 'train_loss': 0.5740605893342391, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:15:19] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:15:19] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:15:19] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:15:19] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:15:19] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.56805819272995, 'eval_accuracy': 0.7107843137254902, 'eval_f1': 0.8201219512195121, 'eval_runtime': 0.6122, 'eval_samples_per_second': 666.416, 'eval_steps_per_second': 21.234, 'epoch': 4.0}\n",
            "Progress: 12/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:15:20] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:15:20] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:15:20] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:15:20]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:15:20]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:15:20]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:15:20]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:15:20]   CPU count: 8\n",
            "[codecarbon INFO @ 00:15:20]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:15:20]   GPU count: 1\n",
            "[codecarbon INFO @ 00:15:20]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6053450703620911, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.7219, 'eval_samples_per_second': 565.147, 'eval_steps_per_second': 18.007, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5885691046714783, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8212703101920237, 'eval_runtime': 0.61, 'eval_samples_per_second': 668.885, 'eval_steps_per_second': 21.313, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5840325355529785, 'eval_accuracy': 0.6985294117647058, 'eval_f1': 0.8166915052160953, 'eval_runtime': 0.6827, 'eval_samples_per_second': 597.618, 'eval_steps_per_second': 19.042, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:15:31] Energy consumed for RAM : 0.000054 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:15:31] Energy consumed for all GPUs : 0.000140 kWh. Total GPU Power : 49.30848252952572 W\n",
            "[codecarbon INFO @ 00:15:31] Energy consumed for all CPUs : 0.000120 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:15:31] 0.000314 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5790587663650513, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8138138138138138, 'eval_runtime': 0.6373, 'eval_samples_per_second': 640.207, 'eval_steps_per_second': 20.399, 'epoch': 4.0}\n",
            "{'train_runtime': 9.4247, 'train_samples_per_second': 1556.752, 'train_steps_per_second': 48.808, 'train_loss': 0.5975138125212296, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:15:32] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:15:32] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:15:32] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:15:32] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:15:32] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5790587663650513, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8138138138138138, 'eval_runtime': 0.6207, 'eval_samples_per_second': 657.321, 'eval_steps_per_second': 20.944, 'epoch': 4.0}\n",
            "Progress: 13/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:15:33] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:15:33] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:15:33] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:15:33]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:15:33]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:15:33]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:15:33]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:15:33]   CPU count: 8\n",
            "[codecarbon INFO @ 00:15:33]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:15:33]   GPU count: 1\n",
            "[codecarbon INFO @ 00:15:33]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5753757357597351, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8132530120481928, 'eval_runtime': 0.6004, 'eval_samples_per_second': 679.562, 'eval_steps_per_second': 11.659, 'epoch': 1.0}\n",
            "{'eval_loss': 0.550995409488678, 'eval_accuracy': 0.7328431372549019, 'eval_f1': 0.8304821150855366, 'eval_runtime': 0.6099, 'eval_samples_per_second': 668.99, 'eval_steps_per_second': 11.478, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5720232129096985, 'eval_accuracy': 0.7598039215686274, 'eval_f1': 0.8434504792332268, 'eval_runtime': 0.6064, 'eval_samples_per_second': 672.861, 'eval_steps_per_second': 11.544, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:15:41] Energy consumed for RAM : 0.000043 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:15:41] Energy consumed for all GPUs : 0.000121 kWh. Total GPU Power : 53.86474097636713 W\n",
            "[codecarbon INFO @ 00:15:41] Energy consumed for all CPUs : 0.000096 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:15:41] 0.000260 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5971444249153137, 'eval_accuracy': 0.75, 'eval_f1': 0.8386075949367089, 'eval_runtime': 0.6466, 'eval_samples_per_second': 630.962, 'eval_steps_per_second': 10.825, 'epoch': 4.0}\n",
            "{'train_runtime': 7.5063, 'train_samples_per_second': 1954.619, 'train_steps_per_second': 30.907, 'train_loss': 0.4707464020827721, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:15:42] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:15:42] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:15:42] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:15:42] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:15:42] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5971444249153137, 'eval_accuracy': 0.75, 'eval_f1': 0.8386075949367089, 'eval_runtime': 0.5997, 'eval_samples_per_second': 680.35, 'eval_steps_per_second': 11.673, 'epoch': 4.0}\n",
            "Progress: 14/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:15:43] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:15:43] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:15:43] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:15:43]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:15:43]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:15:43]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:15:43]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:15:43]   CPU count: 8\n",
            "[codecarbon INFO @ 00:15:43]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:15:43]   GPU count: 1\n",
            "[codecarbon INFO @ 00:15:43]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.594853937625885, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8169838945827232, 'eval_runtime': 0.6053, 'eval_samples_per_second': 674.041, 'eval_steps_per_second': 11.564, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5708560943603516, 'eval_accuracy': 0.7009803921568627, 'eval_f1': 0.8117283950617284, 'eval_runtime': 0.5876, 'eval_samples_per_second': 694.399, 'eval_steps_per_second': 11.914, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5739648938179016, 'eval_accuracy': 0.7230392156862745, 'eval_f1': 0.8269525267993875, 'eval_runtime': 0.5838, 'eval_samples_per_second': 698.881, 'eval_steps_per_second': 11.991, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:15:51] Energy consumed for RAM : 0.000043 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:15:51] Energy consumed for all GPUs : 0.000119 kWh. Total GPU Power : 53.436144915809805 W\n",
            "[codecarbon INFO @ 00:15:51] Energy consumed for all CPUs : 0.000095 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:15:51] 0.000256 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5612186193466187, 'eval_accuracy': 0.7303921568627451, 'eval_f1': 0.8297213622291022, 'eval_runtime': 0.6101, 'eval_samples_per_second': 668.735, 'eval_steps_per_second': 11.473, 'epoch': 4.0}\n",
            "{'train_runtime': 7.3822, 'train_samples_per_second': 1987.477, 'train_steps_per_second': 31.427, 'train_loss': 0.5603954052102977, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:15:51] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:15:51] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:15:51] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:15:51] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:15:52] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5612186193466187, 'eval_accuracy': 0.7303921568627451, 'eval_f1': 0.8297213622291022, 'eval_runtime': 0.5994, 'eval_samples_per_second': 680.703, 'eval_steps_per_second': 11.679, 'epoch': 4.0}\n",
            "Progress: 15/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:15:53] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:15:53] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:15:53] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:15:53]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:15:53]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:15:53]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:15:53]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:15:53]   CPU count: 8\n",
            "[codecarbon INFO @ 00:15:53]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:15:53]   GPU count: 1\n",
            "[codecarbon INFO @ 00:15:53]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6062899231910706, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.5791, 'eval_samples_per_second': 704.58, 'eval_steps_per_second': 12.088, 'epoch': 1.0}\n",
            "{'eval_loss': 0.590184211730957, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8212703101920237, 'eval_runtime': 0.5954, 'eval_samples_per_second': 685.299, 'eval_steps_per_second': 11.758, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5828689932823181, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8143712574850299, 'eval_runtime': 0.611, 'eval_samples_per_second': 667.78, 'eval_steps_per_second': 11.457, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:16:01] Energy consumed for RAM : 0.000042 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:16:01] Energy consumed for all GPUs : 0.000120 kWh. Total GPU Power : 54.37444178773741 W\n",
            "[codecarbon INFO @ 00:16:01] Energy consumed for all CPUs : 0.000094 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:16:01] 0.000256 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5777505040168762, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8078668683812406, 'eval_runtime': 0.6264, 'eval_samples_per_second': 651.339, 'eval_steps_per_second': 11.175, 'epoch': 4.0}\n",
            "{'train_runtime': 7.3164, 'train_samples_per_second': 2005.365, 'train_steps_per_second': 31.71, 'train_loss': 0.5961887096536571, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:16:01] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:16:01] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:16:01] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:16:01] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:16:01] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5777505040168762, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8078668683812406, 'eval_runtime': 0.6069, 'eval_samples_per_second': 672.262, 'eval_steps_per_second': 11.534, 'epoch': 4.0}\n",
            "Progress: 16/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:16:02] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:16:02] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:16:03] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:16:03]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:16:03]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:16:03]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:16:03]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:16:03]   CPU count: 8\n",
            "[codecarbon INFO @ 00:16:03]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:16:03]   GPU count: 1\n",
            "[codecarbon INFO @ 00:16:03]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6178915500640869, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.6143, 'eval_samples_per_second': 664.223, 'eval_steps_per_second': 11.396, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6015655398368835, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.5868, 'eval_samples_per_second': 695.242, 'eval_steps_per_second': 11.928, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5944027900695801, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8181818181818182, 'eval_runtime': 0.593, 'eval_samples_per_second': 688.001, 'eval_steps_per_second': 11.804, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:16:11] Energy consumed for RAM : 0.000042 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:16:11] Energy consumed for all GPUs : 0.000121 kWh. Total GPU Power : 55.091081110862994 W\n",
            "[codecarbon INFO @ 00:16:11] Energy consumed for all CPUs : 0.000094 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:16:11] 0.000257 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5916686058044434, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8217967599410898, 'eval_runtime': 0.607, 'eval_samples_per_second': 672.182, 'eval_steps_per_second': 11.533, 'epoch': 4.0}\n",
            "{'train_runtime': 7.3314, 'train_samples_per_second': 2001.258, 'train_steps_per_second': 31.645, 'train_loss': 0.6165741229879445, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:16:11] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:16:11] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:16:11] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:16:11] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:16:11] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5916686058044434, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8217967599410898, 'eval_runtime': 0.5902, 'eval_samples_per_second': 691.233, 'eval_steps_per_second': 11.859, 'epoch': 4.0}\n",
            "Progress: 17/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:16:12] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:16:12] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:16:12] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:16:12]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:16:12]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:16:12]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:16:12]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:16:12]   CPU count: 8\n",
            "[codecarbon INFO @ 00:16:12]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:16:12]   GPU count: 1\n",
            "[codecarbon INFO @ 00:16:12]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6026797890663147, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.808446455505279, 'eval_runtime': 0.6508, 'eval_samples_per_second': 626.927, 'eval_steps_per_second': 6.146, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5666956901550293, 'eval_accuracy': 0.7205882352941176, 'eval_f1': 0.821875, 'eval_runtime': 0.5991, 'eval_samples_per_second': 681.035, 'eval_steps_per_second': 6.677, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5767462253570557, 'eval_accuracy': 0.7279411764705882, 'eval_f1': 0.8262910798122066, 'eval_runtime': 0.5977, 'eval_samples_per_second': 682.642, 'eval_steps_per_second': 6.693, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:16:20] Energy consumed for RAM : 0.000039 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:16:20] Energy consumed for all GPUs : 0.000111 kWh. Total GPU Power : 53.782004383176016 W\n",
            "[codecarbon INFO @ 00:16:20] Energy consumed for all CPUs : 0.000088 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:16:20] 0.000238 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5759289264678955, 'eval_accuracy': 0.7352941176470589, 'eval_f1': 0.8291139240506329, 'eval_runtime': 0.6036, 'eval_samples_per_second': 675.96, 'eval_steps_per_second': 6.627, 'epoch': 4.0}\n",
            "{'train_runtime': 6.8049, 'train_samples_per_second': 2156.091, 'train_steps_per_second': 17.047, 'train_loss': 0.5189324411852606, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:16:21] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:16:21] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:16:21] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:16:21] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:16:21] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5759289264678955, 'eval_accuracy': 0.7352941176470589, 'eval_f1': 0.8291139240506329, 'eval_runtime': 0.5963, 'eval_samples_per_second': 684.212, 'eval_steps_per_second': 6.708, 'epoch': 4.0}\n",
            "Progress: 18/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:16:22] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:16:22] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:16:22] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:16:22]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:16:22]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:16:22]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:16:22]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:16:22]   CPU count: 8\n",
            "[codecarbon INFO @ 00:16:22]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:16:22]   GPU count: 1\n",
            "[codecarbon INFO @ 00:16:22]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6038169264793396, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.5949, 'eval_samples_per_second': 685.803, 'eval_steps_per_second': 6.724, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5951903462409973, 'eval_accuracy': 0.7058823529411765, 'eval_f1': 0.8224852071005917, 'eval_runtime': 0.6141, 'eval_samples_per_second': 664.388, 'eval_steps_per_second': 6.514, 'epoch': 2.0}\n",
            "{'eval_loss': 0.579287052154541, 'eval_accuracy': 0.6911764705882353, 'eval_f1': 0.8090909090909091, 'eval_runtime': 0.5863, 'eval_samples_per_second': 695.922, 'eval_steps_per_second': 6.823, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:16:29] Energy consumed for RAM : 0.000039 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:16:29] Energy consumed for all GPUs : 0.000110 kWh. Total GPU Power : 53.99248576539583 W\n",
            "[codecarbon INFO @ 00:16:29] Energy consumed for all CPUs : 0.000087 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:16:29] 0.000236 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5748432874679565, 'eval_accuracy': 0.6911764705882353, 'eval_f1': 0.8073394495412844, 'eval_runtime': 0.5937, 'eval_samples_per_second': 687.215, 'eval_steps_per_second': 6.737, 'epoch': 4.0}\n",
            "{'train_runtime': 6.7148, 'train_samples_per_second': 2185.022, 'train_steps_per_second': 17.275, 'train_loss': 0.5897226004764952, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:16:30] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:16:30] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:16:30] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:16:30] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:16:30] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5748432874679565, 'eval_accuracy': 0.6911764705882353, 'eval_f1': 0.8073394495412844, 'eval_runtime': 0.5895, 'eval_samples_per_second': 692.055, 'eval_steps_per_second': 6.785, 'epoch': 4.0}\n",
            "Progress: 19/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:16:31] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:16:31] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:16:31] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:16:31]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:16:31]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:16:31]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:16:31]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:16:31]   CPU count: 8\n",
            "[codecarbon INFO @ 00:16:31]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:16:31]   GPU count: 1\n",
            "[codecarbon INFO @ 00:16:31]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6207587718963623, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.5966, 'eval_samples_per_second': 683.876, 'eval_steps_per_second': 6.705, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6050003170967102, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.5854, 'eval_samples_per_second': 697.014, 'eval_steps_per_second': 6.833, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5970742106437683, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8145985401459854, 'eval_runtime': 0.5885, 'eval_samples_per_second': 693.313, 'eval_steps_per_second': 6.797, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:16:39] Energy consumed for RAM : 0.000039 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:16:39] Energy consumed for all GPUs : 0.000111 kWh. Total GPU Power : 54.24267109660492 W\n",
            "[codecarbon INFO @ 00:16:39] Energy consumed for all CPUs : 0.000087 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:16:39] 0.000237 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5952083468437195, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8169838945827232, 'eval_runtime': 0.636, 'eval_samples_per_second': 641.532, 'eval_steps_per_second': 6.29, 'epoch': 4.0}\n",
            "{'train_runtime': 6.7519, 'train_samples_per_second': 2173.009, 'train_steps_per_second': 17.18, 'train_loss': 0.6204661007585197, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:16:39] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:16:39] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:16:39] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:16:39] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:16:39] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5952083468437195, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8169838945827232, 'eval_runtime': 0.6177, 'eval_samples_per_second': 660.552, 'eval_steps_per_second': 6.476, 'epoch': 4.0}\n",
            "Progress: 20/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:16:40] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:16:40] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:16:40] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:16:40]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:16:40]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:16:40]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:16:40]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:16:40]   CPU count: 8\n",
            "[codecarbon INFO @ 00:16:40]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:16:40]   GPU count: 1\n",
            "[codecarbon INFO @ 00:16:40]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6439599990844727, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.6004, 'eval_samples_per_second': 679.598, 'eval_steps_per_second': 6.663, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6185536980628967, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.585, 'eval_samples_per_second': 697.49, 'eval_steps_per_second': 6.838, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6116704344749451, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.6184, 'eval_samples_per_second': 659.762, 'eval_steps_per_second': 6.468, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:16:48] Energy consumed for RAM : 0.000039 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:16:48] Energy consumed for all GPUs : 0.000110 kWh. Total GPU Power : 54.49682027776501 W\n",
            "[codecarbon INFO @ 00:16:48] Energy consumed for all CPUs : 0.000086 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:16:48] 0.000235 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.609874427318573, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.596, 'eval_samples_per_second': 684.575, 'eval_steps_per_second': 6.712, 'epoch': 4.0}\n",
            "{'train_runtime': 6.6689, 'train_samples_per_second': 2200.078, 'train_steps_per_second': 17.394, 'train_loss': 0.6398460125101024, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:16:48] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:16:48] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:16:48] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:16:48] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:16:48] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.609874427318573, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.5822, 'eval_samples_per_second': 700.83, 'eval_steps_per_second': 6.871, 'epoch': 4.0}\n",
            "Progress: 21/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:16:50] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:16:50] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:16:50] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:16:50]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:16:50]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:16:50]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:16:50]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:16:50]   CPU count: 8\n",
            "[codecarbon INFO @ 00:16:50]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:16:50]   GPU count: 1\n",
            "[codecarbon INFO @ 00:16:50]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.604103684425354, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8036529680365296, 'eval_runtime': 0.7523, 'eval_samples_per_second': 542.344, 'eval_steps_per_second': 67.793, 'epoch': 1.0}\n",
            "{'loss': 0.5992, 'grad_norm': 4.903336048126221, 'learning_rate': 0.00021830065359477123, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.6167462468147278, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.7974481658692185, 'eval_runtime': 0.7349, 'eval_samples_per_second': 555.198, 'eval_steps_per_second': 69.4, 'epoch': 2.0}\n",
            "{'loss': 0.4839, 'grad_norm': 11.671659469604492, 'learning_rate': 0.00013660130718954247, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:17:05] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:17:05] Energy consumed for all GPUs : 0.000160 kWh. Total GPU Power : 38.342296613729204 W\n",
            "[codecarbon INFO @ 00:17:05] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:17:05] 0.000417 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.9141474962234497, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.7756521739130435, 'eval_runtime': 0.7515, 'eval_samples_per_second': 542.94, 'eval_steps_per_second': 67.868, 'epoch': 3.0}\n",
            "{'loss': 0.3345, 'grad_norm': 25.721920013427734, 'learning_rate': 5.4901960784313716e-05, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:17:14] Energy consumed for RAM : 0.000127 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:17:14] Energy consumed for all GPUs : 0.000254 kWh. Total GPU Power : 37.77377533118113 W\n",
            "[codecarbon INFO @ 00:17:14] Energy consumed for all CPUs : 0.000283 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:17:14] 0.000665 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 1.0532586574554443, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.7905405405405406, 'eval_runtime': 0.7529, 'eval_samples_per_second': 541.898, 'eval_steps_per_second': 67.737, 'epoch': 4.0}\n",
            "{'train_runtime': 23.3602, 'train_samples_per_second': 628.078, 'train_steps_per_second': 78.595, 'train_loss': 0.4297513941014774, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:17:14] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:17:14] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:17:14] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:17:14] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:17:14] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 1.0532586574554443, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.7905405405405406, 'eval_runtime': 0.7384, 'eval_samples_per_second': 552.529, 'eval_steps_per_second': 69.066, 'epoch': 4.0}\n",
            "Progress: 22/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:17:16] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:17:16] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:17:16] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:17:16]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:17:16]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:17:16]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:17:16]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:17:16]   CPU count: 8\n",
            "[codecarbon INFO @ 00:17:16]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:17:16]   GPU count: 1\n",
            "[codecarbon INFO @ 00:17:16]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.571905791759491, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8169440242057489, 'eval_runtime': 0.7552, 'eval_samples_per_second': 540.222, 'eval_steps_per_second': 67.528, 'epoch': 1.0}\n",
            "{'loss': 0.5884, 'grad_norm': 4.293759822845459, 'learning_rate': 7.276688453159042e-05, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.5654860734939575, 'eval_accuracy': 0.7352941176470589, 'eval_f1': 0.8285714285714286, 'eval_runtime': 0.7809, 'eval_samples_per_second': 522.476, 'eval_steps_per_second': 65.31, 'epoch': 2.0}\n",
            "{'loss': 0.4993, 'grad_norm': 8.675013542175293, 'learning_rate': 4.5533769063180834e-05, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:17:31] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:17:31] Energy consumed for all GPUs : 0.000158 kWh. Total GPU Power : 37.942136392195714 W\n",
            "[codecarbon INFO @ 00:17:31] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:17:31] 0.000415 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6270501613616943, 'eval_accuracy': 0.7352941176470589, 'eval_f1': 0.8296529968454258, 'eval_runtime': 0.7447, 'eval_samples_per_second': 547.878, 'eval_steps_per_second': 68.485, 'epoch': 3.0}\n",
            "{'loss': 0.4045, 'grad_norm': 26.807472229003906, 'learning_rate': 1.8300653594771242e-05, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:17:40] Energy consumed for RAM : 0.000127 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:17:40] Energy consumed for all GPUs : 0.000251 kWh. Total GPU Power : 37.92992235968498 W\n",
            "[codecarbon INFO @ 00:17:40] Energy consumed for all CPUs : 0.000281 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:17:40] 0.000659 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6656573414802551, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8325508607198748, 'eval_runtime': 0.7452, 'eval_samples_per_second': 547.487, 'eval_steps_per_second': 68.436, 'epoch': 4.0}\n",
            "{'train_runtime': 23.2372, 'train_samples_per_second': 631.4, 'train_steps_per_second': 79.011, 'train_loss': 0.47345523792674077, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:17:40] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:17:40] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:17:40] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:17:40] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:17:40] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6656573414802551, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8325508607198748, 'eval_runtime': 0.7466, 'eval_samples_per_second': 546.464, 'eval_steps_per_second': 68.308, 'epoch': 4.0}\n",
            "Progress: 23/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:17:41] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:17:41] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:17:41] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:17:41]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:17:41]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:17:41]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:17:41]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:17:41]   CPU count: 8\n",
            "[codecarbon INFO @ 00:17:41]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:17:41]   GPU count: 1\n",
            "[codecarbon INFO @ 00:17:41]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5733863711357117, 'eval_accuracy': 0.7009803921568627, 'eval_f1': 0.8134556574923547, 'eval_runtime': 0.7605, 'eval_samples_per_second': 536.495, 'eval_steps_per_second': 67.062, 'epoch': 1.0}\n",
            "{'loss': 0.6013, 'grad_norm': 4.323869228363037, 'learning_rate': 3.638344226579521e-05, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.5774785876274109, 'eval_accuracy': 0.7083333333333334, 'eval_f1': 0.8194233687405159, 'eval_runtime': 0.7698, 'eval_samples_per_second': 530.033, 'eval_steps_per_second': 66.254, 'epoch': 2.0}\n",
            "{'loss': 0.5438, 'grad_norm': 5.283394813537598, 'learning_rate': 2.2766884531590417e-05, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:17:57] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:17:57] Energy consumed for all GPUs : 0.000157 kWh. Total GPU Power : 37.74951274371112 W\n",
            "[codecarbon INFO @ 00:17:57] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:17:57] 0.000414 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5611313581466675, 'eval_accuracy': 0.7279411764705882, 'eval_f1': 0.8246445497630331, 'eval_runtime': 0.7785, 'eval_samples_per_second': 524.068, 'eval_steps_per_second': 65.509, 'epoch': 3.0}\n",
            "{'loss': 0.4849, 'grad_norm': 14.096569061279297, 'learning_rate': 9.150326797385621e-06, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:18:05] Energy consumed for RAM : 0.000127 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:18:05] Energy consumed for all GPUs : 0.000250 kWh. Total GPU Power : 37.664518432737815 W\n",
            "[codecarbon INFO @ 00:18:05] Energy consumed for all CPUs : 0.000282 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:18:05] 0.000659 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.587859570980072, 'eval_accuracy': 0.7279411764705882, 'eval_f1': 0.8268330733229329, 'eval_runtime': 0.7735, 'eval_samples_per_second': 527.456, 'eval_steps_per_second': 65.932, 'epoch': 4.0}\n",
            "{'train_runtime': 23.2179, 'train_samples_per_second': 631.927, 'train_steps_per_second': 79.077, 'train_loss': 0.5309766798497285, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:18:06] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:18:06] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:18:06] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:18:06] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:18:06] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.587859570980072, 'eval_accuracy': 0.7279411764705882, 'eval_f1': 0.8268330733229329, 'eval_runtime': 0.7539, 'eval_samples_per_second': 541.169, 'eval_steps_per_second': 67.646, 'epoch': 4.0}\n",
            "Progress: 24/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:18:07] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:18:07] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:18:07] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:18:07]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:18:07]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:18:07]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:18:07]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:18:07]   CPU count: 8\n",
            "[codecarbon INFO @ 00:18:07]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:18:07]   GPU count: 1\n",
            "[codecarbon INFO @ 00:18:07]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5838139653205872, 'eval_accuracy': 0.7009803921568627, 'eval_f1': 0.8184523809523809, 'eval_runtime': 0.7348, 'eval_samples_per_second': 555.29, 'eval_steps_per_second': 69.411, 'epoch': 1.0}\n",
            "{'loss': 0.6134, 'grad_norm': 2.5178942680358887, 'learning_rate': 2.1830065359477124e-05, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.5830901861190796, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8180451127819549, 'eval_runtime': 0.8195, 'eval_samples_per_second': 497.886, 'eval_steps_per_second': 62.236, 'epoch': 2.0}\n",
            "{'loss': 0.5689, 'grad_norm': 4.079008102416992, 'learning_rate': 1.366013071895425e-05, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:18:23] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:18:23] Energy consumed for all GPUs : 0.000158 kWh. Total GPU Power : 37.99574314236405 W\n",
            "[codecarbon INFO @ 00:18:23] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:18:23] 0.000415 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.568699836730957, 'eval_accuracy': 0.7132352941176471, 'eval_f1': 0.8197226502311248, 'eval_runtime': 0.7522, 'eval_samples_per_second': 542.413, 'eval_steps_per_second': 67.802, 'epoch': 3.0}\n",
            "{'loss': 0.5302, 'grad_norm': 6.041450023651123, 'learning_rate': 5.490196078431373e-06, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:18:31] Energy consumed for RAM : 0.000126 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:18:31] Energy consumed for all GPUs : 0.000250 kWh. Total GPU Power : 37.60303711840397 W\n",
            "[codecarbon INFO @ 00:18:31] Energy consumed for all CPUs : 0.000280 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:18:31] 0.000656 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5771942734718323, 'eval_accuracy': 0.7107843137254902, 'eval_f1': 0.8195718654434251, 'eval_runtime': 0.7626, 'eval_samples_per_second': 535.041, 'eval_steps_per_second': 66.88, 'epoch': 4.0}\n",
            "{'train_runtime': 23.1583, 'train_samples_per_second': 633.551, 'train_steps_per_second': 79.28, 'train_loss': 0.5637553262814458, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:18:32] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:18:32] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:18:32] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:18:32] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:18:32] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5771942734718323, 'eval_accuracy': 0.7107843137254902, 'eval_f1': 0.8195718654434251, 'eval_runtime': 0.7449, 'eval_samples_per_second': 547.755, 'eval_steps_per_second': 68.469, 'epoch': 4.0}\n",
            "Progress: 25/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:18:33] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:18:33] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:18:33] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:18:33]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:18:33]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:18:33]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:18:33]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:18:33]   CPU count: 8\n",
            "[codecarbon INFO @ 00:18:33]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:18:33]   GPU count: 1\n",
            "[codecarbon INFO @ 00:18:33]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5624045133590698, 'eval_accuracy': 0.7230392156862745, 'eval_f1': 0.8231611893583725, 'eval_runtime': 0.6555, 'eval_samples_per_second': 622.437, 'eval_steps_per_second': 39.665, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5531349778175354, 'eval_accuracy': 0.7328431372549019, 'eval_f1': 0.8256, 'eval_runtime': 0.6454, 'eval_samples_per_second': 632.174, 'eval_steps_per_second': 40.286, 'epoch': 2.0}\n",
            "{'loss': 0.5239, 'grad_norm': 15.012598991394043, 'learning_rate': 0.00013695652173913042, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.590812087059021, 'eval_accuracy': 0.7401960784313726, 'eval_f1': 0.8221476510067114, 'eval_runtime': 0.6893, 'eval_samples_per_second': 591.88, 'eval_steps_per_second': 37.718, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:18:48] Energy consumed for RAM : 0.000076 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:18:48] Energy consumed for all GPUs : 0.000163 kWh. Total GPU Power : 40.81579958623773 W\n",
            "[codecarbon INFO @ 00:18:48] Energy consumed for all CPUs : 0.000170 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:18:48] 0.000410 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7519146800041199, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8243021346469622, 'eval_runtime': 0.6775, 'eval_samples_per_second': 602.175, 'eval_steps_per_second': 38.374, 'epoch': 4.0}\n",
            "{'train_runtime': 13.8008, 'train_samples_per_second': 1063.126, 'train_steps_per_second': 66.663, 'train_loss': 0.40669037362803584, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:18:49] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:18:49] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:18:49] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:18:49] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:18:49] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7519146800041199, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8243021346469622, 'eval_runtime': 0.6604, 'eval_samples_per_second': 617.762, 'eval_steps_per_second': 39.367, 'epoch': 4.0}\n",
            "Progress: 26/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:18:50] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:18:50] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:18:50] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:18:50]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:18:50]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:18:50]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:18:50]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:18:50]   CPU count: 8\n",
            "[codecarbon INFO @ 00:18:50]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:18:50]   GPU count: 1\n",
            "[codecarbon INFO @ 00:18:50]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.564354419708252, 'eval_accuracy': 0.7132352941176471, 'eval_f1': 0.8180404354587869, 'eval_runtime': 0.6638, 'eval_samples_per_second': 614.637, 'eval_steps_per_second': 39.168, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5474852919578552, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.831496062992126, 'eval_runtime': 0.6766, 'eval_samples_per_second': 602.985, 'eval_steps_per_second': 38.426, 'epoch': 2.0}\n",
            "{'loss': 0.5577, 'grad_norm': 6.763742923736572, 'learning_rate': 4.565217391304348e-05, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.5569795966148376, 'eval_accuracy': 0.7426470588235294, 'eval_f1': 0.8330683624801272, 'eval_runtime': 0.6666, 'eval_samples_per_second': 612.034, 'eval_steps_per_second': 39.002, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:19:04] Energy consumed for RAM : 0.000078 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:19:04] Energy consumed for all GPUs : 0.000165 kWh. Total GPU Power : 40.740441395643636 W\n",
            "[codecarbon INFO @ 00:19:04] Energy consumed for all CPUs : 0.000172 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:19:04] 0.000415 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5896832346916199, 'eval_accuracy': 0.7328431372549019, 'eval_f1': 0.8299531981279251, 'eval_runtime': 0.8265, 'eval_samples_per_second': 493.67, 'eval_steps_per_second': 31.459, 'epoch': 4.0}\n",
            "{'train_runtime': 13.9916, 'train_samples_per_second': 1048.63, 'train_steps_per_second': 65.754, 'train_loss': 0.5020559891410495, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:19:05] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:19:05] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:19:05] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:19:05] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:19:05] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5896832346916199, 'eval_accuracy': 0.7328431372549019, 'eval_f1': 0.8299531981279251, 'eval_runtime': 0.6762, 'eval_samples_per_second': 603.377, 'eval_steps_per_second': 38.45, 'epoch': 4.0}\n",
            "Progress: 27/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:19:06] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:19:06] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:19:06] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:19:06]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:19:06]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:19:06]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:19:06]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:19:06]   CPU count: 8\n",
            "[codecarbon INFO @ 00:19:06]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:19:06]   GPU count: 1\n",
            "[codecarbon INFO @ 00:19:06]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5816411972045898, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8095952023988006, 'eval_runtime': 0.6642, 'eval_samples_per_second': 614.292, 'eval_steps_per_second': 39.146, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5781240463256836, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8185907046476761, 'eval_runtime': 0.6542, 'eval_samples_per_second': 623.637, 'eval_steps_per_second': 39.742, 'epoch': 2.0}\n",
            "{'loss': 0.5845, 'grad_norm': 4.170251846313477, 'learning_rate': 2.282608695652174e-05, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.568314790725708, 'eval_accuracy': 0.7083333333333334, 'eval_f1': 0.8183206106870229, 'eval_runtime': 0.6967, 'eval_samples_per_second': 585.645, 'eval_steps_per_second': 37.321, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:19:21] Energy consumed for RAM : 0.000077 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:19:21] Energy consumed for all GPUs : 0.000165 kWh. Total GPU Power : 41.12954232155443 W\n",
            "[codecarbon INFO @ 00:19:21] Energy consumed for all CPUs : 0.000171 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:19:21] 0.000413 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.568650484085083, 'eval_accuracy': 0.7205882352941176, 'eval_f1': 0.8246153846153846, 'eval_runtime': 0.6979, 'eval_samples_per_second': 584.631, 'eval_steps_per_second': 37.256, 'epoch': 4.0}\n",
            "{'train_runtime': 13.832, 'train_samples_per_second': 1060.728, 'train_steps_per_second': 66.512, 'train_loss': 0.5531564961309018, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:19:22] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:19:22] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:19:22] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:19:22] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:19:22] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.568650484085083, 'eval_accuracy': 0.7205882352941176, 'eval_f1': 0.8246153846153846, 'eval_runtime': 0.6712, 'eval_samples_per_second': 607.881, 'eval_steps_per_second': 38.737, 'epoch': 4.0}\n",
            "Progress: 28/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:19:23] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:19:23] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:19:23] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:19:23]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:19:23]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:19:23]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:19:23]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:19:23]   CPU count: 8\n",
            "[codecarbon INFO @ 00:19:23]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:19:23]   GPU count: 1\n",
            "[codecarbon INFO @ 00:19:23]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5934128761291504, 'eval_accuracy': 0.6985294117647058, 'eval_f1': 0.8193832599118943, 'eval_runtime': 0.677, 'eval_samples_per_second': 602.62, 'eval_steps_per_second': 38.402, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5834196209907532, 'eval_accuracy': 0.6985294117647058, 'eval_f1': 0.8161434977578476, 'eval_runtime': 0.637, 'eval_samples_per_second': 640.459, 'eval_steps_per_second': 40.814, 'epoch': 2.0}\n",
            "{'loss': 0.6021, 'grad_norm': 2.227717161178589, 'learning_rate': 1.3695652173913042e-05, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.574123740196228, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8114630467571644, 'eval_runtime': 0.7, 'eval_samples_per_second': 582.861, 'eval_steps_per_second': 37.143, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:19:37] Energy consumed for RAM : 0.000077 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:19:37] Energy consumed for all GPUs : 0.000164 kWh. Total GPU Power : 40.97780623943654 W\n",
            "[codecarbon INFO @ 00:19:37] Energy consumed for all CPUs : 0.000170 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:19:37] 0.000411 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5735155940055847, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8126888217522659, 'eval_runtime': 0.6705, 'eval_samples_per_second': 608.481, 'eval_steps_per_second': 38.776, 'epoch': 4.0}\n",
            "{'train_runtime': 13.8043, 'train_samples_per_second': 1062.856, 'train_steps_per_second': 66.646, 'train_loss': 0.580059698353643, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:19:38] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:19:38] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:19:38] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:19:38] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:19:38] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5735155940055847, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8126888217522659, 'eval_runtime': 0.6828, 'eval_samples_per_second': 597.513, 'eval_steps_per_second': 38.077, 'epoch': 4.0}\n",
            "Progress: 29/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:19:39] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:19:39] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:19:39] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:19:39]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:19:39]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:19:39]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:19:39]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:19:39]   CPU count: 8\n",
            "[codecarbon INFO @ 00:19:39]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:19:39]   GPU count: 1\n",
            "[codecarbon INFO @ 00:19:39]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5496113896369934, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.831496062992126, 'eval_runtime': 0.6132, 'eval_samples_per_second': 665.392, 'eval_steps_per_second': 21.201, 'epoch': 1.0}\n",
            "{'eval_loss': 0.552695095539093, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8309636650868878, 'eval_runtime': 0.6357, 'eval_samples_per_second': 641.793, 'eval_steps_per_second': 20.449, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6253054141998291, 'eval_accuracy': 0.7450980392156863, 'eval_f1': 0.8354430379746836, 'eval_runtime': 0.6119, 'eval_samples_per_second': 666.818, 'eval_steps_per_second': 21.247, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:19:49] Energy consumed for RAM : 0.000053 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:19:49] Energy consumed for all GPUs : 0.000139 kWh. Total GPU Power : 50.40737800984371 W\n",
            "[codecarbon INFO @ 00:19:49] Energy consumed for all CPUs : 0.000117 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:19:49] 0.000308 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6537364721298218, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8304278922345484, 'eval_runtime': 0.6395, 'eval_samples_per_second': 637.974, 'eval_steps_per_second': 20.328, 'epoch': 4.0}\n",
            "{'train_runtime': 9.2952, 'train_samples_per_second': 1578.457, 'train_steps_per_second': 49.488, 'train_loss': 0.43501543791397757, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:19:50] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:19:50] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:19:50] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:19:50] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:19:50] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6537364721298218, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8304278922345484, 'eval_runtime': 0.6219, 'eval_samples_per_second': 656.083, 'eval_steps_per_second': 20.905, 'epoch': 4.0}\n",
            "Progress: 30/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:19:51] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:19:51] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:19:51] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:19:51]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:19:51]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:19:51]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:19:51]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:19:51]   CPU count: 8\n",
            "[codecarbon INFO @ 00:19:51]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:19:51]   GPU count: 1\n",
            "[codecarbon INFO @ 00:19:51]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.585704505443573, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.81089258698941, 'eval_runtime': 0.6561, 'eval_samples_per_second': 621.819, 'eval_steps_per_second': 19.813, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5598652958869934, 'eval_accuracy': 0.7181372549019608, 'eval_f1': 0.8205928237129485, 'eval_runtime': 0.6347, 'eval_samples_per_second': 642.835, 'eval_steps_per_second': 20.482, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5700249075889587, 'eval_accuracy': 0.7132352941176471, 'eval_f1': 0.8186046511627907, 'eval_runtime': 0.6724, 'eval_samples_per_second': 606.808, 'eval_steps_per_second': 19.335, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:20:01] Energy consumed for RAM : 0.000054 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:20:01] Energy consumed for all GPUs : 0.000140 kWh. Total GPU Power : 49.203729953255824 W\n",
            "[codecarbon INFO @ 00:20:01] Energy consumed for all CPUs : 0.000121 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:20:01] 0.000314 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5717409253120422, 'eval_accuracy': 0.7254901960784313, 'eval_f1': 0.8255451713395638, 'eval_runtime': 0.6396, 'eval_samples_per_second': 637.885, 'eval_steps_per_second': 20.325, 'epoch': 4.0}\n",
            "{'train_runtime': 9.4465, 'train_samples_per_second': 1553.175, 'train_steps_per_second': 48.695, 'train_loss': 0.5322120666503907, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:20:02] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:20:02] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:20:02] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:20:02] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:20:02] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5717409253120422, 'eval_accuracy': 0.7254901960784313, 'eval_f1': 0.8255451713395638, 'eval_runtime': 0.6202, 'eval_samples_per_second': 657.825, 'eval_steps_per_second': 20.96, 'epoch': 4.0}\n",
            "Progress: 31/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:20:03] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:20:03] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:20:03] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:20:03]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:20:03]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:20:03]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:20:03]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:20:03]   CPU count: 8\n",
            "[codecarbon INFO @ 00:20:03]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:20:03]   GPU count: 1\n",
            "[codecarbon INFO @ 00:20:03]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5961236953735352, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8169838945827232, 'eval_runtime': 0.6229, 'eval_samples_per_second': 655.044, 'eval_steps_per_second': 20.871, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5710234045982361, 'eval_accuracy': 0.7058823529411765, 'eval_f1': 0.817629179331307, 'eval_runtime': 0.6003, 'eval_samples_per_second': 679.674, 'eval_steps_per_second': 21.656, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5729517340660095, 'eval_accuracy': 0.7083333333333334, 'eval_f1': 0.8199697428139183, 'eval_runtime': 0.6362, 'eval_samples_per_second': 641.316, 'eval_steps_per_second': 20.434, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:20:13] Energy consumed for RAM : 0.000052 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:20:13] Energy consumed for all GPUs : 0.000138 kWh. Total GPU Power : 50.66552861051342 W\n",
            "[codecarbon INFO @ 00:20:13] Energy consumed for all CPUs : 0.000116 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:20:13] 0.000307 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.56805819272995, 'eval_accuracy': 0.7107843137254902, 'eval_f1': 0.8201219512195121, 'eval_runtime': 0.6255, 'eval_samples_per_second': 652.317, 'eval_steps_per_second': 20.785, 'epoch': 4.0}\n",
            "{'train_runtime': 9.2283, 'train_samples_per_second': 1589.899, 'train_steps_per_second': 49.847, 'train_loss': 0.5740605893342391, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:20:14] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:20:14] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:20:14] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:20:14] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:20:14] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.56805819272995, 'eval_accuracy': 0.7107843137254902, 'eval_f1': 0.8201219512195121, 'eval_runtime': 0.6135, 'eval_samples_per_second': 665.013, 'eval_steps_per_second': 21.189, 'epoch': 4.0}\n",
            "Progress: 32/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:20:15] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:20:15] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:20:15] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:20:15]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:20:15]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:20:15]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:20:15]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:20:15]   CPU count: 8\n",
            "[codecarbon INFO @ 00:20:15]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:20:15]   GPU count: 1\n",
            "[codecarbon INFO @ 00:20:15]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6053450703620911, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.6337, 'eval_samples_per_second': 643.788, 'eval_steps_per_second': 20.513, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5885691046714783, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8212703101920237, 'eval_runtime': 0.6168, 'eval_samples_per_second': 661.482, 'eval_steps_per_second': 21.077, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5840325355529785, 'eval_accuracy': 0.6985294117647058, 'eval_f1': 0.8166915052160953, 'eval_runtime': 0.6249, 'eval_samples_per_second': 652.933, 'eval_steps_per_second': 20.804, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:20:25] Energy consumed for RAM : 0.000053 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:20:25] Energy consumed for all GPUs : 0.000139 kWh. Total GPU Power : 50.42852931355394 W\n",
            "[codecarbon INFO @ 00:20:25] Energy consumed for all CPUs : 0.000117 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:20:25] 0.000309 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5790587663650513, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8138138138138138, 'eval_runtime': 0.6107, 'eval_samples_per_second': 668.108, 'eval_steps_per_second': 21.288, 'epoch': 4.0}\n",
            "{'train_runtime': 9.3372, 'train_samples_per_second': 1571.355, 'train_steps_per_second': 49.265, 'train_loss': 0.5975138125212296, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:20:26] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:20:26] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:20:26] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:20:26] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:20:26] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5790587663650513, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8138138138138138, 'eval_runtime': 0.6084, 'eval_samples_per_second': 670.613, 'eval_steps_per_second': 21.368, 'epoch': 4.0}\n",
            "Progress: 33/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:20:27] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:20:27] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:20:27] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:20:27]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:20:27]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:20:27]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:20:27]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:20:27]   CPU count: 8\n",
            "[codecarbon INFO @ 00:20:27]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:20:27]   GPU count: 1\n",
            "[codecarbon INFO @ 00:20:27]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5753757357597351, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8132530120481928, 'eval_runtime': 0.6159, 'eval_samples_per_second': 662.406, 'eval_steps_per_second': 11.365, 'epoch': 1.0}\n",
            "{'eval_loss': 0.550995409488678, 'eval_accuracy': 0.7328431372549019, 'eval_f1': 0.8304821150855366, 'eval_runtime': 0.6086, 'eval_samples_per_second': 670.377, 'eval_steps_per_second': 11.502, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5720232129096985, 'eval_accuracy': 0.7598039215686274, 'eval_f1': 0.8434504792332268, 'eval_runtime': 0.6036, 'eval_samples_per_second': 675.973, 'eval_steps_per_second': 11.598, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:20:35] Energy consumed for RAM : 0.000042 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:20:35] Energy consumed for all GPUs : 0.000121 kWh. Total GPU Power : 54.722601512239294 W\n",
            "[codecarbon INFO @ 00:20:35] Energy consumed for all CPUs : 0.000094 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:20:35] 0.000258 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5971444249153137, 'eval_accuracy': 0.75, 'eval_f1': 0.8386075949367089, 'eval_runtime': 0.6156, 'eval_samples_per_second': 662.792, 'eval_steps_per_second': 11.371, 'epoch': 4.0}\n",
            "{'train_runtime': 7.3785, 'train_samples_per_second': 1988.471, 'train_steps_per_second': 31.443, 'train_loss': 0.4707464020827721, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:20:36] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:20:36] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:20:36] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:20:36] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:20:36] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5971444249153137, 'eval_accuracy': 0.75, 'eval_f1': 0.8386075949367089, 'eval_runtime': 0.6431, 'eval_samples_per_second': 634.381, 'eval_steps_per_second': 10.884, 'epoch': 4.0}\n",
            "Progress: 34/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:20:37] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:20:37] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:20:37] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:20:37]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:20:37]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:20:37]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:20:37]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:20:37]   CPU count: 8\n",
            "[codecarbon INFO @ 00:20:37]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:20:37]   GPU count: 1\n",
            "[codecarbon INFO @ 00:20:37]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.594853937625885, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8169838945827232, 'eval_runtime': 0.6099, 'eval_samples_per_second': 668.959, 'eval_steps_per_second': 11.477, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5708560943603516, 'eval_accuracy': 0.7009803921568627, 'eval_f1': 0.8117283950617284, 'eval_runtime': 0.754, 'eval_samples_per_second': 541.138, 'eval_steps_per_second': 9.284, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5739648938179016, 'eval_accuracy': 0.7230392156862745, 'eval_f1': 0.8269525267993875, 'eval_runtime': 0.73, 'eval_samples_per_second': 558.884, 'eval_steps_per_second': 9.589, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:20:45] Energy consumed for RAM : 0.000044 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:20:45] Energy consumed for all GPUs : 0.000129 kWh. Total GPU Power : 56.17772554311377 W\n",
            "[codecarbon INFO @ 00:20:45] Energy consumed for all CPUs : 0.000097 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:20:45] 0.000270 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5612186193466187, 'eval_accuracy': 0.7303921568627451, 'eval_f1': 0.8297213622291022, 'eval_runtime': 0.6067, 'eval_samples_per_second': 672.538, 'eval_steps_per_second': 11.539, 'epoch': 4.0}\n",
            "{'train_runtime': 7.6307, 'train_samples_per_second': 1922.753, 'train_steps_per_second': 30.403, 'train_loss': 0.5603954052102977, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:20:46] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:20:46] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:20:46] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:20:46] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:20:46] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5612186193466187, 'eval_accuracy': 0.7303921568627451, 'eval_f1': 0.8297213622291022, 'eval_runtime': 0.6008, 'eval_samples_per_second': 679.107, 'eval_steps_per_second': 11.651, 'epoch': 4.0}\n",
            "Progress: 35/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:20:47] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:20:47] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:20:47] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:20:47]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:20:47]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:20:47]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:20:47]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:20:47]   CPU count: 8\n",
            "[codecarbon INFO @ 00:20:47]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:20:47]   GPU count: 1\n",
            "[codecarbon INFO @ 00:20:47]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6062899231910706, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.6294, 'eval_samples_per_second': 648.227, 'eval_steps_per_second': 11.122, 'epoch': 1.0}\n",
            "{'eval_loss': 0.590184211730957, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8212703101920237, 'eval_runtime': 0.5975, 'eval_samples_per_second': 682.815, 'eval_steps_per_second': 11.715, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5828689932823181, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8143712574850299, 'eval_runtime': 0.581, 'eval_samples_per_second': 702.256, 'eval_steps_per_second': 12.049, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:20:55] Energy consumed for RAM : 0.000042 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:20:55] Energy consumed for all GPUs : 0.000122 kWh. Total GPU Power : 54.75711233995812 W\n",
            "[codecarbon INFO @ 00:20:55] Energy consumed for all CPUs : 0.000094 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:20:55] 0.000258 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5777505040168762, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8078668683812406, 'eval_runtime': 0.6533, 'eval_samples_per_second': 624.475, 'eval_steps_per_second': 10.714, 'epoch': 4.0}\n",
            "{'train_runtime': 7.3666, 'train_samples_per_second': 1991.691, 'train_steps_per_second': 31.493, 'train_loss': 0.5961887096536571, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:20:56] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:20:56] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:20:56] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:20:56] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:20:56] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5777505040168762, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8078668683812406, 'eval_runtime': 0.6205, 'eval_samples_per_second': 657.505, 'eval_steps_per_second': 11.281, 'epoch': 4.0}\n",
            "Progress: 36/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:20:57] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:20:57] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:20:57] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:20:57]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:20:57]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:20:57]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:20:57]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:20:57]   CPU count: 8\n",
            "[codecarbon INFO @ 00:20:57]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:20:57]   GPU count: 1\n",
            "[codecarbon INFO @ 00:20:57]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6178915500640869, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.606, 'eval_samples_per_second': 673.253, 'eval_steps_per_second': 11.551, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6015655398368835, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.6013, 'eval_samples_per_second': 678.502, 'eval_steps_per_second': 11.641, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5944027900695801, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8181818181818182, 'eval_runtime': 0.5946, 'eval_samples_per_second': 686.17, 'eval_steps_per_second': 11.773, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:21:05] Energy consumed for RAM : 0.000042 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:21:05] Energy consumed for all GPUs : 0.000121 kWh. Total GPU Power : 54.79982073105826 W\n",
            "[codecarbon INFO @ 00:21:05] Energy consumed for all CPUs : 0.000094 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:21:05] 0.000257 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5916686058044434, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8217967599410898, 'eval_runtime': 0.5925, 'eval_samples_per_second': 688.555, 'eval_steps_per_second': 11.813, 'epoch': 4.0}\n",
            "{'train_runtime': 7.3403, 'train_samples_per_second': 1998.828, 'train_steps_per_second': 31.606, 'train_loss': 0.6165741229879445, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:21:06] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:21:06] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:21:06] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:21:06] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:21:06] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5916686058044434, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8217967599410898, 'eval_runtime': 0.7808, 'eval_samples_per_second': 522.55, 'eval_steps_per_second': 8.965, 'epoch': 4.0}\n",
            "Progress: 37/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:21:07] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:21:07] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:21:07] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:21:07]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:21:07]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:21:07]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:21:07]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:21:07]   CPU count: 8\n",
            "[codecarbon INFO @ 00:21:07]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:21:07]   GPU count: 1\n",
            "[codecarbon INFO @ 00:21:07]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6026797890663147, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.808446455505279, 'eval_runtime': 0.5904, 'eval_samples_per_second': 691.044, 'eval_steps_per_second': 6.775, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5666956901550293, 'eval_accuracy': 0.7205882352941176, 'eval_f1': 0.821875, 'eval_runtime': 0.6016, 'eval_samples_per_second': 678.206, 'eval_steps_per_second': 6.649, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5767462253570557, 'eval_accuracy': 0.7279411764705882, 'eval_f1': 0.8262910798122066, 'eval_runtime': 0.598, 'eval_samples_per_second': 682.325, 'eval_steps_per_second': 6.689, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:21:14] Energy consumed for RAM : 0.000039 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:21:14] Energy consumed for all GPUs : 0.000109 kWh. Total GPU Power : 53.43069966302736 W\n",
            "[codecarbon INFO @ 00:21:14] Energy consumed for all CPUs : 0.000087 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:21:14] 0.000234 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5759289264678955, 'eval_accuracy': 0.7352941176470589, 'eval_f1': 0.8291139240506329, 'eval_runtime': 0.6463, 'eval_samples_per_second': 631.327, 'eval_steps_per_second': 6.189, 'epoch': 4.0}\n",
            "{'train_runtime': 6.7216, 'train_samples_per_second': 2182.798, 'train_steps_per_second': 17.258, 'train_loss': 0.5189324411852606, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:21:15] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:21:15] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:21:15] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:21:15] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:21:15] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5759289264678955, 'eval_accuracy': 0.7352941176470589, 'eval_f1': 0.8291139240506329, 'eval_runtime': 0.5841, 'eval_samples_per_second': 698.555, 'eval_steps_per_second': 6.849, 'epoch': 4.0}\n",
            "Progress: 38/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:21:16] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:21:16] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:21:16] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:21:16]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:21:16]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:21:16]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:21:16]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:21:16]   CPU count: 8\n",
            "[codecarbon INFO @ 00:21:16]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:21:16]   GPU count: 1\n",
            "[codecarbon INFO @ 00:21:16]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6038169264793396, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.633, 'eval_samples_per_second': 644.577, 'eval_steps_per_second': 6.319, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5951903462409973, 'eval_accuracy': 0.7058823529411765, 'eval_f1': 0.8224852071005917, 'eval_runtime': 0.646, 'eval_samples_per_second': 631.566, 'eval_steps_per_second': 6.192, 'epoch': 2.0}\n",
            "{'eval_loss': 0.579287052154541, 'eval_accuracy': 0.6911764705882353, 'eval_f1': 0.8090909090909091, 'eval_runtime': 0.7897, 'eval_samples_per_second': 516.639, 'eval_steps_per_second': 5.065, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:21:24] Energy consumed for RAM : 0.000040 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:21:24] Energy consumed for all GPUs : 0.000112 kWh. Total GPU Power : 53.33854656373786 W\n",
            "[codecarbon INFO @ 00:21:24] Energy consumed for all CPUs : 0.000089 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:21:24] 0.000242 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5748432874679565, 'eval_accuracy': 0.6911764705882353, 'eval_f1': 0.8073394495412844, 'eval_runtime': 0.6008, 'eval_samples_per_second': 679.093, 'eval_steps_per_second': 6.658, 'epoch': 4.0}\n",
            "{'train_runtime': 6.9582, 'train_samples_per_second': 2108.591, 'train_steps_per_second': 16.671, 'train_loss': 0.5897226004764952, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:21:24] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:21:24] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:21:24] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:21:24] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:21:24] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5748432874679565, 'eval_accuracy': 0.6911764705882353, 'eval_f1': 0.8073394495412844, 'eval_runtime': 0.6068, 'eval_samples_per_second': 672.372, 'eval_steps_per_second': 6.592, 'epoch': 4.0}\n",
            "Progress: 39/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:21:25] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:21:25] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:21:25] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:21:25]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:21:25]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:21:25]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:21:25]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:21:25]   CPU count: 8\n",
            "[codecarbon INFO @ 00:21:25]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:21:25]   GPU count: 1\n",
            "[codecarbon INFO @ 00:21:25]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6207587718963623, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.5947, 'eval_samples_per_second': 686.096, 'eval_steps_per_second': 6.726, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6050003170967102, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.5828, 'eval_samples_per_second': 700.034, 'eval_steps_per_second': 6.863, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5970742106437683, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8145985401459854, 'eval_runtime': 0.5828, 'eval_samples_per_second': 700.097, 'eval_steps_per_second': 6.864, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:21:33] Energy consumed for RAM : 0.000038 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:21:33] Energy consumed for all GPUs : 0.000108 kWh. Total GPU Power : 53.72493918695563 W\n",
            "[codecarbon INFO @ 00:21:33] Energy consumed for all CPUs : 0.000085 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:21:33] 0.000232 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5952083468437195, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8169838945827232, 'eval_runtime': 0.5942, 'eval_samples_per_second': 686.671, 'eval_steps_per_second': 6.732, 'epoch': 4.0}\n",
            "{'train_runtime': 6.6345, 'train_samples_per_second': 2211.474, 'train_steps_per_second': 17.484, 'train_loss': 0.6204661007585197, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:21:33] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:21:33] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:21:33] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:21:33] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:21:33] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5952083468437195, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8169838945827232, 'eval_runtime': 0.5796, 'eval_samples_per_second': 703.959, 'eval_steps_per_second': 6.902, 'epoch': 4.0}\n",
            "Progress: 40/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:21:35] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:21:35] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:21:35] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:21:35]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:21:35]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:21:35]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:21:35]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:21:35]   CPU count: 8\n",
            "[codecarbon INFO @ 00:21:35]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:21:35]   GPU count: 1\n",
            "[codecarbon INFO @ 00:21:35]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6439599990844727, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.6019, 'eval_samples_per_second': 677.854, 'eval_steps_per_second': 6.646, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6185536980628967, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.5978, 'eval_samples_per_second': 682.502, 'eval_steps_per_second': 6.691, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6116704344749451, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.5929, 'eval_samples_per_second': 688.193, 'eval_steps_per_second': 6.747, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:21:42] Energy consumed for RAM : 0.000039 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:21:42] Energy consumed for all GPUs : 0.000110 kWh. Total GPU Power : 53.91148737448163 W\n",
            "[codecarbon INFO @ 00:21:42] Energy consumed for all CPUs : 0.000087 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:21:42] 0.000236 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.609874427318573, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.5983, 'eval_samples_per_second': 681.981, 'eval_steps_per_second': 6.686, 'epoch': 4.0}\n",
            "{'train_runtime': 6.7214, 'train_samples_per_second': 2182.885, 'train_steps_per_second': 17.258, 'train_loss': 0.6398460125101024, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:21:43] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:21:43] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:21:43] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:21:43] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:21:43] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.609874427318573, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.5848, 'eval_samples_per_second': 697.664, 'eval_steps_per_second': 6.84, 'epoch': 4.0}\n",
            "Progress: 41/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:21:44] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:21:44] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:21:44] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:21:44]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:21:44]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:21:44]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:21:44]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:21:44]   CPU count: 8\n",
            "[codecarbon INFO @ 00:21:44]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:21:44]   GPU count: 1\n",
            "[codecarbon INFO @ 00:21:44]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5731094479560852, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8163884673748103, 'eval_runtime': 0.7354, 'eval_samples_per_second': 554.831, 'eval_steps_per_second': 69.354, 'epoch': 1.0}\n",
            "{'loss': 0.602, 'grad_norm': 1.9797930717468262, 'learning_rate': 0.00021830065359477123, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.5846077799797058, 'eval_accuracy': 0.7009803921568627, 'eval_f1': 0.8057324840764332, 'eval_runtime': 0.7823, 'eval_samples_per_second': 521.536, 'eval_steps_per_second': 65.192, 'epoch': 2.0}\n",
            "{'loss': 0.4747, 'grad_norm': 2.5506746768951416, 'learning_rate': 0.00013660130718954247, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:21:59] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:21:59] Energy consumed for all GPUs : 0.000160 kWh. Total GPU Power : 38.32216053146261 W\n",
            "[codecarbon INFO @ 00:21:59] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:21:59] 0.000417 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.8188014030456543, 'eval_accuracy': 0.7083333333333334, 'eval_f1': 0.7937608318890814, 'eval_runtime': 0.7688, 'eval_samples_per_second': 530.705, 'eval_steps_per_second': 66.338, 'epoch': 3.0}\n",
            "{'loss': 0.3085, 'grad_norm': 38.36646270751953, 'learning_rate': 5.4901960784313716e-05, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:22:08] Energy consumed for RAM : 0.000126 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:22:08] Energy consumed for all GPUs : 0.000252 kWh. Total GPU Power : 38.01916034465728 W\n",
            "[codecarbon INFO @ 00:22:08] Energy consumed for all CPUs : 0.000281 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:22:08] 0.000659 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 1.008986473083496, 'eval_accuracy': 0.7132352941176471, 'eval_f1': 0.8040201005025126, 'eval_runtime': 0.7478, 'eval_samples_per_second': 545.612, 'eval_steps_per_second': 68.202, 'epoch': 4.0}\n",
            "{'train_runtime': 23.1687, 'train_samples_per_second': 633.268, 'train_steps_per_second': 79.245, 'train_loss': 0.4198933395684934, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:22:09] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:22:09] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:22:09] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:22:09] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:22:09] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 1.008986473083496, 'eval_accuracy': 0.7132352941176471, 'eval_f1': 0.8040201005025126, 'eval_runtime': 0.7392, 'eval_samples_per_second': 551.973, 'eval_steps_per_second': 68.997, 'epoch': 4.0}\n",
            "Progress: 42/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:22:10] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:22:10] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:22:10] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:22:10]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:22:10]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:22:10]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:22:10]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:22:10]   CPU count: 8\n",
            "[codecarbon INFO @ 00:22:10]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:22:10]   GPU count: 1\n",
            "[codecarbon INFO @ 00:22:10]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.571905791759491, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8169440242057489, 'eval_runtime': 0.7456, 'eval_samples_per_second': 547.184, 'eval_steps_per_second': 68.398, 'epoch': 1.0}\n",
            "{'loss': 0.5884, 'grad_norm': 4.293759822845459, 'learning_rate': 7.276688453159042e-05, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.5654860734939575, 'eval_accuracy': 0.7352941176470589, 'eval_f1': 0.8285714285714286, 'eval_runtime': 0.777, 'eval_samples_per_second': 525.117, 'eval_steps_per_second': 65.64, 'epoch': 2.0}\n",
            "{'loss': 0.4993, 'grad_norm': 8.675013542175293, 'learning_rate': 4.5533769063180834e-05, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:22:25] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:22:25] Energy consumed for all GPUs : 0.000158 kWh. Total GPU Power : 37.94618125999611 W\n",
            "[codecarbon INFO @ 00:22:25] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:22:25] 0.000415 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6270501613616943, 'eval_accuracy': 0.7352941176470589, 'eval_f1': 0.8296529968454258, 'eval_runtime': 0.7373, 'eval_samples_per_second': 553.373, 'eval_steps_per_second': 69.172, 'epoch': 3.0}\n",
            "{'loss': 0.4045, 'grad_norm': 26.807472229003906, 'learning_rate': 1.8300653594771242e-05, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:22:34] Energy consumed for RAM : 0.000127 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:22:34] Energy consumed for all GPUs : 0.000251 kWh. Total GPU Power : 37.66743679026234 W\n",
            "[codecarbon INFO @ 00:22:34] Energy consumed for all CPUs : 0.000282 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:22:34] 0.000660 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6656573414802551, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8325508607198748, 'eval_runtime': 0.7729, 'eval_samples_per_second': 527.895, 'eval_steps_per_second': 65.987, 'epoch': 4.0}\n",
            "{'train_runtime': 23.2753, 'train_samples_per_second': 630.368, 'train_steps_per_second': 78.882, 'train_loss': 0.47345523792674077, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:22:34] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:22:34] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:22:34] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:22:34] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:22:34] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6656573414802551, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8325508607198748, 'eval_runtime': 0.7375, 'eval_samples_per_second': 553.193, 'eval_steps_per_second': 69.149, 'epoch': 4.0}\n",
            "Progress: 43/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:22:36] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:22:36] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:22:36] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:22:36]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:22:36]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:22:36]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:22:36]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:22:36]   CPU count: 8\n",
            "[codecarbon INFO @ 00:22:36]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:22:36]   GPU count: 1\n",
            "[codecarbon INFO @ 00:22:36]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5733863711357117, 'eval_accuracy': 0.7009803921568627, 'eval_f1': 0.8134556574923547, 'eval_runtime': 0.7703, 'eval_samples_per_second': 529.656, 'eval_steps_per_second': 66.207, 'epoch': 1.0}\n",
            "{'loss': 0.6013, 'grad_norm': 4.323869228363037, 'learning_rate': 3.638344226579521e-05, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.5774785876274109, 'eval_accuracy': 0.7083333333333334, 'eval_f1': 0.8194233687405159, 'eval_runtime': 0.758, 'eval_samples_per_second': 538.288, 'eval_steps_per_second': 67.286, 'epoch': 2.0}\n",
            "{'loss': 0.5438, 'grad_norm': 5.283394813537598, 'learning_rate': 2.2766884531590417e-05, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:22:51] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:22:51] Energy consumed for all GPUs : 0.000157 kWh. Total GPU Power : 37.74901799338462 W\n",
            "[codecarbon INFO @ 00:22:51] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:22:51] 0.000414 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5611313581466675, 'eval_accuracy': 0.7279411764705882, 'eval_f1': 0.8246445497630331, 'eval_runtime': 0.7386, 'eval_samples_per_second': 552.392, 'eval_steps_per_second': 69.049, 'epoch': 3.0}\n",
            "{'loss': 0.4849, 'grad_norm': 14.096569061279297, 'learning_rate': 9.150326797385621e-06, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:23:00] Energy consumed for RAM : 0.000127 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:23:00] Energy consumed for all GPUs : 0.000250 kWh. Total GPU Power : 37.81711068977627 W\n",
            "[codecarbon INFO @ 00:23:00] Energy consumed for all CPUs : 0.000282 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:23:00] 0.000658 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.587859570980072, 'eval_accuracy': 0.7279411764705882, 'eval_f1': 0.8268330733229329, 'eval_runtime': 0.7495, 'eval_samples_per_second': 544.341, 'eval_steps_per_second': 68.043, 'epoch': 4.0}\n",
            "{'train_runtime': 23.2436, 'train_samples_per_second': 631.228, 'train_steps_per_second': 78.99, 'train_loss': 0.5309766798497285, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:23:00] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:23:00] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:23:00] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:23:00] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:23:00] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.587859570980072, 'eval_accuracy': 0.7279411764705882, 'eval_f1': 0.8268330733229329, 'eval_runtime': 0.739, 'eval_samples_per_second': 552.098, 'eval_steps_per_second': 69.012, 'epoch': 4.0}\n",
            "Progress: 44/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:23:01] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:23:01] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:23:01] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:23:01]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:23:01]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:23:01]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:23:01]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:23:01]   CPU count: 8\n",
            "[codecarbon INFO @ 00:23:01]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:23:01]   GPU count: 1\n",
            "[codecarbon INFO @ 00:23:02]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5838139653205872, 'eval_accuracy': 0.7009803921568627, 'eval_f1': 0.8184523809523809, 'eval_runtime': 0.7809, 'eval_samples_per_second': 522.459, 'eval_steps_per_second': 65.307, 'epoch': 1.0}\n",
            "{'loss': 0.6134, 'grad_norm': 2.5178942680358887, 'learning_rate': 2.1830065359477124e-05, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.5830901861190796, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8180451127819549, 'eval_runtime': 0.7391, 'eval_samples_per_second': 552.026, 'eval_steps_per_second': 69.003, 'epoch': 2.0}\n",
            "{'loss': 0.5689, 'grad_norm': 4.079008102416992, 'learning_rate': 1.366013071895425e-05, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:23:17] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:23:17] Energy consumed for all GPUs : 0.000158 kWh. Total GPU Power : 37.886085185046305 W\n",
            "[codecarbon INFO @ 00:23:17] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:23:17] 0.000415 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.568699836730957, 'eval_accuracy': 0.7132352941176471, 'eval_f1': 0.8197226502311248, 'eval_runtime': 0.736, 'eval_samples_per_second': 554.347, 'eval_steps_per_second': 69.293, 'epoch': 3.0}\n",
            "{'loss': 0.5302, 'grad_norm': 6.041450023651123, 'learning_rate': 5.490196078431373e-06, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:23:25] Energy consumed for RAM : 0.000127 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:23:26] Energy consumed for all GPUs : 0.000250 kWh. Total GPU Power : 37.55681161228711 W\n",
            "[codecarbon INFO @ 00:23:26] Energy consumed for all CPUs : 0.000282 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:23:26] 0.000659 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5771942734718323, 'eval_accuracy': 0.7107843137254902, 'eval_f1': 0.8195718654434251, 'eval_runtime': 0.7416, 'eval_samples_per_second': 550.126, 'eval_steps_per_second': 68.766, 'epoch': 4.0}\n",
            "{'train_runtime': 23.2601, 'train_samples_per_second': 630.78, 'train_steps_per_second': 78.933, 'train_loss': 0.5637553262814458, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:23:26] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:23:26] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:23:26] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:23:26] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:23:26] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5771942734718323, 'eval_accuracy': 0.7107843137254902, 'eval_f1': 0.8195718654434251, 'eval_runtime': 0.7314, 'eval_samples_per_second': 557.848, 'eval_steps_per_second': 69.731, 'epoch': 4.0}\n",
            "Progress: 45/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:23:27] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:23:27] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:23:27] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:23:27]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:23:27]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:23:27]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:23:27]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:23:27]   CPU count: 8\n",
            "[codecarbon INFO @ 00:23:27]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:23:27]   GPU count: 1\n",
            "[codecarbon INFO @ 00:23:27]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5624045133590698, 'eval_accuracy': 0.7230392156862745, 'eval_f1': 0.8231611893583725, 'eval_runtime': 0.6585, 'eval_samples_per_second': 619.56, 'eval_steps_per_second': 39.482, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5531349778175354, 'eval_accuracy': 0.7328431372549019, 'eval_f1': 0.8256, 'eval_runtime': 0.6521, 'eval_samples_per_second': 625.678, 'eval_steps_per_second': 39.872, 'epoch': 2.0}\n",
            "{'loss': 0.5239, 'grad_norm': 15.012598991394043, 'learning_rate': 0.00013695652173913042, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.590812087059021, 'eval_accuracy': 0.7401960784313726, 'eval_f1': 0.8221476510067114, 'eval_runtime': 0.7009, 'eval_samples_per_second': 582.118, 'eval_steps_per_second': 37.096, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:23:42] Energy consumed for RAM : 0.000077 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:23:42] Energy consumed for all GPUs : 0.000163 kWh. Total GPU Power : 40.52761564486248 W\n",
            "[codecarbon INFO @ 00:23:42] Energy consumed for all CPUs : 0.000171 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:23:42] 0.000412 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7519146800041199, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8243021346469622, 'eval_runtime': 0.6728, 'eval_samples_per_second': 606.428, 'eval_steps_per_second': 38.645, 'epoch': 4.0}\n",
            "{'train_runtime': 13.8997, 'train_samples_per_second': 1055.561, 'train_steps_per_second': 66.188, 'train_loss': 0.40669037362803584, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:23:43] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:23:43] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:23:43] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:23:43] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:23:43] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7519146800041199, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8243021346469622, 'eval_runtime': 0.6894, 'eval_samples_per_second': 591.794, 'eval_steps_per_second': 37.712, 'epoch': 4.0}\n",
            "Progress: 46/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:23:44] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:23:44] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:23:44] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:23:44]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:23:44]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:23:44]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:23:44]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:23:44]   CPU count: 8\n",
            "[codecarbon INFO @ 00:23:44]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:23:44]   GPU count: 1\n",
            "[codecarbon INFO @ 00:23:44]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.564354419708252, 'eval_accuracy': 0.7132352941176471, 'eval_f1': 0.8180404354587869, 'eval_runtime': 0.6644, 'eval_samples_per_second': 614.104, 'eval_steps_per_second': 39.134, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5474852919578552, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.831496062992126, 'eval_runtime': 0.6764, 'eval_samples_per_second': 603.191, 'eval_steps_per_second': 38.439, 'epoch': 2.0}\n",
            "{'loss': 0.5577, 'grad_norm': 6.763742923736572, 'learning_rate': 4.565217391304348e-05, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.5569795966148376, 'eval_accuracy': 0.7426470588235294, 'eval_f1': 0.8330683624801272, 'eval_runtime': 0.6738, 'eval_samples_per_second': 605.564, 'eval_steps_per_second': 38.59, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:23:58] Energy consumed for RAM : 0.000076 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:23:58] Energy consumed for all GPUs : 0.000163 kWh. Total GPU Power : 41.06711783470983 W\n",
            "[codecarbon INFO @ 00:23:58] Energy consumed for all CPUs : 0.000169 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:23:58] 0.000407 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5896832346916199, 'eval_accuracy': 0.7328431372549019, 'eval_f1': 0.8299531981279251, 'eval_runtime': 0.6437, 'eval_samples_per_second': 633.836, 'eval_steps_per_second': 40.391, 'epoch': 4.0}\n",
            "{'train_runtime': 13.6817, 'train_samples_per_second': 1072.383, 'train_steps_per_second': 67.243, 'train_loss': 0.5020559891410495, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:23:59] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:23:59] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:23:59] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:23:59] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:23:59] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5896832346916199, 'eval_accuracy': 0.7328431372549019, 'eval_f1': 0.8299531981279251, 'eval_runtime': 0.6563, 'eval_samples_per_second': 621.666, 'eval_steps_per_second': 39.616, 'epoch': 4.0}\n",
            "Progress: 47/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:24:00] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:24:00] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:24:00] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:24:00]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:24:00]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:24:00]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:24:00]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:24:00]   CPU count: 8\n",
            "[codecarbon INFO @ 00:24:00]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:24:00]   GPU count: 1\n",
            "[codecarbon INFO @ 00:24:00]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5816411972045898, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8095952023988006, 'eval_runtime': 0.6763, 'eval_samples_per_second': 603.27, 'eval_steps_per_second': 38.444, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5781240463256836, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8185907046476761, 'eval_runtime': 0.6616, 'eval_samples_per_second': 616.723, 'eval_steps_per_second': 39.301, 'epoch': 2.0}\n",
            "{'loss': 0.5845, 'grad_norm': 4.170251846313477, 'learning_rate': 2.282608695652174e-05, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.568314790725708, 'eval_accuracy': 0.7083333333333334, 'eval_f1': 0.8183206106870229, 'eval_runtime': 0.6712, 'eval_samples_per_second': 607.91, 'eval_steps_per_second': 38.739, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:24:15] Energy consumed for RAM : 0.000076 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:24:15] Energy consumed for all GPUs : 0.000165 kWh. Total GPU Power : 41.494562236351776 W\n",
            "[codecarbon INFO @ 00:24:15] Energy consumed for all CPUs : 0.000169 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:24:15] 0.000410 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.568650484085083, 'eval_accuracy': 0.7205882352941176, 'eval_f1': 0.8246153846153846, 'eval_runtime': 0.6652, 'eval_samples_per_second': 613.325, 'eval_steps_per_second': 39.084, 'epoch': 4.0}\n",
            "{'train_runtime': 13.7118, 'train_samples_per_second': 1070.027, 'train_steps_per_second': 67.095, 'train_loss': 0.5531564961309018, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:24:15] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:24:15] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:24:15] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:24:15] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:24:15] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.568650484085083, 'eval_accuracy': 0.7205882352941176, 'eval_f1': 0.8246153846153846, 'eval_runtime': 0.6461, 'eval_samples_per_second': 631.445, 'eval_steps_per_second': 40.239, 'epoch': 4.0}\n",
            "Progress: 48/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:24:16] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:24:16] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:24:16] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:24:16]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:24:16]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:24:16]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:24:16]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:24:16]   CPU count: 8\n",
            "[codecarbon INFO @ 00:24:16]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:24:16]   GPU count: 1\n",
            "[codecarbon INFO @ 00:24:16]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5934128761291504, 'eval_accuracy': 0.6985294117647058, 'eval_f1': 0.8193832599118943, 'eval_runtime': 0.7169, 'eval_samples_per_second': 569.09, 'eval_steps_per_second': 36.266, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5834196209907532, 'eval_accuracy': 0.6985294117647058, 'eval_f1': 0.8161434977578476, 'eval_runtime': 0.6589, 'eval_samples_per_second': 619.175, 'eval_steps_per_second': 39.457, 'epoch': 2.0}\n",
            "{'loss': 0.6021, 'grad_norm': 2.227717161178589, 'learning_rate': 1.3695652173913042e-05, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.574123740196228, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8114630467571644, 'eval_runtime': 0.7018, 'eval_samples_per_second': 581.335, 'eval_steps_per_second': 37.046, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:24:31] Energy consumed for RAM : 0.000077 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:24:31] Energy consumed for all GPUs : 0.000166 kWh. Total GPU Power : 40.99888485440507 W\n",
            "[codecarbon INFO @ 00:24:31] Energy consumed for all CPUs : 0.000172 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:24:31] 0.000414 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5735155940055847, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8126888217522659, 'eval_runtime': 0.6736, 'eval_samples_per_second': 605.688, 'eval_steps_per_second': 38.598, 'epoch': 4.0}\n",
            "{'train_runtime': 13.9272, 'train_samples_per_second': 1053.475, 'train_steps_per_second': 66.058, 'train_loss': 0.580059698353643, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:24:32] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:24:32] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:24:32] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:24:32] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:24:32] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5735155940055847, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8126888217522659, 'eval_runtime': 0.6574, 'eval_samples_per_second': 620.644, 'eval_steps_per_second': 39.551, 'epoch': 4.0}\n",
            "Progress: 49/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:24:33] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:24:33] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:24:33] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:24:33]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:24:33]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:24:33]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:24:33]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:24:33]   CPU count: 8\n",
            "[codecarbon INFO @ 00:24:33]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:24:33]   GPU count: 1\n",
            "[codecarbon INFO @ 00:24:33]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5496113896369934, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.831496062992126, 'eval_runtime': 0.6248, 'eval_samples_per_second': 652.961, 'eval_steps_per_second': 20.805, 'epoch': 1.0}\n",
            "{'eval_loss': 0.552695095539093, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8309636650868878, 'eval_runtime': 0.6091, 'eval_samples_per_second': 669.815, 'eval_steps_per_second': 21.342, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6253054141998291, 'eval_accuracy': 0.7450980392156863, 'eval_f1': 0.8354430379746836, 'eval_runtime': 0.618, 'eval_samples_per_second': 660.235, 'eval_steps_per_second': 21.037, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:24:43] Energy consumed for RAM : 0.000053 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:24:43] Energy consumed for all GPUs : 0.000140 kWh. Total GPU Power : 50.762377592032436 W\n",
            "[codecarbon INFO @ 00:24:43] Energy consumed for all CPUs : 0.000117 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:24:43] 0.000309 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6537364721298218, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8304278922345484, 'eval_runtime': 0.6553, 'eval_samples_per_second': 622.624, 'eval_steps_per_second': 19.839, 'epoch': 4.0}\n",
            "{'train_runtime': 9.2975, 'train_samples_per_second': 1578.051, 'train_steps_per_second': 49.475, 'train_loss': 0.43501543791397757, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:24:44] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:24:44] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:24:44] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:24:44] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:24:44] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6537364721298218, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8304278922345484, 'eval_runtime': 0.6108, 'eval_samples_per_second': 667.931, 'eval_steps_per_second': 21.282, 'epoch': 4.0}\n",
            "Progress: 50/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:24:45] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:24:45] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:24:45] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:24:45]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:24:45]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:24:45]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:24:45]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:24:45]   CPU count: 8\n",
            "[codecarbon INFO @ 00:24:45]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:24:45]   GPU count: 1\n",
            "[codecarbon INFO @ 00:24:45]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.585704505443573, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.81089258698941, 'eval_runtime': 0.621, 'eval_samples_per_second': 656.958, 'eval_steps_per_second': 20.932, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5598652958869934, 'eval_accuracy': 0.7181372549019608, 'eval_f1': 0.8205928237129485, 'eval_runtime': 0.6065, 'eval_samples_per_second': 672.73, 'eval_steps_per_second': 21.435, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5700249075889587, 'eval_accuracy': 0.7132352941176471, 'eval_f1': 0.8186046511627907, 'eval_runtime': 0.6234, 'eval_samples_per_second': 654.461, 'eval_steps_per_second': 20.853, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:24:55] Energy consumed for RAM : 0.000052 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:24:55] Energy consumed for all GPUs : 0.000140 kWh. Total GPU Power : 51.643047858793906 W\n",
            "[codecarbon INFO @ 00:24:55] Energy consumed for all CPUs : 0.000116 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:24:55] 0.000308 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5717409253120422, 'eval_accuracy': 0.7254901960784313, 'eval_f1': 0.8255451713395638, 'eval_runtime': 0.6244, 'eval_samples_per_second': 653.421, 'eval_steps_per_second': 20.82, 'epoch': 4.0}\n",
            "{'train_runtime': 9.1931, 'train_samples_per_second': 1595.975, 'train_steps_per_second': 50.037, 'train_loss': 0.5322120666503907, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:24:55] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:24:55] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:24:55] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:24:55] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:24:55] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5717409253120422, 'eval_accuracy': 0.7254901960784313, 'eval_f1': 0.8255451713395638, 'eval_runtime': 0.6558, 'eval_samples_per_second': 622.144, 'eval_steps_per_second': 19.823, 'epoch': 4.0}\n",
            "Progress: 51/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:24:56] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:24:56] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:24:57] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:24:57]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:24:57]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:24:57]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:24:57]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:24:57]   CPU count: 8\n",
            "[codecarbon INFO @ 00:24:57]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:24:57]   GPU count: 1\n",
            "[codecarbon INFO @ 00:24:57]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5961236953735352, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8169838945827232, 'eval_runtime': 0.6613, 'eval_samples_per_second': 616.956, 'eval_steps_per_second': 19.658, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5710234045982361, 'eval_accuracy': 0.7058823529411765, 'eval_f1': 0.817629179331307, 'eval_runtime': 0.6607, 'eval_samples_per_second': 617.527, 'eval_steps_per_second': 19.676, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5729517340660095, 'eval_accuracy': 0.7083333333333334, 'eval_f1': 0.8199697428139183, 'eval_runtime': 0.6111, 'eval_samples_per_second': 667.664, 'eval_steps_per_second': 21.274, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:25:07] Energy consumed for RAM : 0.000053 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:25:07] Energy consumed for all GPUs : 0.000140 kWh. Total GPU Power : 50.72093141499554 W\n",
            "[codecarbon INFO @ 00:25:07] Energy consumed for all CPUs : 0.000117 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:25:07] 0.000310 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.56805819272995, 'eval_accuracy': 0.7107843137254902, 'eval_f1': 0.8201219512195121, 'eval_runtime': 0.6339, 'eval_samples_per_second': 643.659, 'eval_steps_per_second': 20.509, 'epoch': 4.0}\n",
            "{'train_runtime': 9.3351, 'train_samples_per_second': 1571.702, 'train_steps_per_second': 49.276, 'train_loss': 0.5740605893342391, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:25:07] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:25:07] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:25:07] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:25:07] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:25:07] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.56805819272995, 'eval_accuracy': 0.7107843137254902, 'eval_f1': 0.8201219512195121, 'eval_runtime': 0.6225, 'eval_samples_per_second': 655.42, 'eval_steps_per_second': 20.883, 'epoch': 4.0}\n",
            "Progress: 52/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:25:08] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:25:08] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:25:08] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:25:08]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:25:08]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:25:08]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:25:08]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:25:08]   CPU count: 8\n",
            "[codecarbon INFO @ 00:25:08]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:25:08]   GPU count: 1\n",
            "[codecarbon INFO @ 00:25:08]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6053450703620911, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.642, 'eval_samples_per_second': 635.526, 'eval_steps_per_second': 20.25, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5885691046714783, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8212703101920237, 'eval_runtime': 0.6214, 'eval_samples_per_second': 656.615, 'eval_steps_per_second': 20.922, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5840325355529785, 'eval_accuracy': 0.6985294117647058, 'eval_f1': 0.8166915052160953, 'eval_runtime': 0.6248, 'eval_samples_per_second': 653.035, 'eval_steps_per_second': 20.807, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:25:18] Energy consumed for RAM : 0.000053 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:25:18] Energy consumed for all GPUs : 0.000141 kWh. Total GPU Power : 51.17573026218734 W\n",
            "[codecarbon INFO @ 00:25:18] Energy consumed for all CPUs : 0.000117 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:25:18] 0.000311 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5790587663650513, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8138138138138138, 'eval_runtime': 0.666, 'eval_samples_per_second': 612.629, 'eval_steps_per_second': 19.52, 'epoch': 4.0}\n",
            "{'train_runtime': 9.3091, 'train_samples_per_second': 1576.097, 'train_steps_per_second': 49.414, 'train_loss': 0.5975138125212296, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:25:19] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:25:19] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:25:19] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:25:19] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:25:19] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5790587663650513, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8138138138138138, 'eval_runtime': 0.6227, 'eval_samples_per_second': 655.214, 'eval_steps_per_second': 20.877, 'epoch': 4.0}\n",
            "Progress: 53/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:25:20] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:25:20] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:25:20] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:25:20]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:25:20]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:25:20]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:25:20]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:25:20]   CPU count: 8\n",
            "[codecarbon INFO @ 00:25:20]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:25:20]   GPU count: 1\n",
            "[codecarbon INFO @ 00:25:20]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5753757357597351, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8132530120481928, 'eval_runtime': 0.7722, 'eval_samples_per_second': 528.374, 'eval_steps_per_second': 9.065, 'epoch': 1.0}\n",
            "{'eval_loss': 0.550995409488678, 'eval_accuracy': 0.7328431372549019, 'eval_f1': 0.8304821150855366, 'eval_runtime': 0.5918, 'eval_samples_per_second': 689.374, 'eval_steps_per_second': 11.828, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5720232129096985, 'eval_accuracy': 0.7598039215686274, 'eval_f1': 0.8434504792332268, 'eval_runtime': 0.5938, 'eval_samples_per_second': 687.084, 'eval_steps_per_second': 11.788, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:25:28] Energy consumed for RAM : 0.000043 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:25:28] Energy consumed for all GPUs : 0.000125 kWh. Total GPU Power : 55.43315893841427 W\n",
            "[codecarbon INFO @ 00:25:28] Energy consumed for all CPUs : 0.000096 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:25:28] 0.000264 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5971444249153137, 'eval_accuracy': 0.75, 'eval_f1': 0.8386075949367089, 'eval_runtime': 0.5953, 'eval_samples_per_second': 685.359, 'eval_steps_per_second': 11.759, 'epoch': 4.0}\n",
            "{'train_runtime': 7.4403, 'train_samples_per_second': 1971.955, 'train_steps_per_second': 31.181, 'train_loss': 0.4707464020827721, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:25:29] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:25:29] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:25:29] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:25:29] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:25:29] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5971444249153137, 'eval_accuracy': 0.75, 'eval_f1': 0.8386075949367089, 'eval_runtime': 0.6199, 'eval_samples_per_second': 658.151, 'eval_steps_per_second': 11.292, 'epoch': 4.0}\n",
            "Progress: 54/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:25:30] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:25:30] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:25:30] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:25:30]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:25:30]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:25:30]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:25:30]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:25:30]   CPU count: 8\n",
            "[codecarbon INFO @ 00:25:30]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:25:30]   GPU count: 1\n",
            "[codecarbon INFO @ 00:25:30]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.594853937625885, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8169838945827232, 'eval_runtime': 0.6099, 'eval_samples_per_second': 668.951, 'eval_steps_per_second': 11.477, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5708560943603516, 'eval_accuracy': 0.7009803921568627, 'eval_f1': 0.8117283950617284, 'eval_runtime': 0.612, 'eval_samples_per_second': 666.68, 'eval_steps_per_second': 11.438, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5739648938179016, 'eval_accuracy': 0.7230392156862745, 'eval_f1': 0.8269525267993875, 'eval_runtime': 0.6087, 'eval_samples_per_second': 670.264, 'eval_steps_per_second': 11.5, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:25:38] Energy consumed for RAM : 0.000043 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:25:38] Energy consumed for all GPUs : 0.000127 kWh. Total GPU Power : 56.43215835028142 W\n",
            "[codecarbon INFO @ 00:25:38] Energy consumed for all CPUs : 0.000095 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:25:38] 0.000265 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5612186193466187, 'eval_accuracy': 0.7303921568627451, 'eval_f1': 0.8297213622291022, 'eval_runtime': 0.6974, 'eval_samples_per_second': 585.006, 'eval_steps_per_second': 10.037, 'epoch': 4.0}\n",
            "{'train_runtime': 7.4689, 'train_samples_per_second': 1964.418, 'train_steps_per_second': 31.062, 'train_loss': 0.5603954052102977, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:25:39] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:25:39] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:25:39] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:25:39] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:25:39] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5612186193466187, 'eval_accuracy': 0.7303921568627451, 'eval_f1': 0.8297213622291022, 'eval_runtime': 0.6266, 'eval_samples_per_second': 651.184, 'eval_steps_per_second': 11.172, 'epoch': 4.0}\n",
            "Progress: 55/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:25:40] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:25:40] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:25:40] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:25:40]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:25:40]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:25:40]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:25:40]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:25:40]   CPU count: 8\n",
            "[codecarbon INFO @ 00:25:40]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:25:40]   GPU count: 1\n",
            "[codecarbon INFO @ 00:25:40]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6062899231910706, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.6458, 'eval_samples_per_second': 631.778, 'eval_steps_per_second': 10.839, 'epoch': 1.0}\n",
            "{'eval_loss': 0.590184211730957, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8212703101920237, 'eval_runtime': 0.6136, 'eval_samples_per_second': 664.923, 'eval_steps_per_second': 11.408, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5828689932823181, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8143712574850299, 'eval_runtime': 0.5952, 'eval_samples_per_second': 685.537, 'eval_steps_per_second': 11.762, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:25:48] Energy consumed for RAM : 0.000043 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:25:48] Energy consumed for all GPUs : 0.000122 kWh. Total GPU Power : 54.72787336412275 W\n",
            "[codecarbon INFO @ 00:25:48] Energy consumed for all CPUs : 0.000095 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:25:48] 0.000259 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5777505040168762, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8078668683812406, 'eval_runtime': 0.5974, 'eval_samples_per_second': 682.957, 'eval_steps_per_second': 11.717, 'epoch': 4.0}\n",
            "{'train_runtime': 7.4182, 'train_samples_per_second': 1977.833, 'train_steps_per_second': 31.274, 'train_loss': 0.5961887096536571, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:25:49] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:25:49] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:25:49] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:25:49] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:25:49] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5777505040168762, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8078668683812406, 'eval_runtime': 0.6105, 'eval_samples_per_second': 668.337, 'eval_steps_per_second': 11.467, 'epoch': 4.0}\n",
            "Progress: 56/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:25:50] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:25:50] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:25:50] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:25:50]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:25:50]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:25:50]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:25:50]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:25:50]   CPU count: 8\n",
            "[codecarbon INFO @ 00:25:50]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:25:50]   GPU count: 1\n",
            "[codecarbon INFO @ 00:25:50]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6178915500640869, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.5876, 'eval_samples_per_second': 694.339, 'eval_steps_per_second': 11.913, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6015655398368835, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.6324, 'eval_samples_per_second': 645.202, 'eval_steps_per_second': 11.07, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5944027900695801, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8181818181818182, 'eval_runtime': 1.0161, 'eval_samples_per_second': 401.55, 'eval_steps_per_second': 6.889, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:25:59] Energy consumed for RAM : 0.000045 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:25:59] Energy consumed for all GPUs : 0.000127 kWh. Total GPU Power : 54.50483239357069 W\n",
            "[codecarbon INFO @ 00:25:59] Energy consumed for all CPUs : 0.000099 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:25:59] 0.000272 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5916686058044434, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8217967599410898, 'eval_runtime': 0.6049, 'eval_samples_per_second': 674.537, 'eval_steps_per_second': 11.573, 'epoch': 4.0}\n",
            "{'train_runtime': 7.8132, 'train_samples_per_second': 1877.841, 'train_steps_per_second': 29.693, 'train_loss': 0.6165741229879445, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:25:59] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:25:59] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:25:59] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:25:59] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:25:59] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5916686058044434, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8217967599410898, 'eval_runtime': 0.6079, 'eval_samples_per_second': 671.206, 'eval_steps_per_second': 11.516, 'epoch': 4.0}\n",
            "Progress: 57/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:26:01] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:26:01] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:26:01] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:26:01]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:26:01]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:26:01]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:26:01]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:26:01]   CPU count: 8\n",
            "[codecarbon INFO @ 00:26:01]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:26:01]   GPU count: 1\n",
            "[codecarbon INFO @ 00:26:01]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6026797890663147, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.808446455505279, 'eval_runtime': 0.5953, 'eval_samples_per_second': 685.39, 'eval_steps_per_second': 6.72, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5666956901550293, 'eval_accuracy': 0.7205882352941176, 'eval_f1': 0.821875, 'eval_runtime': 0.5999, 'eval_samples_per_second': 680.088, 'eval_steps_per_second': 6.668, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5767462253570557, 'eval_accuracy': 0.7279411764705882, 'eval_f1': 0.8262910798122066, 'eval_runtime': 0.5882, 'eval_samples_per_second': 693.631, 'eval_steps_per_second': 6.8, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:26:08] Energy consumed for RAM : 0.000039 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:26:08] Energy consumed for all GPUs : 0.000110 kWh. Total GPU Power : 54.35495986617367 W\n",
            "[codecarbon INFO @ 00:26:08] Energy consumed for all CPUs : 0.000086 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:26:08] 0.000235 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5759289264678955, 'eval_accuracy': 0.7352941176470589, 'eval_f1': 0.8291139240506329, 'eval_runtime': 0.5939, 'eval_samples_per_second': 687.025, 'eval_steps_per_second': 6.736, 'epoch': 4.0}\n",
            "{'train_runtime': 6.6608, 'train_samples_per_second': 2202.734, 'train_steps_per_second': 17.415, 'train_loss': 0.5189324411852606, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:26:09] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:26:09] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:26:09] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:26:09] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:26:09] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5759289264678955, 'eval_accuracy': 0.7352941176470589, 'eval_f1': 0.8291139240506329, 'eval_runtime': 0.5903, 'eval_samples_per_second': 691.126, 'eval_steps_per_second': 6.776, 'epoch': 4.0}\n",
            "Progress: 58/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:26:10] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:26:10] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:26:10] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:26:10]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:26:10]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:26:10]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:26:10]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:26:10]   CPU count: 8\n",
            "[codecarbon INFO @ 00:26:10]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:26:10]   GPU count: 1\n",
            "[codecarbon INFO @ 00:26:10]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6038169264793396, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.6386, 'eval_samples_per_second': 638.942, 'eval_steps_per_second': 6.264, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5951903462409973, 'eval_accuracy': 0.7058823529411765, 'eval_f1': 0.8224852071005917, 'eval_runtime': 0.5972, 'eval_samples_per_second': 683.208, 'eval_steps_per_second': 6.698, 'epoch': 2.0}\n",
            "{'eval_loss': 0.579287052154541, 'eval_accuracy': 0.6911764705882353, 'eval_f1': 0.8090909090909091, 'eval_runtime': 0.5939, 'eval_samples_per_second': 687.042, 'eval_steps_per_second': 6.736, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:26:17] Energy consumed for RAM : 0.000040 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:26:17] Energy consumed for all GPUs : 0.000111 kWh. Total GPU Power : 53.164533485790294 W\n",
            "[codecarbon INFO @ 00:26:17] Energy consumed for all CPUs : 0.000089 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:26:17] 0.000239 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5748432874679565, 'eval_accuracy': 0.6911764705882353, 'eval_f1': 0.8073394495412844, 'eval_runtime': 0.5969, 'eval_samples_per_second': 683.536, 'eval_steps_per_second': 6.701, 'epoch': 4.0}\n",
            "{'train_runtime': 6.7453, 'train_samples_per_second': 2175.131, 'train_steps_per_second': 17.197, 'train_loss': 0.5897226004764952, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:26:18] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:26:18] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:26:18] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:26:18] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:26:18] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5748432874679565, 'eval_accuracy': 0.6911764705882353, 'eval_f1': 0.8073394495412844, 'eval_runtime': 0.5933, 'eval_samples_per_second': 687.702, 'eval_steps_per_second': 6.742, 'epoch': 4.0}\n",
            "Progress: 59/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:26:19] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:26:19] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:26:19] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:26:19]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:26:19]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:26:19]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:26:19]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:26:19]   CPU count: 8\n",
            "[codecarbon INFO @ 00:26:19]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:26:19]   GPU count: 1\n",
            "[codecarbon INFO @ 00:26:19]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6207587718963623, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.6123, 'eval_samples_per_second': 666.323, 'eval_steps_per_second': 6.533, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6050003170967102, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.5837, 'eval_samples_per_second': 698.934, 'eval_steps_per_second': 6.852, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5970742106437683, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8145985401459854, 'eval_runtime': 0.6224, 'eval_samples_per_second': 655.525, 'eval_steps_per_second': 6.427, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:26:27] Energy consumed for RAM : 0.000039 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:26:27] Energy consumed for all GPUs : 0.000110 kWh. Total GPU Power : 53.188323534838595 W\n",
            "[codecarbon INFO @ 00:26:27] Energy consumed for all CPUs : 0.000088 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:26:27] 0.000237 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5952083468437195, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8169838945827232, 'eval_runtime': 0.6127, 'eval_samples_per_second': 665.853, 'eval_steps_per_second': 6.528, 'epoch': 4.0}\n",
            "{'train_runtime': 6.7802, 'train_samples_per_second': 2163.953, 'train_steps_per_second': 17.109, 'train_loss': 0.6204661007585197, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:26:27] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:26:27] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:26:27] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:26:27] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:26:27] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5952083468437195, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8169838945827232, 'eval_runtime': 0.5981, 'eval_samples_per_second': 682.169, 'eval_steps_per_second': 6.688, 'epoch': 4.0}\n",
            "Progress: 60/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:26:28] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:26:28] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:26:28] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:26:28]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:26:28]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:26:28]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:26:28]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:26:28]   CPU count: 8\n",
            "[codecarbon INFO @ 00:26:28]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:26:28]   GPU count: 1\n",
            "[codecarbon INFO @ 00:26:28]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6439599990844727, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.621, 'eval_samples_per_second': 656.986, 'eval_steps_per_second': 6.441, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6185536980628967, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.6242, 'eval_samples_per_second': 653.648, 'eval_steps_per_second': 6.408, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6116704344749451, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.5951, 'eval_samples_per_second': 685.627, 'eval_steps_per_second': 6.722, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:26:36] Energy consumed for RAM : 0.000041 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:26:36] Energy consumed for all GPUs : 0.000114 kWh. Total GPU Power : 53.642600038148196 W\n",
            "[codecarbon INFO @ 00:26:36] Energy consumed for all CPUs : 0.000090 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:26:36] 0.000245 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.609874427318573, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.593, 'eval_samples_per_second': 688.001, 'eval_steps_per_second': 6.745, 'epoch': 4.0}\n",
            "{'train_runtime': 7.0303, 'train_samples_per_second': 2086.957, 'train_steps_per_second': 16.5, 'train_loss': 0.6398460125101024, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:26:37] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:26:37] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:26:37] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:26:37] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:26:37] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.609874427318573, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.6094, 'eval_samples_per_second': 669.479, 'eval_steps_per_second': 6.564, 'epoch': 4.0}\n",
            "Progress: 61/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:26:38] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:26:38] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:26:38] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:26:38]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:26:38]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:26:38]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:26:38]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:26:38]   CPU count: 8\n",
            "[codecarbon INFO @ 00:26:38]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:26:38]   GPU count: 1\n",
            "[codecarbon INFO @ 00:26:38]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.563829779624939, 'eval_accuracy': 0.7181372549019608, 'eval_f1': 0.8217054263565892, 'eval_runtime': 0.7711, 'eval_samples_per_second': 529.106, 'eval_steps_per_second': 66.138, 'epoch': 1.0}\n",
            "{'loss': 0.5928, 'grad_norm': 2.919314384460449, 'learning_rate': 0.00021830065359477123, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.5867751836776733, 'eval_accuracy': 0.75, 'eval_f1': 0.8365384615384616, 'eval_runtime': 0.8086, 'eval_samples_per_second': 504.592, 'eval_steps_per_second': 63.074, 'epoch': 2.0}\n",
            "{'loss': 0.4614, 'grad_norm': 19.731420516967773, 'learning_rate': 0.00013660130718954247, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:26:53] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:26:53] Energy consumed for all GPUs : 0.000156 kWh. Total GPU Power : 37.538537289535284 W\n",
            "[codecarbon INFO @ 00:26:53] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:26:53] 0.000413 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7742764353752136, 'eval_accuracy': 0.75, 'eval_f1': 0.8271186440677966, 'eval_runtime': 0.8206, 'eval_samples_per_second': 497.199, 'eval_steps_per_second': 62.15, 'epoch': 3.0}\n",
            "{'loss': 0.2982, 'grad_norm': 6.061849117279053, 'learning_rate': 5.4901960784313716e-05, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:27:05] Energy consumed for RAM : 0.000142 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:27:05] Energy consumed for all GPUs : 0.000277 kWh. Total GPU Power : 37.226875181553666 W\n",
            "[codecarbon INFO @ 00:27:05] Energy consumed for all CPUs : 0.000315 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:27:05] 0.000734 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.9748042821884155, 'eval_accuracy': 0.7401960784313726, 'eval_f1': 0.826797385620915, 'eval_runtime': 0.7785, 'eval_samples_per_second': 524.088, 'eval_steps_per_second': 65.511, 'epoch': 4.0}\n",
            "{'train_runtime': 26.0641, 'train_samples_per_second': 562.919, 'train_steps_per_second': 70.442, 'train_loss': 0.4078846227109822, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:27:06] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:27:06] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:27:06] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:27:06] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:27:06] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.9748042821884155, 'eval_accuracy': 0.7401960784313726, 'eval_f1': 0.826797385620915, 'eval_runtime': 0.7796, 'eval_samples_per_second': 523.33, 'eval_steps_per_second': 65.416, 'epoch': 4.0}\n",
            "Progress: 62/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:27:07] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:27:07] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:27:07] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:27:07]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:27:07]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:27:07]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:27:07]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:27:07]   CPU count: 8\n",
            "[codecarbon INFO @ 00:27:07]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:27:07]   GPU count: 1\n",
            "[codecarbon INFO @ 00:27:07]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.571905791759491, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8169440242057489, 'eval_runtime': 0.7839, 'eval_samples_per_second': 520.49, 'eval_steps_per_second': 65.061, 'epoch': 1.0}\n",
            "{'loss': 0.5884, 'grad_norm': 4.293759822845459, 'learning_rate': 7.276688453159042e-05, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.5654860734939575, 'eval_accuracy': 0.7352941176470589, 'eval_f1': 0.8285714285714286, 'eval_runtime': 0.77, 'eval_samples_per_second': 529.864, 'eval_steps_per_second': 66.233, 'epoch': 2.0}\n",
            "{'loss': 0.4993, 'grad_norm': 8.675013542175293, 'learning_rate': 4.5533769063180834e-05, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:27:22] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:27:22] Energy consumed for all GPUs : 0.000156 kWh. Total GPU Power : 37.370006914861904 W\n",
            "[codecarbon INFO @ 00:27:22] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:27:22] 0.000413 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6270501613616943, 'eval_accuracy': 0.7352941176470589, 'eval_f1': 0.8296529968454258, 'eval_runtime': 0.7966, 'eval_samples_per_second': 512.189, 'eval_steps_per_second': 64.024, 'epoch': 3.0}\n",
            "{'loss': 0.4045, 'grad_norm': 26.807472229003906, 'learning_rate': 1.8300653594771242e-05, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:27:33] Energy consumed for RAM : 0.000140 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:27:33] Energy consumed for all GPUs : 0.000272 kWh. Total GPU Power : 37.19719612400874 W\n",
            "[codecarbon INFO @ 00:27:33] Energy consumed for all CPUs : 0.000310 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:27:33] 0.000722 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6656573414802551, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8325508607198748, 'eval_runtime': 0.7614, 'eval_samples_per_second': 535.84, 'eval_steps_per_second': 66.98, 'epoch': 4.0}\n",
            "{'train_runtime': 25.6468, 'train_samples_per_second': 572.078, 'train_steps_per_second': 71.588, 'train_loss': 0.47345523792674077, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:27:34] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:27:34] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:27:34] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:27:34] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:27:34] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6656573414802551, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8325508607198748, 'eval_runtime': 0.7509, 'eval_samples_per_second': 543.37, 'eval_steps_per_second': 67.921, 'epoch': 4.0}\n",
            "Progress: 63/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:27:35] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:27:35] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:27:35] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:27:35]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:27:35]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:27:35]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:27:35]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:27:35]   CPU count: 8\n",
            "[codecarbon INFO @ 00:27:35]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:27:35]   GPU count: 1\n",
            "[codecarbon INFO @ 00:27:35]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5733863711357117, 'eval_accuracy': 0.7009803921568627, 'eval_f1': 0.8134556574923547, 'eval_runtime': 0.7932, 'eval_samples_per_second': 514.381, 'eval_steps_per_second': 64.298, 'epoch': 1.0}\n",
            "{'loss': 0.6013, 'grad_norm': 4.323869228363037, 'learning_rate': 3.638344226579521e-05, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.5774785876274109, 'eval_accuracy': 0.7083333333333334, 'eval_f1': 0.8194233687405159, 'eval_runtime': 0.7683, 'eval_samples_per_second': 531.028, 'eval_steps_per_second': 66.379, 'epoch': 2.0}\n",
            "{'loss': 0.5438, 'grad_norm': 5.283394813537598, 'learning_rate': 2.2766884531590417e-05, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:27:50] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:27:50] Energy consumed for all GPUs : 0.000156 kWh. Total GPU Power : 37.39624009654885 W\n",
            "[codecarbon INFO @ 00:27:50] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:27:50] 0.000413 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5611313581466675, 'eval_accuracy': 0.7279411764705882, 'eval_f1': 0.8246445497630331, 'eval_runtime': 0.7606, 'eval_samples_per_second': 536.414, 'eval_steps_per_second': 67.052, 'epoch': 3.0}\n",
            "{'loss': 0.4849, 'grad_norm': 14.096569061279297, 'learning_rate': 9.150326797385621e-06, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:28:00] Energy consumed for RAM : 0.000131 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:28:00] Energy consumed for all GPUs : 0.000257 kWh. Total GPU Power : 37.694705406297146 W\n",
            "[codecarbon INFO @ 00:28:00] Energy consumed for all CPUs : 0.000291 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:28:00] 0.000678 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.587859570980072, 'eval_accuracy': 0.7279411764705882, 'eval_f1': 0.8268330733229329, 'eval_runtime': 0.7708, 'eval_samples_per_second': 529.302, 'eval_steps_per_second': 66.163, 'epoch': 4.0}\n",
            "{'train_runtime': 23.9766, 'train_samples_per_second': 611.931, 'train_steps_per_second': 76.575, 'train_loss': 0.5309766798497285, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:28:01] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:28:01] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:28:01] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:28:01] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:28:01] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.587859570980072, 'eval_accuracy': 0.7279411764705882, 'eval_f1': 0.8268330733229329, 'eval_runtime': 0.7627, 'eval_samples_per_second': 534.96, 'eval_steps_per_second': 66.87, 'epoch': 4.0}\n",
            "Progress: 64/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:28:02] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:28:02] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:28:02] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:28:02]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:28:02]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:28:02]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:28:02]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:28:02]   CPU count: 8\n",
            "[codecarbon INFO @ 00:28:02]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:28:02]   GPU count: 1\n",
            "[codecarbon INFO @ 00:28:02]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5838139653205872, 'eval_accuracy': 0.7009803921568627, 'eval_f1': 0.8184523809523809, 'eval_runtime': 0.7429, 'eval_samples_per_second': 549.205, 'eval_steps_per_second': 68.651, 'epoch': 1.0}\n",
            "{'loss': 0.6134, 'grad_norm': 2.5178942680358887, 'learning_rate': 2.1830065359477124e-05, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.5830901861190796, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8180451127819549, 'eval_runtime': 0.7645, 'eval_samples_per_second': 533.665, 'eval_steps_per_second': 66.708, 'epoch': 2.0}\n",
            "{'loss': 0.5689, 'grad_norm': 4.079008102416992, 'learning_rate': 1.366013071895425e-05, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:28:17] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:28:17] Energy consumed for all GPUs : 0.000158 kWh. Total GPU Power : 37.8297092743749 W\n",
            "[codecarbon INFO @ 00:28:17] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:28:17] 0.000415 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.568699836730957, 'eval_accuracy': 0.7132352941176471, 'eval_f1': 0.8197226502311248, 'eval_runtime': 0.7515, 'eval_samples_per_second': 542.94, 'eval_steps_per_second': 67.867, 'epoch': 3.0}\n",
            "{'loss': 0.5302, 'grad_norm': 6.041450023651123, 'learning_rate': 5.490196078431373e-06, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:28:26] Energy consumed for RAM : 0.000128 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:28:26] Energy consumed for all GPUs : 0.000252 kWh. Total GPU Power : 37.55284747768146 W\n",
            "[codecarbon INFO @ 00:28:26] Energy consumed for all CPUs : 0.000284 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:28:26] 0.000663 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5771942734718323, 'eval_accuracy': 0.7107843137254902, 'eval_f1': 0.8195718654434251, 'eval_runtime': 0.76, 'eval_samples_per_second': 536.809, 'eval_steps_per_second': 67.101, 'epoch': 4.0}\n",
            "{'train_runtime': 23.3318, 'train_samples_per_second': 628.841, 'train_steps_per_second': 78.691, 'train_loss': 0.5637553262814458, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:28:27] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:28:27] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:28:27] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:28:27] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:28:27] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5771942734718323, 'eval_accuracy': 0.7107843137254902, 'eval_f1': 0.8195718654434251, 'eval_runtime': 0.7671, 'eval_samples_per_second': 531.907, 'eval_steps_per_second': 66.488, 'epoch': 4.0}\n",
            "Progress: 65/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:28:28] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:28:28] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:28:28] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:28:28]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:28:28]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:28:28]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:28:28]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:28:28]   CPU count: 8\n",
            "[codecarbon INFO @ 00:28:28]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:28:28]   GPU count: 1\n",
            "[codecarbon INFO @ 00:28:28]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5624045133590698, 'eval_accuracy': 0.7230392156862745, 'eval_f1': 0.8231611893583725, 'eval_runtime': 0.8537, 'eval_samples_per_second': 477.897, 'eval_steps_per_second': 30.454, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5531349778175354, 'eval_accuracy': 0.7328431372549019, 'eval_f1': 0.8256, 'eval_runtime': 0.665, 'eval_samples_per_second': 613.552, 'eval_steps_per_second': 39.099, 'epoch': 2.0}\n",
            "{'loss': 0.5239, 'grad_norm': 15.012598991394043, 'learning_rate': 0.00013695652173913042, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.590812087059021, 'eval_accuracy': 0.7401960784313726, 'eval_f1': 0.8221476510067114, 'eval_runtime': 0.6643, 'eval_samples_per_second': 614.196, 'eval_steps_per_second': 39.14, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:28:43] Energy consumed for RAM : 0.000079 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:28:43] Energy consumed for all GPUs : 0.000167 kWh. Total GPU Power : 40.6394953799484 W\n",
            "[codecarbon INFO @ 00:28:43] Energy consumed for all CPUs : 0.000175 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:28:43] 0.000420 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7519146800041199, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8243021346469622, 'eval_runtime': 0.7394, 'eval_samples_per_second': 551.828, 'eval_steps_per_second': 35.165, 'epoch': 4.0}\n",
            "{'train_runtime': 14.16, 'train_samples_per_second': 1036.155, 'train_steps_per_second': 64.972, 'train_loss': 0.40669037362803584, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:28:44] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:28:44] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:28:44] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:28:44] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:28:44] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7519146800041199, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8243021346469622, 'eval_runtime': 0.6561, 'eval_samples_per_second': 621.878, 'eval_steps_per_second': 39.63, 'epoch': 4.0}\n",
            "Progress: 66/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:28:45] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:28:45] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:28:45] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:28:45]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:28:45]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:28:45]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:28:45]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:28:45]   CPU count: 8\n",
            "[codecarbon INFO @ 00:28:45]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:28:45]   GPU count: 1\n",
            "[codecarbon INFO @ 00:28:45]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.564354419708252, 'eval_accuracy': 0.7132352941176471, 'eval_f1': 0.8180404354587869, 'eval_runtime': 0.666, 'eval_samples_per_second': 612.644, 'eval_steps_per_second': 39.041, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5474852919578552, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.831496062992126, 'eval_runtime': 0.6633, 'eval_samples_per_second': 615.074, 'eval_steps_per_second': 39.196, 'epoch': 2.0}\n",
            "{'loss': 0.5577, 'grad_norm': 6.763742923736572, 'learning_rate': 4.565217391304348e-05, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.5569795966148376, 'eval_accuracy': 0.7426470588235294, 'eval_f1': 0.8330683624801272, 'eval_runtime': 0.6743, 'eval_samples_per_second': 605.104, 'eval_steps_per_second': 38.561, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:28:59] Energy consumed for RAM : 0.000077 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:28:59] Energy consumed for all GPUs : 0.000165 kWh. Total GPU Power : 40.92635459473809 W\n",
            "[codecarbon INFO @ 00:28:59] Energy consumed for all CPUs : 0.000171 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:28:59] 0.000413 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5896832346916199, 'eval_accuracy': 0.7328431372549019, 'eval_f1': 0.8299531981279251, 'eval_runtime': 0.68, 'eval_samples_per_second': 600.033, 'eval_steps_per_second': 38.237, 'epoch': 4.0}\n",
            "{'train_runtime': 13.8848, 'train_samples_per_second': 1056.699, 'train_steps_per_second': 66.26, 'train_loss': 0.5020559891410495, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:29:00] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:29:00] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:29:00] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:29:00] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:29:00] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5896832346916199, 'eval_accuracy': 0.7328431372549019, 'eval_f1': 0.8299531981279251, 'eval_runtime': 0.6603, 'eval_samples_per_second': 617.921, 'eval_steps_per_second': 39.377, 'epoch': 4.0}\n",
            "Progress: 67/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:29:01] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:29:01] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:29:01] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:29:01]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:29:01]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:29:01]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:29:01]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:29:01]   CPU count: 8\n",
            "[codecarbon INFO @ 00:29:01]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:29:01]   GPU count: 1\n",
            "[codecarbon INFO @ 00:29:01]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5816411972045898, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8095952023988006, 'eval_runtime': 0.672, 'eval_samples_per_second': 607.185, 'eval_steps_per_second': 38.693, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5781240463256836, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8185907046476761, 'eval_runtime': 0.6554, 'eval_samples_per_second': 622.491, 'eval_steps_per_second': 39.669, 'epoch': 2.0}\n",
            "{'loss': 0.5845, 'grad_norm': 4.170251846313477, 'learning_rate': 2.282608695652174e-05, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.568314790725708, 'eval_accuracy': 0.7083333333333334, 'eval_f1': 0.8183206106870229, 'eval_runtime': 0.6797, 'eval_samples_per_second': 600.286, 'eval_steps_per_second': 38.253, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:29:16] Energy consumed for RAM : 0.000077 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:29:16] Energy consumed for all GPUs : 0.000165 kWh. Total GPU Power : 40.800050104991264 W\n",
            "[codecarbon INFO @ 00:29:16] Energy consumed for all CPUs : 0.000172 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:29:16] 0.000414 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.568650484085083, 'eval_accuracy': 0.7205882352941176, 'eval_f1': 0.8246153846153846, 'eval_runtime': 0.6821, 'eval_samples_per_second': 598.188, 'eval_steps_per_second': 38.12, 'epoch': 4.0}\n",
            "{'train_runtime': 13.909, 'train_samples_per_second': 1054.855, 'train_steps_per_second': 66.144, 'train_loss': 0.5531564961309018, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:29:17] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:29:17] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:29:17] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:29:17] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:29:17] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.568650484085083, 'eval_accuracy': 0.7205882352941176, 'eval_f1': 0.8246153846153846, 'eval_runtime': 0.6749, 'eval_samples_per_second': 604.552, 'eval_steps_per_second': 38.525, 'epoch': 4.0}\n",
            "Progress: 68/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:29:18] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:29:18] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:29:18] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:29:18]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:29:18]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:29:18]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:29:18]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:29:18]   CPU count: 8\n",
            "[codecarbon INFO @ 00:29:18]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:29:18]   GPU count: 1\n",
            "[codecarbon INFO @ 00:29:18]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5934128761291504, 'eval_accuracy': 0.6985294117647058, 'eval_f1': 0.8193832599118943, 'eval_runtime': 0.6736, 'eval_samples_per_second': 605.701, 'eval_steps_per_second': 38.599, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5834196209907532, 'eval_accuracy': 0.6985294117647058, 'eval_f1': 0.8161434977578476, 'eval_runtime': 0.6513, 'eval_samples_per_second': 626.426, 'eval_steps_per_second': 39.919, 'epoch': 2.0}\n",
            "{'loss': 0.6021, 'grad_norm': 2.227717161178589, 'learning_rate': 1.3695652173913042e-05, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.574123740196228, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8114630467571644, 'eval_runtime': 0.6881, 'eval_samples_per_second': 592.96, 'eval_steps_per_second': 37.787, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:29:33] Energy consumed for RAM : 0.000077 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:29:33] Energy consumed for all GPUs : 0.000164 kWh. Total GPU Power : 40.82448732950009 W\n",
            "[codecarbon INFO @ 00:29:33] Energy consumed for all CPUs : 0.000171 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:29:33] 0.000412 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5735155940055847, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8126888217522659, 'eval_runtime': 0.6702, 'eval_samples_per_second': 608.806, 'eval_steps_per_second': 38.796, 'epoch': 4.0}\n",
            "{'train_runtime': 13.8855, 'train_samples_per_second': 1056.643, 'train_steps_per_second': 66.256, 'train_loss': 0.580059698353643, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:29:33] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:29:33] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:29:33] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:29:33] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:29:33] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5735155940055847, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8126888217522659, 'eval_runtime': 0.6604, 'eval_samples_per_second': 617.81, 'eval_steps_per_second': 39.37, 'epoch': 4.0}\n",
            "Progress: 69/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:29:34] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:29:34] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:29:34] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:29:34]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:29:34]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:29:34]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:29:34]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:29:34]   CPU count: 8\n",
            "[codecarbon INFO @ 00:29:34]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:29:34]   GPU count: 1\n",
            "[codecarbon INFO @ 00:29:34]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5496113896369934, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.831496062992126, 'eval_runtime': 0.6189, 'eval_samples_per_second': 659.281, 'eval_steps_per_second': 21.006, 'epoch': 1.0}\n",
            "{'eval_loss': 0.552695095539093, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8309636650868878, 'eval_runtime': 0.6286, 'eval_samples_per_second': 649.098, 'eval_steps_per_second': 20.682, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6253054141998291, 'eval_accuracy': 0.7450980392156863, 'eval_f1': 0.8354430379746836, 'eval_runtime': 0.6057, 'eval_samples_per_second': 673.595, 'eval_steps_per_second': 21.463, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:29:45] Energy consumed for RAM : 0.000056 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:29:45] Energy consumed for all GPUs : 0.000138 kWh. Total GPU Power : 47.52730043755392 W\n",
            "[codecarbon INFO @ 00:29:45] Energy consumed for all CPUs : 0.000124 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:29:45] 0.000318 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6537364721298218, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8304278922345484, 'eval_runtime': 0.6321, 'eval_samples_per_second': 645.481, 'eval_steps_per_second': 20.567, 'epoch': 4.0}\n",
            "{'train_runtime': 9.4029, 'train_samples_per_second': 1560.367, 'train_steps_per_second': 48.921, 'train_loss': 0.43501543791397757, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:29:46] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:29:46] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:29:46] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:29:46] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:29:46] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6537364721298218, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8304278922345484, 'eval_runtime': 0.6155, 'eval_samples_per_second': 662.858, 'eval_steps_per_second': 21.12, 'epoch': 4.0}\n",
            "Progress: 70/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:29:47] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:29:47] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:29:47] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:29:47]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:29:47]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:29:47]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:29:47]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:29:47]   CPU count: 8\n",
            "[codecarbon INFO @ 00:29:47]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:29:47]   GPU count: 1\n",
            "[codecarbon INFO @ 00:29:47]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.585704505443573, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.81089258698941, 'eval_runtime': 0.6146, 'eval_samples_per_second': 663.832, 'eval_steps_per_second': 21.152, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5598652958869934, 'eval_accuracy': 0.7181372549019608, 'eval_f1': 0.8205928237129485, 'eval_runtime': 0.6756, 'eval_samples_per_second': 603.871, 'eval_steps_per_second': 19.241, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5700249075889587, 'eval_accuracy': 0.7132352941176471, 'eval_f1': 0.8186046511627907, 'eval_runtime': 0.6186, 'eval_samples_per_second': 659.554, 'eval_steps_per_second': 21.015, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:29:57] Energy consumed for RAM : 0.000053 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:29:57] Energy consumed for all GPUs : 0.000136 kWh. Total GPU Power : 48.8727090038366 W\n",
            "[codecarbon INFO @ 00:29:57] Energy consumed for all CPUs : 0.000118 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:29:57] 0.000307 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5717409253120422, 'eval_accuracy': 0.7254901960784313, 'eval_f1': 0.8255451713395638, 'eval_runtime': 0.639, 'eval_samples_per_second': 638.492, 'eval_steps_per_second': 20.344, 'epoch': 4.0}\n",
            "{'train_runtime': 9.3934, 'train_samples_per_second': 1561.945, 'train_steps_per_second': 48.97, 'train_loss': 0.5322120666503907, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:29:58] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:29:58] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:29:58] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:29:58] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:29:58] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5717409253120422, 'eval_accuracy': 0.7254901960784313, 'eval_f1': 0.8255451713395638, 'eval_runtime': 0.6334, 'eval_samples_per_second': 644.193, 'eval_steps_per_second': 20.526, 'epoch': 4.0}\n",
            "Progress: 71/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:29:59] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:29:59] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:29:59] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:29:59]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:29:59]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:29:59]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:29:59]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:29:59]   CPU count: 8\n",
            "[codecarbon INFO @ 00:29:59]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:29:59]   GPU count: 1\n",
            "[codecarbon INFO @ 00:29:59]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5961236953735352, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8169838945827232, 'eval_runtime': 0.6188, 'eval_samples_per_second': 659.34, 'eval_steps_per_second': 21.008, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5710234045982361, 'eval_accuracy': 0.7058823529411765, 'eval_f1': 0.817629179331307, 'eval_runtime': 0.6236, 'eval_samples_per_second': 654.312, 'eval_steps_per_second': 20.848, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5729517340660095, 'eval_accuracy': 0.7083333333333334, 'eval_f1': 0.8199697428139183, 'eval_runtime': 0.6203, 'eval_samples_per_second': 657.776, 'eval_steps_per_second': 20.959, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:30:09] Energy consumed for RAM : 0.000053 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:30:09] Energy consumed for all GPUs : 0.000134 kWh. Total GPU Power : 48.52670482108014 W\n",
            "[codecarbon INFO @ 00:30:09] Energy consumed for all CPUs : 0.000118 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:30:09] 0.000305 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.56805819272995, 'eval_accuracy': 0.7107843137254902, 'eval_f1': 0.8201219512195121, 'eval_runtime': 0.6072, 'eval_samples_per_second': 671.98, 'eval_steps_per_second': 21.411, 'epoch': 4.0}\n",
            "{'train_runtime': 9.3613, 'train_samples_per_second': 1567.304, 'train_steps_per_second': 49.138, 'train_loss': 0.5740605893342391, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:30:10] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:30:10] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:30:10] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:30:10] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:30:10] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.56805819272995, 'eval_accuracy': 0.7107843137254902, 'eval_f1': 0.8201219512195121, 'eval_runtime': 0.6278, 'eval_samples_per_second': 649.848, 'eval_steps_per_second': 20.706, 'epoch': 4.0}\n",
            "Progress: 72/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:30:11] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:30:11] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:30:11] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:30:11]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:30:11]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:30:11]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:30:11]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:30:11]   CPU count: 8\n",
            "[codecarbon INFO @ 00:30:11]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:30:11]   GPU count: 1\n",
            "[codecarbon INFO @ 00:30:11]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6053450703620911, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.6344, 'eval_samples_per_second': 643.078, 'eval_steps_per_second': 20.49, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5885691046714783, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8212703101920237, 'eval_runtime': 0.631, 'eval_samples_per_second': 646.549, 'eval_steps_per_second': 20.601, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5840325355529785, 'eval_accuracy': 0.6985294117647058, 'eval_f1': 0.8166915052160953, 'eval_runtime': 0.7352, 'eval_samples_per_second': 554.948, 'eval_steps_per_second': 17.682, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:30:21] Energy consumed for RAM : 0.000054 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:30:21] Energy consumed for all GPUs : 0.000141 kWh. Total GPU Power : 50.334022301623115 W\n",
            "[codecarbon INFO @ 00:30:21] Energy consumed for all CPUs : 0.000119 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:30:21] 0.000314 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5790587663650513, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8138138138138138, 'eval_runtime': 0.6506, 'eval_samples_per_second': 627.115, 'eval_steps_per_second': 19.982, 'epoch': 4.0}\n",
            "{'train_runtime': 9.503, 'train_samples_per_second': 1543.94, 'train_steps_per_second': 48.406, 'train_loss': 0.5975138125212296, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:30:22] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:30:22] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:30:22] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:30:22] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:30:22] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5790587663650513, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8138138138138138, 'eval_runtime': 0.6156, 'eval_samples_per_second': 662.783, 'eval_steps_per_second': 21.118, 'epoch': 4.0}\n",
            "Progress: 73/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:30:23] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:30:23] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:30:23] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:30:23]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:30:23]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:30:23]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:30:23]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:30:23]   CPU count: 8\n",
            "[codecarbon INFO @ 00:30:23]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:30:23]   GPU count: 1\n",
            "[codecarbon INFO @ 00:30:23]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5753757357597351, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8132530120481928, 'eval_runtime': 0.7225, 'eval_samples_per_second': 564.736, 'eval_steps_per_second': 9.689, 'epoch': 1.0}\n",
            "{'eval_loss': 0.550995409488678, 'eval_accuracy': 0.7328431372549019, 'eval_f1': 0.8304821150855366, 'eval_runtime': 0.5961, 'eval_samples_per_second': 684.403, 'eval_steps_per_second': 11.742, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5720232129096985, 'eval_accuracy': 0.7598039215686274, 'eval_f1': 0.8434504792332268, 'eval_runtime': 0.5967, 'eval_samples_per_second': 683.706, 'eval_steps_per_second': 11.73, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:30:31] Energy consumed for RAM : 0.000043 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:30:31] Energy consumed for all GPUs : 0.000125 kWh. Total GPU Power : 55.2156805611925 W\n",
            "[codecarbon INFO @ 00:30:31] Energy consumed for all CPUs : 0.000096 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:30:31] 0.000264 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5971444249153137, 'eval_accuracy': 0.75, 'eval_f1': 0.8386075949367089, 'eval_runtime': 0.6343, 'eval_samples_per_second': 643.245, 'eval_steps_per_second': 11.036, 'epoch': 4.0}\n",
            "{'train_runtime': 7.5122, 'train_samples_per_second': 1953.084, 'train_steps_per_second': 30.883, 'train_loss': 0.4707464020827721, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:30:32] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:30:32] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:30:32] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:30:32] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:30:32] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5971444249153137, 'eval_accuracy': 0.75, 'eval_f1': 0.8386075949367089, 'eval_runtime': 0.6328, 'eval_samples_per_second': 644.789, 'eval_steps_per_second': 11.063, 'epoch': 4.0}\n",
            "Progress: 74/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:30:33] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:30:33] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:30:33] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:30:33]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:30:33]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:30:33]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:30:33]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:30:33]   CPU count: 8\n",
            "[codecarbon INFO @ 00:30:33]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:30:33]   GPU count: 1\n",
            "[codecarbon INFO @ 00:30:33]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.594853937625885, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8169838945827232, 'eval_runtime': 0.588, 'eval_samples_per_second': 693.931, 'eval_steps_per_second': 11.906, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5708560943603516, 'eval_accuracy': 0.7009803921568627, 'eval_f1': 0.8117283950617284, 'eval_runtime': 0.6006, 'eval_samples_per_second': 679.293, 'eval_steps_per_second': 11.655, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5739648938179016, 'eval_accuracy': 0.7230392156862745, 'eval_f1': 0.8269525267993875, 'eval_runtime': 0.603, 'eval_samples_per_second': 676.604, 'eval_steps_per_second': 11.608, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:30:41] Energy consumed for RAM : 0.000042 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:30:41] Energy consumed for all GPUs : 0.000123 kWh. Total GPU Power : 55.826242132382205 W\n",
            "[codecarbon INFO @ 00:30:41] Energy consumed for all CPUs : 0.000094 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:30:41] 0.000259 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5612186193466187, 'eval_accuracy': 0.7303921568627451, 'eval_f1': 0.8297213622291022, 'eval_runtime': 0.5946, 'eval_samples_per_second': 686.17, 'eval_steps_per_second': 11.773, 'epoch': 4.0}\n",
            "{'train_runtime': 7.3338, 'train_samples_per_second': 2000.591, 'train_steps_per_second': 31.634, 'train_loss': 0.5603954052102977, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:30:42] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:30:42] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:30:42] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:30:42] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:30:42] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5612186193466187, 'eval_accuracy': 0.7303921568627451, 'eval_f1': 0.8297213622291022, 'eval_runtime': 0.6847, 'eval_samples_per_second': 595.852, 'eval_steps_per_second': 10.223, 'epoch': 4.0}\n",
            "Progress: 75/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:30:43] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:30:43] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:30:43] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:30:43]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:30:43]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:30:43]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:30:43]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:30:43]   CPU count: 8\n",
            "[codecarbon INFO @ 00:30:43]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:30:43]   GPU count: 1\n",
            "[codecarbon INFO @ 00:30:43]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6062899231910706, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.6197, 'eval_samples_per_second': 658.398, 'eval_steps_per_second': 11.296, 'epoch': 1.0}\n",
            "{'eval_loss': 0.590184211730957, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8212703101920237, 'eval_runtime': 0.5943, 'eval_samples_per_second': 686.571, 'eval_steps_per_second': 11.779, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5828689932823181, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8143712574850299, 'eval_runtime': 0.6145, 'eval_samples_per_second': 663.996, 'eval_steps_per_second': 11.392, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:30:51] Energy consumed for RAM : 0.000043 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:30:51] Energy consumed for all GPUs : 0.000125 kWh. Total GPU Power : 54.90529478589501 W\n",
            "[codecarbon INFO @ 00:30:51] Energy consumed for all CPUs : 0.000097 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:30:51] 0.000265 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5777505040168762, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8078668683812406, 'eval_runtime': 0.7796, 'eval_samples_per_second': 523.367, 'eval_steps_per_second': 8.979, 'epoch': 4.0}\n",
            "{'train_runtime': 7.5329, 'train_samples_per_second': 1947.711, 'train_steps_per_second': 30.798, 'train_loss': 0.5961887096536571, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:30:52] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:30:52] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:30:52] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:30:52] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:30:52] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5777505040168762, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8078668683812406, 'eval_runtime': 0.6013, 'eval_samples_per_second': 678.551, 'eval_steps_per_second': 11.642, 'epoch': 4.0}\n",
            "Progress: 76/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:30:53] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:30:53] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:30:53] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:30:53]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:30:53]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:30:53]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:30:53]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:30:53]   CPU count: 8\n",
            "[codecarbon INFO @ 00:30:53]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:30:53]   GPU count: 1\n",
            "[codecarbon INFO @ 00:30:53]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6178915500640869, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.5975, 'eval_samples_per_second': 682.818, 'eval_steps_per_second': 11.715, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6015655398368835, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.6403, 'eval_samples_per_second': 637.218, 'eval_steps_per_second': 10.933, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5944027900695801, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8181818181818182, 'eval_runtime': 0.5864, 'eval_samples_per_second': 695.767, 'eval_steps_per_second': 11.937, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:31:01] Energy consumed for RAM : 0.000043 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:31:01] Energy consumed for all GPUs : 0.000124 kWh. Total GPU Power : 55.53696006658071 W\n",
            "[codecarbon INFO @ 00:31:01] Energy consumed for all CPUs : 0.000095 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:31:01] 0.000261 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5916686058044434, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8217967599410898, 'eval_runtime': 0.5946, 'eval_samples_per_second': 686.132, 'eval_steps_per_second': 11.772, 'epoch': 4.0}\n",
            "{'train_runtime': 7.4008, 'train_samples_per_second': 1982.477, 'train_steps_per_second': 31.348, 'train_loss': 0.6165741229879445, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:31:02] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:31:02] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:31:02] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:31:02] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:31:02] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5916686058044434, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8217967599410898, 'eval_runtime': 0.5966, 'eval_samples_per_second': 683.886, 'eval_steps_per_second': 11.733, 'epoch': 4.0}\n",
            "Progress: 77/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:31:03] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:31:03] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:31:03] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:31:03]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:31:03]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:31:03]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:31:03]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:31:03]   CPU count: 8\n",
            "[codecarbon INFO @ 00:31:03]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:31:03]   GPU count: 1\n",
            "[codecarbon INFO @ 00:31:03]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6026797890663147, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.808446455505279, 'eval_runtime': 0.5864, 'eval_samples_per_second': 695.728, 'eval_steps_per_second': 6.821, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5666956901550293, 'eval_accuracy': 0.7205882352941176, 'eval_f1': 0.821875, 'eval_runtime': 0.6078, 'eval_samples_per_second': 671.312, 'eval_steps_per_second': 6.581, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5767462253570557, 'eval_accuracy': 0.7279411764705882, 'eval_f1': 0.8262910798122066, 'eval_runtime': 0.5843, 'eval_samples_per_second': 698.271, 'eval_steps_per_second': 6.846, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:31:10] Energy consumed for RAM : 0.000039 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:31:10] Energy consumed for all GPUs : 0.000109 kWh. Total GPU Power : 53.38896948433578 W\n",
            "[codecarbon INFO @ 00:31:10] Energy consumed for all CPUs : 0.000086 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:31:10] 0.000234 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5759289264678955, 'eval_accuracy': 0.7352941176470589, 'eval_f1': 0.8291139240506329, 'eval_runtime': 0.6008, 'eval_samples_per_second': 679.104, 'eval_steps_per_second': 6.658, 'epoch': 4.0}\n",
            "{'train_runtime': 6.7086, 'train_samples_per_second': 2187.048, 'train_steps_per_second': 17.291, 'train_loss': 0.5189324411852606, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:31:11] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:31:11] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:31:11] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:31:11] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:31:11] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5759289264678955, 'eval_accuracy': 0.7352941176470589, 'eval_f1': 0.8291139240506329, 'eval_runtime': 0.6859, 'eval_samples_per_second': 594.816, 'eval_steps_per_second': 5.832, 'epoch': 4.0}\n",
            "Progress: 78/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:31:12] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:31:12] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:31:12] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:31:12]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:31:12]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:31:12]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:31:12]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:31:12]   CPU count: 8\n",
            "[codecarbon INFO @ 00:31:12]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:31:12]   GPU count: 1\n",
            "[codecarbon INFO @ 00:31:12]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6038169264793396, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.6023, 'eval_samples_per_second': 677.385, 'eval_steps_per_second': 6.641, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5951903462409973, 'eval_accuracy': 0.7058823529411765, 'eval_f1': 0.8224852071005917, 'eval_runtime': 0.5818, 'eval_samples_per_second': 701.219, 'eval_steps_per_second': 6.875, 'epoch': 2.0}\n",
            "{'eval_loss': 0.579287052154541, 'eval_accuracy': 0.6911764705882353, 'eval_f1': 0.8090909090909091, 'eval_runtime': 0.6465, 'eval_samples_per_second': 631.131, 'eval_steps_per_second': 6.188, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:31:20] Energy consumed for RAM : 0.000040 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:31:20] Energy consumed for all GPUs : 0.000110 kWh. Total GPU Power : 53.27632054284838 W\n",
            "[codecarbon INFO @ 00:31:20] Energy consumed for all CPUs : 0.000088 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:31:20] 0.000238 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5748432874679565, 'eval_accuracy': 0.6911764705882353, 'eval_f1': 0.8073394495412844, 'eval_runtime': 0.6337, 'eval_samples_per_second': 643.876, 'eval_steps_per_second': 6.313, 'epoch': 4.0}\n",
            "{'train_runtime': 6.7895, 'train_samples_per_second': 2160.995, 'train_steps_per_second': 17.085, 'train_loss': 0.5897226004764952, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:31:20] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:31:20] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:31:20] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:31:20] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:31:20] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5748432874679565, 'eval_accuracy': 0.6911764705882353, 'eval_f1': 0.8073394495412844, 'eval_runtime': 0.5981, 'eval_samples_per_second': 682.153, 'eval_steps_per_second': 6.688, 'epoch': 4.0}\n",
            "Progress: 79/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:31:22] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:31:22] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:31:22] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:31:22]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:31:22]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:31:22]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:31:22]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:31:22]   CPU count: 8\n",
            "[codecarbon INFO @ 00:31:22]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:31:22]   GPU count: 1\n",
            "[codecarbon INFO @ 00:31:22]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6207587718963623, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.6134, 'eval_samples_per_second': 665.125, 'eval_steps_per_second': 6.521, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6050003170967102, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.5886, 'eval_samples_per_second': 693.188, 'eval_steps_per_second': 6.796, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5970742106437683, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8145985401459854, 'eval_runtime': 0.6082, 'eval_samples_per_second': 670.833, 'eval_steps_per_second': 6.577, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:31:29] Energy consumed for RAM : 0.000039 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:31:29] Energy consumed for all GPUs : 0.000110 kWh. Total GPU Power : 53.59826799130786 W\n",
            "[codecarbon INFO @ 00:31:29] Energy consumed for all CPUs : 0.000088 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:31:29] 0.000237 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5952083468437195, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8169838945827232, 'eval_runtime': 0.6256, 'eval_samples_per_second': 652.167, 'eval_steps_per_second': 6.394, 'epoch': 4.0}\n",
            "{'train_runtime': 6.7819, 'train_samples_per_second': 2163.412, 'train_steps_per_second': 17.104, 'train_loss': 0.6204661007585197, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:31:30] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:31:30] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:31:30] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:31:30] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:31:30] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5952083468437195, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8169838945827232, 'eval_runtime': 0.6046, 'eval_samples_per_second': 674.83, 'eval_steps_per_second': 6.616, 'epoch': 4.0}\n",
            "Progress: 80/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:31:31] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:31:31] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:31:31] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:31:31]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:31:31]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:31:31]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:31:31]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:31:31]   CPU count: 8\n",
            "[codecarbon INFO @ 00:31:31]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:31:31]   GPU count: 1\n",
            "[codecarbon INFO @ 00:31:31]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6439599990844727, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.5948, 'eval_samples_per_second': 685.898, 'eval_steps_per_second': 6.724, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6185536980628967, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.6009, 'eval_samples_per_second': 679.016, 'eval_steps_per_second': 6.657, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6116704344749451, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.5908, 'eval_samples_per_second': 690.605, 'eval_steps_per_second': 6.771, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:31:38] Energy consumed for RAM : 0.000039 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:31:38] Energy consumed for all GPUs : 0.000110 kWh. Total GPU Power : 53.5343696895187 W\n",
            "[codecarbon INFO @ 00:31:38] Energy consumed for all CPUs : 0.000088 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:31:38] 0.000238 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.609874427318573, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.593, 'eval_samples_per_second': 688.025, 'eval_steps_per_second': 6.745, 'epoch': 4.0}\n",
            "{'train_runtime': 6.7935, 'train_samples_per_second': 2159.699, 'train_steps_per_second': 17.075, 'train_loss': 0.6398460125101024, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:31:39] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:31:39] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:31:39] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:31:39] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:31:39] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.609874427318573, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.6169, 'eval_samples_per_second': 661.357, 'eval_steps_per_second': 6.484, 'epoch': 4.0}\n",
            "Progress: 81/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:31:40] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:31:40] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:31:40] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:31:40]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:31:40]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:31:40]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:31:40]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:31:40]   CPU count: 8\n",
            "[codecarbon INFO @ 00:31:40]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:31:40]   GPU count: 1\n",
            "[codecarbon INFO @ 00:31:40]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.57334303855896, 'eval_accuracy': 0.7132352941176471, 'eval_f1': 0.8186046511627907, 'eval_runtime': 0.7985, 'eval_samples_per_second': 510.945, 'eval_steps_per_second': 63.868, 'epoch': 1.0}\n",
            "{'loss': 0.6026, 'grad_norm': 2.707974910736084, 'learning_rate': 0.00021830065359477123, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.5893756747245789, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.802610114192496, 'eval_runtime': 0.7638, 'eval_samples_per_second': 534.203, 'eval_steps_per_second': 66.775, 'epoch': 2.0}\n",
            "{'loss': 0.4794, 'grad_norm': 18.406923294067383, 'learning_rate': 0.00013660130718954247, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:31:55] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:31:55] Energy consumed for all GPUs : 0.000159 kWh. Total GPU Power : 38.163601647896044 W\n",
            "[codecarbon INFO @ 00:31:55] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:31:55] 0.000416 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.9547463059425354, 'eval_accuracy': 0.6495098039215687, 'eval_f1': 0.7404718693284936, 'eval_runtime': 0.7603, 'eval_samples_per_second': 536.641, 'eval_steps_per_second': 67.08, 'epoch': 3.0}\n",
            "{'loss': 0.3262, 'grad_norm': 5.297708511352539, 'learning_rate': 5.4901960784313716e-05, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:32:05] Energy consumed for RAM : 0.000128 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:32:05] Energy consumed for all GPUs : 0.000255 kWh. Total GPU Power : 37.70555267057316 W\n",
            "[codecarbon INFO @ 00:32:05] Energy consumed for all CPUs : 0.000286 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:32:05] 0.000669 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 1.136927604675293, 'eval_accuracy': 0.6764705882352942, 'eval_f1': 0.7700348432055749, 'eval_runtime': 0.7524, 'eval_samples_per_second': 542.279, 'eval_steps_per_second': 67.785, 'epoch': 4.0}\n",
            "{'train_runtime': 23.5654, 'train_samples_per_second': 622.607, 'train_steps_per_second': 77.911, 'train_loss': 0.42590306267499406, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:32:05] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:32:05] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:32:05] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:32:05] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:32:05] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 1.136927604675293, 'eval_accuracy': 0.6764705882352942, 'eval_f1': 0.7700348432055749, 'eval_runtime': 0.7748, 'eval_samples_per_second': 526.621, 'eval_steps_per_second': 65.828, 'epoch': 4.0}\n",
            "Progress: 82/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:32:07] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:32:07] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:32:07] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:32:07]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:32:07]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:32:07]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:32:07]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:32:07]   CPU count: 8\n",
            "[codecarbon INFO @ 00:32:07]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:32:07]   GPU count: 1\n",
            "[codecarbon INFO @ 00:32:07]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.571905791759491, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8169440242057489, 'eval_runtime': 0.7497, 'eval_samples_per_second': 544.184, 'eval_steps_per_second': 68.023, 'epoch': 1.0}\n",
            "{'loss': 0.5884, 'grad_norm': 4.293759822845459, 'learning_rate': 7.276688453159042e-05, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.5654860734939575, 'eval_accuracy': 0.7352941176470589, 'eval_f1': 0.8285714285714286, 'eval_runtime': 0.7723, 'eval_samples_per_second': 528.323, 'eval_steps_per_second': 66.04, 'epoch': 2.0}\n",
            "{'loss': 0.4993, 'grad_norm': 8.675013542175293, 'learning_rate': 4.5533769063180834e-05, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:32:22] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:32:22] Energy consumed for all GPUs : 0.000157 kWh. Total GPU Power : 37.677252112605686 W\n",
            "[codecarbon INFO @ 00:32:22] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:32:22] 0.000414 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6270501613616943, 'eval_accuracy': 0.7352941176470589, 'eval_f1': 0.8296529968454258, 'eval_runtime': 0.7368, 'eval_samples_per_second': 553.765, 'eval_steps_per_second': 69.221, 'epoch': 3.0}\n",
            "{'loss': 0.4045, 'grad_norm': 26.807472229003906, 'learning_rate': 1.8300653594771242e-05, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:32:31] Energy consumed for RAM : 0.000129 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:32:31] Energy consumed for all GPUs : 0.000255 kWh. Total GPU Power : 37.971270631795164 W\n",
            "[codecarbon INFO @ 00:32:31] Energy consumed for all CPUs : 0.000287 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:32:31] 0.000670 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6656573414802551, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8325508607198748, 'eval_runtime': 0.7955, 'eval_samples_per_second': 512.871, 'eval_steps_per_second': 64.109, 'epoch': 4.0}\n",
            "{'train_runtime': 23.6062, 'train_samples_per_second': 621.532, 'train_steps_per_second': 77.776, 'train_loss': 0.47345523792674077, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:32:32] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:32:32] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:32:32] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:32:32] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:32:32] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6656573414802551, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8325508607198748, 'eval_runtime': 0.7578, 'eval_samples_per_second': 538.429, 'eval_steps_per_second': 67.304, 'epoch': 4.0}\n",
            "Progress: 83/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:32:33] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:32:33] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:32:33] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:32:33]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:32:33]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:32:33]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:32:33]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:32:33]   CPU count: 8\n",
            "[codecarbon INFO @ 00:32:33]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:32:33]   GPU count: 1\n",
            "[codecarbon INFO @ 00:32:33]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5733863711357117, 'eval_accuracy': 0.7009803921568627, 'eval_f1': 0.8134556574923547, 'eval_runtime': 0.7524, 'eval_samples_per_second': 542.265, 'eval_steps_per_second': 67.783, 'epoch': 1.0}\n",
            "{'loss': 0.6013, 'grad_norm': 4.323869228363037, 'learning_rate': 3.638344226579521e-05, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.5774785876274109, 'eval_accuracy': 0.7083333333333334, 'eval_f1': 0.8194233687405159, 'eval_runtime': 0.7452, 'eval_samples_per_second': 547.487, 'eval_steps_per_second': 68.436, 'epoch': 2.0}\n",
            "{'loss': 0.5438, 'grad_norm': 5.283394813537598, 'learning_rate': 2.2766884531590417e-05, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:32:48] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:32:48] Energy consumed for all GPUs : 0.000158 kWh. Total GPU Power : 37.8146148382403 W\n",
            "[codecarbon INFO @ 00:32:48] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:32:48] 0.000414 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5611313581466675, 'eval_accuracy': 0.7279411764705882, 'eval_f1': 0.8246445497630331, 'eval_runtime': 0.7693, 'eval_samples_per_second': 530.382, 'eval_steps_per_second': 66.298, 'epoch': 3.0}\n",
            "{'loss': 0.4849, 'grad_norm': 14.096569061279297, 'learning_rate': 9.150326797385621e-06, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:32:57] Energy consumed for RAM : 0.000128 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:32:57] Energy consumed for all GPUs : 0.000252 kWh. Total GPU Power : 37.28430329195994 W\n",
            "[codecarbon INFO @ 00:32:57] Energy consumed for all CPUs : 0.000285 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:32:57] 0.000665 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.587859570980072, 'eval_accuracy': 0.7279411764705882, 'eval_f1': 0.8268330733229329, 'eval_runtime': 0.7677, 'eval_samples_per_second': 531.464, 'eval_steps_per_second': 66.433, 'epoch': 4.0}\n",
            "{'train_runtime': 23.4996, 'train_samples_per_second': 624.351, 'train_steps_per_second': 78.129, 'train_loss': 0.5309766798497285, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:32:58] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:32:58] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:32:58] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:32:58] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:32:58] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.587859570980072, 'eval_accuracy': 0.7279411764705882, 'eval_f1': 0.8268330733229329, 'eval_runtime': 0.7442, 'eval_samples_per_second': 548.228, 'eval_steps_per_second': 68.528, 'epoch': 4.0}\n",
            "Progress: 84/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:32:59] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:32:59] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:32:59] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:32:59]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:32:59]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:32:59]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:32:59]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:32:59]   CPU count: 8\n",
            "[codecarbon INFO @ 00:32:59]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:32:59]   GPU count: 1\n",
            "[codecarbon INFO @ 00:32:59]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5838139653205872, 'eval_accuracy': 0.7009803921568627, 'eval_f1': 0.8184523809523809, 'eval_runtime': 0.7965, 'eval_samples_per_second': 512.269, 'eval_steps_per_second': 64.034, 'epoch': 1.0}\n",
            "{'loss': 0.6134, 'grad_norm': 2.5178942680358887, 'learning_rate': 2.1830065359477124e-05, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.5830901861190796, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8180451127819549, 'eval_runtime': 0.8109, 'eval_samples_per_second': 503.121, 'eval_steps_per_second': 62.89, 'epoch': 2.0}\n",
            "{'loss': 0.5689, 'grad_norm': 4.079008102416992, 'learning_rate': 1.366013071895425e-05, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:33:14] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:33:14] Energy consumed for all GPUs : 0.000156 kWh. Total GPU Power : 37.436222727726246 W\n",
            "[codecarbon INFO @ 00:33:14] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:33:14] 0.000413 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.568699836730957, 'eval_accuracy': 0.7132352941176471, 'eval_f1': 0.8197226502311248, 'eval_runtime': 0.8668, 'eval_samples_per_second': 470.688, 'eval_steps_per_second': 58.836, 'epoch': 3.0}\n",
            "{'loss': 0.5302, 'grad_norm': 6.041450023651123, 'learning_rate': 5.490196078431373e-06, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:33:24] Energy consumed for RAM : 0.000129 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:33:24] Energy consumed for all GPUs : 0.000253 kWh. Total GPU Power : 37.685338473879334 W\n",
            "[codecarbon INFO @ 00:33:24] Energy consumed for all CPUs : 0.000287 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:33:24] 0.000669 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5771942734718323, 'eval_accuracy': 0.7107843137254902, 'eval_f1': 0.8195718654434251, 'eval_runtime': 0.7786, 'eval_samples_per_second': 524.029, 'eval_steps_per_second': 65.504, 'epoch': 4.0}\n",
            "{'train_runtime': 23.6231, 'train_samples_per_second': 621.088, 'train_steps_per_second': 77.721, 'train_loss': 0.5637553262814458, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:33:24] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:33:24] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:33:24] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:33:24] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:33:24] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5771942734718323, 'eval_accuracy': 0.7107843137254902, 'eval_f1': 0.8195718654434251, 'eval_runtime': 0.7541, 'eval_samples_per_second': 541.008, 'eval_steps_per_second': 67.626, 'epoch': 4.0}\n",
            "Progress: 85/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:33:25] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:33:25] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:33:25] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:33:25]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:33:25]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:33:25]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:33:25]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:33:25]   CPU count: 8\n",
            "[codecarbon INFO @ 00:33:25]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:33:25]   GPU count: 1\n",
            "[codecarbon INFO @ 00:33:25]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5624045133590698, 'eval_accuracy': 0.7230392156862745, 'eval_f1': 0.8231611893583725, 'eval_runtime': 0.7422, 'eval_samples_per_second': 549.692, 'eval_steps_per_second': 35.029, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5531349778175354, 'eval_accuracy': 0.7328431372549019, 'eval_f1': 0.8256, 'eval_runtime': 0.6737, 'eval_samples_per_second': 605.606, 'eval_steps_per_second': 38.593, 'epoch': 2.0}\n",
            "{'loss': 0.5239, 'grad_norm': 15.012598991394043, 'learning_rate': 0.00013695652173913042, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.590812087059021, 'eval_accuracy': 0.7401960784313726, 'eval_f1': 0.8221476510067114, 'eval_runtime': 0.6809, 'eval_samples_per_second': 599.247, 'eval_steps_per_second': 38.187, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:33:40] Energy consumed for RAM : 0.000078 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:33:40] Energy consumed for all GPUs : 0.000165 kWh. Total GPU Power : 40.59122500825253 W\n",
            "[codecarbon INFO @ 00:33:40] Energy consumed for all CPUs : 0.000173 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:33:40] 0.000415 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7519146800041199, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8243021346469622, 'eval_runtime': 0.648, 'eval_samples_per_second': 629.623, 'eval_steps_per_second': 40.123, 'epoch': 4.0}\n",
            "{'train_runtime': 14.0137, 'train_samples_per_second': 1046.972, 'train_steps_per_second': 65.65, 'train_loss': 0.40669037362803584, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:33:41] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:33:41] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:33:41] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:33:41] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:33:41] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7519146800041199, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8243021346469622, 'eval_runtime': 0.6815, 'eval_samples_per_second': 598.644, 'eval_steps_per_second': 38.149, 'epoch': 4.0}\n",
            "Progress: 86/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:33:42] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:33:42] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:33:42] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:33:42]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:33:42]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:33:42]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:33:42]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:33:42]   CPU count: 8\n",
            "[codecarbon INFO @ 00:33:42]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:33:42]   GPU count: 1\n",
            "[codecarbon INFO @ 00:33:42]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.564354419708252, 'eval_accuracy': 0.7132352941176471, 'eval_f1': 0.8180404354587869, 'eval_runtime': 0.6662, 'eval_samples_per_second': 612.417, 'eval_steps_per_second': 39.027, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5474852919578552, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.831496062992126, 'eval_runtime': 0.6777, 'eval_samples_per_second': 602.063, 'eval_steps_per_second': 38.367, 'epoch': 2.0}\n",
            "{'loss': 0.5577, 'grad_norm': 6.763742923736572, 'learning_rate': 4.565217391304348e-05, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.5569795966148376, 'eval_accuracy': 0.7426470588235294, 'eval_f1': 0.8330683624801272, 'eval_runtime': 0.6741, 'eval_samples_per_second': 605.265, 'eval_steps_per_second': 38.571, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:33:57] Energy consumed for RAM : 0.000077 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:33:57] Energy consumed for all GPUs : 0.000165 kWh. Total GPU Power : 40.780720395844774 W\n",
            "[codecarbon INFO @ 00:33:57] Energy consumed for all CPUs : 0.000172 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:33:57] 0.000414 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5896832346916199, 'eval_accuracy': 0.7328431372549019, 'eval_f1': 0.8299531981279251, 'eval_runtime': 0.7129, 'eval_samples_per_second': 572.332, 'eval_steps_per_second': 36.472, 'epoch': 4.0}\n",
            "{'train_runtime': 13.9478, 'train_samples_per_second': 1051.925, 'train_steps_per_second': 65.96, 'train_loss': 0.5020559891410495, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:33:57] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:33:57] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:33:57] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:33:57] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:33:57] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5896832346916199, 'eval_accuracy': 0.7328431372549019, 'eval_f1': 0.8299531981279251, 'eval_runtime': 0.6731, 'eval_samples_per_second': 606.137, 'eval_steps_per_second': 38.626, 'epoch': 4.0}\n",
            "Progress: 87/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:33:59] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:33:59] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:33:59] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:33:59]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:33:59]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:33:59]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:33:59]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:33:59]   CPU count: 8\n",
            "[codecarbon INFO @ 00:33:59]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:33:59]   GPU count: 1\n",
            "[codecarbon INFO @ 00:33:59]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5816411972045898, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8095952023988006, 'eval_runtime': 0.6851, 'eval_samples_per_second': 595.511, 'eval_steps_per_second': 37.949, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5781240463256836, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8185907046476761, 'eval_runtime': 0.6602, 'eval_samples_per_second': 617.983, 'eval_steps_per_second': 39.381, 'epoch': 2.0}\n",
            "{'loss': 0.5845, 'grad_norm': 4.170251846313477, 'learning_rate': 2.282608695652174e-05, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.568314790725708, 'eval_accuracy': 0.7083333333333334, 'eval_f1': 0.8183206106870229, 'eval_runtime': 0.6514, 'eval_samples_per_second': 626.38, 'eval_steps_per_second': 39.916, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:34:13] Energy consumed for RAM : 0.000077 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:34:13] Energy consumed for all GPUs : 0.000164 kWh. Total GPU Power : 40.50858085444893 W\n",
            "[codecarbon INFO @ 00:34:13] Energy consumed for all CPUs : 0.000172 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:34:13] 0.000413 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.568650484085083, 'eval_accuracy': 0.7205882352941176, 'eval_f1': 0.8246153846153846, 'eval_runtime': 0.6794, 'eval_samples_per_second': 600.529, 'eval_steps_per_second': 38.269, 'epoch': 4.0}\n",
            "{'train_runtime': 13.9433, 'train_samples_per_second': 1052.259, 'train_steps_per_second': 65.981, 'train_loss': 0.5531564961309018, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:34:14] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:34:14] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:34:14] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:34:14] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:34:14] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.568650484085083, 'eval_accuracy': 0.7205882352941176, 'eval_f1': 0.8246153846153846, 'eval_runtime': 0.7017, 'eval_samples_per_second': 581.42, 'eval_steps_per_second': 37.051, 'epoch': 4.0}\n",
            "Progress: 88/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:34:15] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:34:15] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:34:15] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:34:15]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:34:15]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:34:15]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:34:15]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:34:15]   CPU count: 8\n",
            "[codecarbon INFO @ 00:34:15]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:34:15]   GPU count: 1\n",
            "[codecarbon INFO @ 00:34:15]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5934128761291504, 'eval_accuracy': 0.6985294117647058, 'eval_f1': 0.8193832599118943, 'eval_runtime': 0.675, 'eval_samples_per_second': 604.488, 'eval_steps_per_second': 38.521, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5834196209907532, 'eval_accuracy': 0.6985294117647058, 'eval_f1': 0.8161434977578476, 'eval_runtime': 0.6532, 'eval_samples_per_second': 624.57, 'eval_steps_per_second': 39.801, 'epoch': 2.0}\n",
            "{'loss': 0.6021, 'grad_norm': 2.227717161178589, 'learning_rate': 1.3695652173913042e-05, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.574123740196228, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8114630467571644, 'eval_runtime': 0.6848, 'eval_samples_per_second': 595.818, 'eval_steps_per_second': 37.969, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:34:30] Energy consumed for RAM : 0.000077 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:34:30] Energy consumed for all GPUs : 0.000165 kWh. Total GPU Power : 41.14166620187173 W\n",
            "[codecarbon INFO @ 00:34:30] Energy consumed for all CPUs : 0.000171 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:34:30] 0.000412 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5735155940055847, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8126888217522659, 'eval_runtime': 0.6599, 'eval_samples_per_second': 618.246, 'eval_steps_per_second': 39.398, 'epoch': 4.0}\n",
            "{'train_runtime': 13.8526, 'train_samples_per_second': 1059.15, 'train_steps_per_second': 66.413, 'train_loss': 0.580059698353643, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:34:31] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:34:31] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:34:31] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:34:31] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:34:31] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5735155940055847, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8126888217522659, 'eval_runtime': 0.7044, 'eval_samples_per_second': 579.182, 'eval_steps_per_second': 36.909, 'epoch': 4.0}\n",
            "Progress: 89/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:34:32] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:34:32] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:34:32] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:34:32]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:34:32]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:34:32]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:34:32]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:34:32]   CPU count: 8\n",
            "[codecarbon INFO @ 00:34:32]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:34:32]   GPU count: 1\n",
            "[codecarbon INFO @ 00:34:32]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5496113896369934, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.831496062992126, 'eval_runtime': 0.618, 'eval_samples_per_second': 660.223, 'eval_steps_per_second': 21.037, 'epoch': 1.0}\n",
            "{'eval_loss': 0.552695095539093, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8309636650868878, 'eval_runtime': 0.6141, 'eval_samples_per_second': 664.407, 'eval_steps_per_second': 21.17, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6253054141998291, 'eval_accuracy': 0.7450980392156863, 'eval_f1': 0.8354430379746836, 'eval_runtime': 0.7337, 'eval_samples_per_second': 556.119, 'eval_steps_per_second': 17.719, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:34:42] Energy consumed for RAM : 0.000054 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:34:42] Energy consumed for all GPUs : 0.000138 kWh. Total GPU Power : 49.15825584744905 W\n",
            "[codecarbon INFO @ 00:34:42] Energy consumed for all CPUs : 0.000119 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:34:42] 0.000310 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6537364721298218, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8304278922345484, 'eval_runtime': 0.6297, 'eval_samples_per_second': 647.941, 'eval_steps_per_second': 20.645, 'epoch': 4.0}\n",
            "{'train_runtime': 9.4435, 'train_samples_per_second': 1553.667, 'train_steps_per_second': 48.711, 'train_loss': 0.43501543791397757, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:34:43] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:34:43] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:34:43] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:34:43] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:34:43] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6537364721298218, 'eval_accuracy': 0.7377450980392157, 'eval_f1': 0.8304278922345484, 'eval_runtime': 0.6178, 'eval_samples_per_second': 660.457, 'eval_steps_per_second': 21.044, 'epoch': 4.0}\n",
            "Progress: 90/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:34:44] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:34:44] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:34:44] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:34:44]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:34:44]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:34:44]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:34:44]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:34:44]   CPU count: 8\n",
            "[codecarbon INFO @ 00:34:44]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:34:44]   GPU count: 1\n",
            "[codecarbon INFO @ 00:34:44]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.585704505443573, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.81089258698941, 'eval_runtime': 0.6358, 'eval_samples_per_second': 641.689, 'eval_steps_per_second': 20.446, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5598652958869934, 'eval_accuracy': 0.7181372549019608, 'eval_f1': 0.8205928237129485, 'eval_runtime': 0.6196, 'eval_samples_per_second': 658.505, 'eval_steps_per_second': 20.982, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5700249075889587, 'eval_accuracy': 0.7132352941176471, 'eval_f1': 0.8186046511627907, 'eval_runtime': 0.6619, 'eval_samples_per_second': 616.391, 'eval_steps_per_second': 19.64, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:34:54] Energy consumed for RAM : 0.000053 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:34:54] Energy consumed for all GPUs : 0.000142 kWh. Total GPU Power : 50.897820795115074 W\n",
            "[codecarbon INFO @ 00:34:54] Energy consumed for all CPUs : 0.000119 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:34:54] 0.000314 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5717409253120422, 'eval_accuracy': 0.7254901960784313, 'eval_f1': 0.8255451713395638, 'eval_runtime': 0.6512, 'eval_samples_per_second': 626.545, 'eval_steps_per_second': 19.963, 'epoch': 4.0}\n",
            "{'train_runtime': 9.4482, 'train_samples_per_second': 1552.887, 'train_steps_per_second': 48.686, 'train_loss': 0.5322120666503907, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:34:55] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:34:55] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:34:55] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:34:55] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:34:55] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5717409253120422, 'eval_accuracy': 0.7254901960784313, 'eval_f1': 0.8255451713395638, 'eval_runtime': 0.7142, 'eval_samples_per_second': 571.285, 'eval_steps_per_second': 18.203, 'epoch': 4.0}\n",
            "Progress: 91/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:34:56] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:34:56] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:34:56] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:34:56]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:34:56]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:34:56]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:34:56]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:34:56]   CPU count: 8\n",
            "[codecarbon INFO @ 00:34:56]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:34:56]   GPU count: 1\n",
            "[codecarbon INFO @ 00:34:56]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5961236953735352, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8169838945827232, 'eval_runtime': 0.7975, 'eval_samples_per_second': 511.595, 'eval_steps_per_second': 16.301, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5710234045982361, 'eval_accuracy': 0.7058823529411765, 'eval_f1': 0.817629179331307, 'eval_runtime': 0.6417, 'eval_samples_per_second': 635.844, 'eval_steps_per_second': 20.26, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5729517340660095, 'eval_accuracy': 0.7083333333333334, 'eval_f1': 0.8199697428139183, 'eval_runtime': 0.6877, 'eval_samples_per_second': 593.294, 'eval_steps_per_second': 18.904, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:35:06] Energy consumed for RAM : 0.000054 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:35:06] Energy consumed for all GPUs : 0.000140 kWh. Total GPU Power : 49.50521191445355 W\n",
            "[codecarbon INFO @ 00:35:06] Energy consumed for all CPUs : 0.000120 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:35:06] 0.000315 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.56805819272995, 'eval_accuracy': 0.7107843137254902, 'eval_f1': 0.8201219512195121, 'eval_runtime': 0.6241, 'eval_samples_per_second': 653.776, 'eval_steps_per_second': 20.831, 'epoch': 4.0}\n",
            "{'train_runtime': 9.5895, 'train_samples_per_second': 1530.004, 'train_steps_per_second': 47.969, 'train_loss': 0.5740605893342391, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:35:07] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:35:07] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:35:07] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:35:07] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:35:07] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.56805819272995, 'eval_accuracy': 0.7107843137254902, 'eval_f1': 0.8201219512195121, 'eval_runtime': 0.6229, 'eval_samples_per_second': 654.971, 'eval_steps_per_second': 20.869, 'epoch': 4.0}\n",
            "Progress: 92/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:35:08] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:35:08] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:35:08] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:35:08]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:35:08]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:35:08]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:35:08]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:35:08]   CPU count: 8\n",
            "[codecarbon INFO @ 00:35:08]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:35:08]   GPU count: 1\n",
            "[codecarbon INFO @ 00:35:08]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6053450703620911, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.6541, 'eval_samples_per_second': 623.754, 'eval_steps_per_second': 19.875, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5885691046714783, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8212703101920237, 'eval_runtime': 0.6279, 'eval_samples_per_second': 649.804, 'eval_steps_per_second': 20.705, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5840325355529785, 'eval_accuracy': 0.6985294117647058, 'eval_f1': 0.8166915052160953, 'eval_runtime': 0.6104, 'eval_samples_per_second': 668.416, 'eval_steps_per_second': 21.298, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:35:18] Energy consumed for RAM : 0.000055 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:35:18] Energy consumed for all GPUs : 0.000141 kWh. Total GPU Power : 48.58517069570554 W\n",
            "[codecarbon INFO @ 00:35:18] Energy consumed for all CPUs : 0.000123 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:35:18] 0.000319 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5790587663650513, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8138138138138138, 'eval_runtime': 0.6319, 'eval_samples_per_second': 645.644, 'eval_steps_per_second': 20.572, 'epoch': 4.0}\n",
            "{'train_runtime': 9.445, 'train_samples_per_second': 1553.412, 'train_steps_per_second': 48.703, 'train_loss': 0.5975138125212296, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:35:19] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:35:19] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:35:19] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:35:19] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:35:19] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5790587663650513, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8138138138138138, 'eval_runtime': 0.6033, 'eval_samples_per_second': 676.322, 'eval_steps_per_second': 21.549, 'epoch': 4.0}\n",
            "Progress: 93/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:35:20] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:35:20] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:35:20] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:35:20]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:35:20]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:35:20]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:35:20]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:35:20]   CPU count: 8\n",
            "[codecarbon INFO @ 00:35:20]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:35:20]   GPU count: 1\n",
            "[codecarbon INFO @ 00:35:20]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5753757357597351, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8132530120481928, 'eval_runtime': 0.593, 'eval_samples_per_second': 688.042, 'eval_steps_per_second': 11.805, 'epoch': 1.0}\n",
            "{'eval_loss': 0.550995409488678, 'eval_accuracy': 0.7328431372549019, 'eval_f1': 0.8304821150855366, 'eval_runtime': 0.6069, 'eval_samples_per_second': 672.218, 'eval_steps_per_second': 11.533, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5720232129096985, 'eval_accuracy': 0.7598039215686274, 'eval_f1': 0.8434504792332268, 'eval_runtime': 0.5966, 'eval_samples_per_second': 683.853, 'eval_steps_per_second': 11.733, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:35:28] Energy consumed for RAM : 0.000042 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:35:28] Energy consumed for all GPUs : 0.000122 kWh. Total GPU Power : 55.46084695480783 W\n",
            "[codecarbon INFO @ 00:35:28] Energy consumed for all CPUs : 0.000094 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:35:28] 0.000258 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5971444249153137, 'eval_accuracy': 0.75, 'eval_f1': 0.8386075949367089, 'eval_runtime': 0.6009, 'eval_samples_per_second': 679.0, 'eval_steps_per_second': 11.65, 'epoch': 4.0}\n",
            "{'train_runtime': 7.314, 'train_samples_per_second': 2006.027, 'train_steps_per_second': 31.72, 'train_loss': 0.4707464020827721, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:35:29] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:35:29] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:35:29] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:35:29] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:35:29] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5971444249153137, 'eval_accuracy': 0.75, 'eval_f1': 0.8386075949367089, 'eval_runtime': 0.6337, 'eval_samples_per_second': 643.805, 'eval_steps_per_second': 11.046, 'epoch': 4.0}\n",
            "Progress: 94/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:35:30] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:35:30] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:35:30] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:35:30]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:35:30]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:35:30]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:35:30]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:35:30]   CPU count: 8\n",
            "[codecarbon INFO @ 00:35:30]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:35:30]   GPU count: 1\n",
            "[codecarbon INFO @ 00:35:30]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.594853937625885, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8169838945827232, 'eval_runtime': 0.5936, 'eval_samples_per_second': 687.315, 'eval_steps_per_second': 11.792, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5708560943603516, 'eval_accuracy': 0.7009803921568627, 'eval_f1': 0.8117283950617284, 'eval_runtime': 0.6074, 'eval_samples_per_second': 671.752, 'eval_steps_per_second': 11.525, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5739648938179016, 'eval_accuracy': 0.7230392156862745, 'eval_f1': 0.8269525267993875, 'eval_runtime': 0.5946, 'eval_samples_per_second': 686.147, 'eval_steps_per_second': 11.772, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:35:38] Energy consumed for RAM : 0.000042 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:35:38] Energy consumed for all GPUs : 0.000120 kWh. Total GPU Power : 54.333736801990234 W\n",
            "[codecarbon INFO @ 00:35:38] Energy consumed for all CPUs : 0.000094 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:35:38] 0.000255 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5612186193466187, 'eval_accuracy': 0.7303921568627451, 'eval_f1': 0.8297213622291022, 'eval_runtime': 0.6307, 'eval_samples_per_second': 646.948, 'eval_steps_per_second': 11.1, 'epoch': 4.0}\n",
            "{'train_runtime': 7.3253, 'train_samples_per_second': 2002.91, 'train_steps_per_second': 31.671, 'train_loss': 0.5603954052102977, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:35:39] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:35:39] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:35:39] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:35:39] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:35:39] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5612186193466187, 'eval_accuracy': 0.7303921568627451, 'eval_f1': 0.8297213622291022, 'eval_runtime': 0.5928, 'eval_samples_per_second': 688.304, 'eval_steps_per_second': 11.809, 'epoch': 4.0}\n",
            "Progress: 95/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:35:40] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:35:40] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:35:40] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:35:40]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:35:40]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:35:40]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:35:40]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:35:40]   CPU count: 8\n",
            "[codecarbon INFO @ 00:35:40]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:35:40]   GPU count: 1\n",
            "[codecarbon INFO @ 00:35:40]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6062899231910706, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.6814, 'eval_samples_per_second': 598.785, 'eval_steps_per_second': 10.273, 'epoch': 1.0}\n",
            "{'eval_loss': 0.590184211730957, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8212703101920237, 'eval_runtime': 0.591, 'eval_samples_per_second': 690.32, 'eval_steps_per_second': 11.844, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5828689932823181, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8143712574850299, 'eval_runtime': 0.5959, 'eval_samples_per_second': 684.637, 'eval_steps_per_second': 11.746, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:35:48] Energy consumed for RAM : 0.000043 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:35:48] Energy consumed for all GPUs : 0.000122 kWh. Total GPU Power : 54.36565839704877 W\n",
            "[codecarbon INFO @ 00:35:48] Energy consumed for all CPUs : 0.000096 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:35:48] 0.000261 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5777505040168762, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8078668683812406, 'eval_runtime': 0.6125, 'eval_samples_per_second': 666.126, 'eval_steps_per_second': 11.429, 'epoch': 4.0}\n",
            "{'train_runtime': 7.4518, 'train_samples_per_second': 1968.917, 'train_steps_per_second': 31.133, 'train_loss': 0.5961887096536571, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:35:49] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:35:49] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:35:49] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:35:49] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:35:49] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5777505040168762, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8078668683812406, 'eval_runtime': 0.652, 'eval_samples_per_second': 625.76, 'eval_steps_per_second': 10.736, 'epoch': 4.0}\n",
            "Progress: 96/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:35:50] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:35:50] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:35:50] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:35:50]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:35:50]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:35:50]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:35:50]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:35:50]   CPU count: 8\n",
            "[codecarbon INFO @ 00:35:50]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:35:50]   GPU count: 1\n",
            "[codecarbon INFO @ 00:35:50]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6178915500640869, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.5976, 'eval_samples_per_second': 682.706, 'eval_steps_per_second': 11.713, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6015655398368835, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.5961, 'eval_samples_per_second': 684.411, 'eval_steps_per_second': 11.742, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5944027900695801, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8181818181818182, 'eval_runtime': 0.5969, 'eval_samples_per_second': 683.504, 'eval_steps_per_second': 11.727, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:35:58] Energy consumed for RAM : 0.000043 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:35:58] Energy consumed for all GPUs : 0.000124 kWh. Total GPU Power : 55.949227033032365 W\n",
            "[codecarbon INFO @ 00:35:58] Energy consumed for all CPUs : 0.000095 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:35:58] 0.000261 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5916686058044434, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8217967599410898, 'eval_runtime': 0.602, 'eval_samples_per_second': 677.745, 'eval_steps_per_second': 11.628, 'epoch': 4.0}\n",
            "{'train_runtime': 7.3573, 'train_samples_per_second': 1994.211, 'train_steps_per_second': 31.533, 'train_loss': 0.6165741229879445, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:35:59] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:35:59] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:35:59] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:35:59] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:35:59] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5916686058044434, 'eval_accuracy': 0.7034313725490197, 'eval_f1': 0.8217967599410898, 'eval_runtime': 0.6124, 'eval_samples_per_second': 666.272, 'eval_steps_per_second': 11.431, 'epoch': 4.0}\n",
            "Progress: 97/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:36:00] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:36:00] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:36:00] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:36:00]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:36:00]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:36:00]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:36:00]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:36:00]   CPU count: 8\n",
            "[codecarbon INFO @ 00:36:00]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:36:00]   GPU count: 1\n",
            "[codecarbon INFO @ 00:36:00]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6026797890663147, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.808446455505279, 'eval_runtime': 0.6043, 'eval_samples_per_second': 675.163, 'eval_steps_per_second': 6.619, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5666956901550293, 'eval_accuracy': 0.7205882352941176, 'eval_f1': 0.821875, 'eval_runtime': 0.6128, 'eval_samples_per_second': 665.766, 'eval_steps_per_second': 6.527, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5767462253570557, 'eval_accuracy': 0.7279411764705882, 'eval_f1': 0.8262910798122066, 'eval_runtime': 0.5912, 'eval_samples_per_second': 690.18, 'eval_steps_per_second': 6.766, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:36:07] Energy consumed for RAM : 0.000039 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:36:07] Energy consumed for all GPUs : 0.000110 kWh. Total GPU Power : 53.895195015547145 W\n",
            "[codecarbon INFO @ 00:36:07] Energy consumed for all CPUs : 0.000087 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:36:07] 0.000236 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5759289264678955, 'eval_accuracy': 0.7352941176470589, 'eval_f1': 0.8291139240506329, 'eval_runtime': 0.6236, 'eval_samples_per_second': 654.305, 'eval_steps_per_second': 6.415, 'epoch': 4.0}\n",
            "{'train_runtime': 6.7396, 'train_samples_per_second': 2176.99, 'train_steps_per_second': 17.212, 'train_loss': 0.5189324411852606, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:36:08] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:36:08] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:36:08] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:36:08] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:36:08] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5759289264678955, 'eval_accuracy': 0.7352941176470589, 'eval_f1': 0.8291139240506329, 'eval_runtime': 0.6021, 'eval_samples_per_second': 677.589, 'eval_steps_per_second': 6.643, 'epoch': 4.0}\n",
            "Progress: 98/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:36:09] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:36:09] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:36:09] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:36:09]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:36:09]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:36:09]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:36:09]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:36:09]   CPU count: 8\n",
            "[codecarbon INFO @ 00:36:09]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:36:09]   GPU count: 1\n",
            "[codecarbon INFO @ 00:36:09]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6038169264793396, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.6016, 'eval_samples_per_second': 678.24, 'eval_steps_per_second': 6.649, 'epoch': 1.0}\n",
            "{'eval_loss': 0.5951903462409973, 'eval_accuracy': 0.7058823529411765, 'eval_f1': 0.8224852071005917, 'eval_runtime': 0.5907, 'eval_samples_per_second': 690.658, 'eval_steps_per_second': 6.771, 'epoch': 2.0}\n",
            "{'eval_loss': 0.579287052154541, 'eval_accuracy': 0.6911764705882353, 'eval_f1': 0.8090909090909091, 'eval_runtime': 0.763, 'eval_samples_per_second': 534.698, 'eval_steps_per_second': 5.242, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:36:17] Energy consumed for RAM : 0.000040 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:36:17] Energy consumed for all GPUs : 0.000111 kWh. Total GPU Power : 53.257109776570594 W\n",
            "[codecarbon INFO @ 00:36:17] Energy consumed for all CPUs : 0.000089 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:36:17] 0.000239 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5748432874679565, 'eval_accuracy': 0.6911764705882353, 'eval_f1': 0.8073394495412844, 'eval_runtime': 0.591, 'eval_samples_per_second': 690.403, 'eval_steps_per_second': 6.769, 'epoch': 4.0}\n",
            "{'train_runtime': 6.8853, 'train_samples_per_second': 2130.918, 'train_steps_per_second': 16.848, 'train_loss': 0.5897226004764952, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:36:17] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:36:17] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:36:17] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:36:17] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:36:17] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5748432874679565, 'eval_accuracy': 0.6911764705882353, 'eval_f1': 0.8073394495412844, 'eval_runtime': 0.6031, 'eval_samples_per_second': 676.537, 'eval_steps_per_second': 6.633, 'epoch': 4.0}\n",
            "Progress: 99/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:36:19] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:36:19] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:36:19] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:36:19]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:36:19]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:36:19]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:36:19]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:36:19]   CPU count: 8\n",
            "[codecarbon INFO @ 00:36:19]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:36:19]   GPU count: 1\n",
            "[codecarbon INFO @ 00:36:19]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6207587718963623, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.6027, 'eval_samples_per_second': 676.965, 'eval_steps_per_second': 6.637, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6050003170967102, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.8062, 'eval_samples_per_second': 506.081, 'eval_steps_per_second': 4.962, 'epoch': 2.0}\n",
            "{'eval_loss': 0.5970742106437683, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8145985401459854, 'eval_runtime': 0.6138, 'eval_samples_per_second': 664.695, 'eval_steps_per_second': 6.517, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:36:27] Energy consumed for RAM : 0.000041 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:36:27] Energy consumed for all GPUs : 0.000114 kWh. Total GPU Power : 52.84481317745219 W\n",
            "[codecarbon INFO @ 00:36:27] Energy consumed for all CPUs : 0.000092 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:36:27] 0.000248 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5952083468437195, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8169838945827232, 'eval_runtime': 0.607, 'eval_samples_per_second': 672.117, 'eval_steps_per_second': 6.589, 'epoch': 4.0}\n",
            "{'train_runtime': 7.0917, 'train_samples_per_second': 2068.903, 'train_steps_per_second': 16.357, 'train_loss': 0.6204661007585197, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:36:27] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:36:27] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:36:27] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:36:27] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:36:27] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5952083468437195, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8169838945827232, 'eval_runtime': 0.6042, 'eval_samples_per_second': 675.252, 'eval_steps_per_second': 6.62, 'epoch': 4.0}\n",
            "Progress: 100/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:36:28] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:36:28] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:36:28] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:36:28]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:36:28]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:36:28]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:36:28]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:36:28]   CPU count: 8\n",
            "[codecarbon INFO @ 00:36:28]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:36:28]   GPU count: 1\n",
            "[codecarbon INFO @ 00:36:28]   GPU model: 1 x Tesla T4\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6439599990844727, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.6122, 'eval_samples_per_second': 666.492, 'eval_steps_per_second': 6.534, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6185536980628967, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.5996, 'eval_samples_per_second': 680.405, 'eval_steps_per_second': 6.671, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6116704344749451, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.5951, 'eval_samples_per_second': 685.605, 'eval_steps_per_second': 6.722, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:36:36] Energy consumed for RAM : 0.000039 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:36:36] Energy consumed for all GPUs : 0.000111 kWh. Total GPU Power : 53.62237985736155 W\n",
            "[codecarbon INFO @ 00:36:36] Energy consumed for all CPUs : 0.000088 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:36:36] 0.000238 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.609874427318573, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.5996, 'eval_samples_per_second': 680.485, 'eval_steps_per_second': 6.671, 'epoch': 4.0}\n",
            "{'train_runtime': 6.8018, 'train_samples_per_second': 2157.088, 'train_steps_per_second': 17.054, 'train_loss': 0.6398460125101024, 'epoch': 4.0}\n",
            "{'eval_loss': 0.609874427318573, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8122270742358079, 'eval_runtime': 0.5987, 'eval_samples_per_second': 681.5, 'eval_steps_per_second': 6.681, 'epoch': 4.0}\n",
            "\n",
            "================         \n",
            "Total Runtime: 24.73579385280609 minutes         \n",
            "Best Result:         \n",
            "\tF1=0.8386075949367089         \n",
            "\tBatch Size=64         \n",
            "\tLearning Rate=0.0003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Low-Rank Adaptation (LoRA)"
      ],
      "metadata": {
        "id": "fn2hce2EzI11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "lora_model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2).to(device)"
      ],
      "metadata": {
        "id": "HeNFNs4QzF7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MivaCxsh7UKy"
      },
      "outputs": [],
      "source": [
        "class LoraModule(nn.Module):\n",
        "  def __init__(self, in_features, out_features, rank, alpha):\n",
        "    super().__init__()\n",
        "    self.scale = alpha / rank\n",
        "    self.A = nn.Parameter(torch.randn(in_features, rank))\n",
        "    self.B = nn.Parameter(torch.zeros(rank, out_features))\n",
        "\n",
        "  def forward(self, x):\n",
        "    return (self.scale * (x @ self.A @ self.B))\n",
        "\n",
        "class LoraLinear(nn.Module):\n",
        "  def __init__(self, linear, rank, alpha):\n",
        "    super().__init__()\n",
        "    if (isinstance(linear, LoraLinear)):\n",
        "      self.linear = linear.linear\n",
        "      self.lora = LoraModule(self.linear.in_features, self.linear.out_features, rank, alpha)\n",
        "\n",
        "    else:\n",
        "      self.linear = linear\n",
        "      self.lora = LoraModule(self.linear.in_features, self.linear.out_features, rank, alpha)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x) + self.lora(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def configure_lora_model(model, rank, alpha):\n",
        "  # Replace the query and value linear layers with LoRA layers\n",
        "  for _, layer in enumerate(model.bert.encoder.layer):\n",
        "    s = layer.attention.self\n",
        "    s.query = LoraLinear(s.query, rank, alpha)\n",
        "    s.value = LoraLinear(s.value, rank, alpha)\n",
        "\n",
        "  # Freeze the pre-trained weights\n",
        "  for name, param in model.named_parameters():\n",
        "    if 'A' in name or 'B' in name:\n",
        "      param.requires_grad = True\n",
        "    else:\n",
        "      param.requires_grad = False"
      ],
      "metadata": {
        "id": "G32Km33dIKU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fine_tune_with_lora_model(model, rank, alpha, epochs, batch_size, learning_rate):\n",
        "  # Initialize result\n",
        "  result = {\"rank\": rank, \"alpha\": alpha, \"batch_size\": batch_size, \"learning_rate\": learning_rate}\n",
        "\n",
        "  # Track emissions\n",
        "  tracker = EmissionsTracker('lora-bert-tiny', save_to_file=False)\n",
        "  try:\n",
        "    tracker.start()\n",
        "\n",
        "    # Configure an existing model with new LoRA layers\n",
        "    configure_lora_model(model, rank, alpha)\n",
        "\n",
        "    # Setup the trainer\n",
        "    training_args = TrainingArguments(\n",
        "        \"lora-trainer\",\n",
        "        eval_strategy=\"epoch\",\n",
        "        per_device_eval_batch_size=size,\n",
        "        per_device_train_batch_size=size,\n",
        "        num_train_epochs=epochs,\n",
        "        learning_rate=rate,\n",
        "        disable_tqdm=True,\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "    trainer = Trainer(\n",
        "        model,\n",
        "        training_args,\n",
        "        train_dataset=tokenized_datasets[\"train\"],\n",
        "        eval_dataset=tokenized_datasets[\"validation\"],\n",
        "        data_collator=data_collator,\n",
        "        processing_class=tokenizer,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    result |= trainer.train().metrics\n",
        "\n",
        "    # Stop tracking emissions\n",
        "    tracker.stop()\n",
        "\n",
        "    # Store metrics and delete the tracker\n",
        "    result |= trainer.evaluate() | get_trainable_parameters(model) | tracker.final_emissions_data.values\n",
        "  finally:\n",
        "    del tracker\n",
        "\n",
        "  return result"
      ],
      "metadata": {
        "id": "LCBi9TYnHlk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranks = [1, 2, 4, 8, 16]\n",
        "alphas = [1, 2, 4, 8, 16]"
      ],
      "metadata": {
        "id": "niceYTIvGnz2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments, set_seed\n",
        "import time\n",
        "\n",
        "lora_results = []\n",
        "progress = 0\n",
        "iterations = len(batch_sizes)*len(learning_rates)*len(ranks)*len(alphas)*num_runs\n",
        "\n",
        "# Hyperparameter tuning\n",
        "start_time = time.time()\n",
        "for run in range(1, num_runs+1):\n",
        "  set_seed(run)\n",
        "\n",
        "  for rank in ranks:\n",
        "    for alpha in alphas:\n",
        "      for size in batch_sizes:\n",
        "        for rate in learning_rates:\n",
        "          # Track progress\n",
        "          progress += 1\n",
        "          print(f\"Progress: {progress}/{iterations}\")\n",
        "\n",
        "          # Fine-tune the LoRA model and store the results\n",
        "          lora_result = {\"run\": run}\n",
        "          lora_result |= fine_tune_with_lora_model(lora_model, rank, alpha, epochs, size, rate)\n",
        "          lora_results.append(lora_result)\n",
        "\n",
        "  write_results_to_csv(output_dir + 'lora-results.csv', lora_results)\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "runtime_seconds = end_time - start_time\n",
        "runtime_hours = runtime_seconds / 3600\n",
        "\n",
        "# Output the best result\n",
        "max_lora_result = lora_results[0]\n",
        "for _, result in enumerate(lora_results):\n",
        "  if result['eval_f1'] > max_lora_result['eval_f1']:\n",
        "    max_lora_result = result\n",
        "print(f'\\n================ \\\n",
        "        \\nTotal Runtime: {runtime_hours} hours \\\n",
        "        \\nBest Result: \\\n",
        "        \\n\\tF1={max_lora_result[\"eval_f1\"]} \\\n",
        "        \\n\\tRank={max_lora_result[\"rank\"]} \\\n",
        "        \\n\\tAlpha={max_lora_result[\"alpha\"]} \\\n",
        "        \\n\\tBatch Size={max_lora_result[\"batch_size\"]} \\\n",
        "        \\n\\tLearning Rate={max_lora_result[\"learning_rate\"]}'\n",
        ")"
      ],
      "metadata": {
        "id": "2sRCUocTD3eo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e91f55c-10bd-4066-d7da-6f1551b42d00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:36:37] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:36:37] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:36:37] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:36:37] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:36:37] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 1/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:36:38] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:36:38] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:36:38] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:36:38]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:36:38]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:36:38]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:36:38]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:36:38]   CPU count: 8\n",
            "[codecarbon INFO @ 00:36:38]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:36:38]   GPU count: 1\n",
            "[codecarbon INFO @ 00:36:38]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6247038841247559, 'eval_accuracy': 0.6813725490196079, 'eval_f1': 0.8099415204678363, 'eval_runtime': 0.7752, 'eval_samples_per_second': 526.32, 'eval_steps_per_second': 65.79, 'epoch': 1.0}\n",
            "{'loss': 0.6576, 'grad_norm': 0.5037346482276917, 'learning_rate': 0.00021830065359477123, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.6202483773231506, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8116788321167884, 'eval_runtime': 0.7992, 'eval_samples_per_second': 510.494, 'eval_steps_per_second': 63.812, 'epoch': 2.0}\n",
            "{'loss': 0.6277, 'grad_norm': 0.49709364771842957, 'learning_rate': 0.00013660130718954247, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:36:53] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:36:53] Energy consumed for all GPUs : 0.000144 kWh. Total GPU Power : 34.5985816934756 W\n",
            "[codecarbon INFO @ 00:36:53] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:36:53] 0.000401 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6195987462997437, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8116788321167884, 'eval_runtime': 1.0061, 'eval_samples_per_second': 405.529, 'eval_steps_per_second': 50.691, 'epoch': 3.0}\n",
            "{'loss': 0.6211, 'grad_norm': 0.6490159630775452, 'learning_rate': 5.4901960784313716e-05, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:37:00] Energy consumed for RAM : 0.000116 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:37:00] Energy consumed for all GPUs : 0.000209 kWh. Total GPU Power : 34.1280252307746 W\n",
            "[codecarbon INFO @ 00:37:00] Energy consumed for all CPUs : 0.000258 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:37:00] 0.000583 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6194120049476624, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8116788321167884, 'eval_runtime': 0.7783, 'eval_samples_per_second': 524.192, 'eval_steps_per_second': 65.524, 'epoch': 4.0}\n",
            "{'train_runtime': 21.4416, 'train_samples_per_second': 684.278, 'train_steps_per_second': 85.628, 'train_loss': 0.6344402454517506, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:37:01] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:37:01] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:37:01] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:37:01] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:37:01] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6194120049476624, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8116788321167884, 'eval_runtime': 0.8446, 'eval_samples_per_second': 483.069, 'eval_steps_per_second': 60.384, 'epoch': 4.0}\n",
            "Progress: 2/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:37:02] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:37:02] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:37:02] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:37:02]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:37:02]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:37:02]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:37:02]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:37:02]   CPU count: 8\n",
            "[codecarbon INFO @ 00:37:02]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:37:02]   GPU count: 1\n",
            "[codecarbon INFO @ 00:37:02]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6730965375900269, 'eval_accuracy': 0.6470588235294118, 'eval_f1': 0.7534246575342466, 'eval_runtime': 0.7895, 'eval_samples_per_second': 516.809, 'eval_steps_per_second': 64.601, 'epoch': 1.0}\n",
            "{'loss': 0.7085, 'grad_norm': 0.3521327078342438, 'learning_rate': 7.276688453159042e-05, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.6384305953979492, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8107302533532041, 'eval_runtime': 0.7796, 'eval_samples_per_second': 523.337, 'eval_steps_per_second': 65.417, 'epoch': 2.0}\n",
            "{'loss': 0.6512, 'grad_norm': 0.4592481851577759, 'learning_rate': 4.5533769063180834e-05, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:37:17] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:37:17] Energy consumed for all GPUs : 0.000142 kWh. Total GPU Power : 34.09828738013208 W\n",
            "[codecarbon INFO @ 00:37:17] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:37:17] 0.000399 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6301237940788269, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8112094395280236, 'eval_runtime': 0.7704, 'eval_samples_per_second': 529.574, 'eval_steps_per_second': 66.197, 'epoch': 3.0}\n",
            "{'loss': 0.632, 'grad_norm': 0.5441040396690369, 'learning_rate': 1.8300653594771242e-05, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:37:24] Energy consumed for RAM : 0.000117 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:37:24] Energy consumed for all GPUs : 0.000208 kWh. Total GPU Power : 33.89138079955329 W\n",
            "[codecarbon INFO @ 00:37:24] Energy consumed for all CPUs : 0.000259 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:37:24] 0.000583 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6279606819152832, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.812960235640648, 'eval_runtime': 0.8937, 'eval_samples_per_second': 456.538, 'eval_steps_per_second': 57.067, 'epoch': 4.0}\n",
            "{'train_runtime': 21.5469, 'train_samples_per_second': 680.934, 'train_steps_per_second': 85.21, 'train_loss': 0.6589283413357205, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:37:25] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:37:25] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:37:25] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:37:25] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:37:25] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6279606819152832, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.812960235640648, 'eval_runtime': 0.7739, 'eval_samples_per_second': 527.173, 'eval_steps_per_second': 65.897, 'epoch': 4.0}\n",
            "Progress: 3/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:37:26] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:37:26] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:37:26] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:37:26]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:37:26]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:37:26]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:37:26]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:37:26]   CPU count: 8\n",
            "[codecarbon INFO @ 00:37:26]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:37:26]   GPU count: 1\n",
            "[codecarbon INFO @ 00:37:26]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7177466750144958, 'eval_accuracy': 0.32107843137254904, 'eval_f1': 0.061016949152542375, 'eval_runtime': 0.8018, 'eval_samples_per_second': 508.887, 'eval_steps_per_second': 63.611, 'epoch': 1.0}\n",
            "{'loss': 0.7322, 'grad_norm': 0.3813965320587158, 'learning_rate': 3.638344226579521e-05, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.6852342486381531, 'eval_accuracy': 0.5735294117647058, 'eval_f1': 0.6627906976744186, 'eval_runtime': 0.7862, 'eval_samples_per_second': 518.982, 'eval_steps_per_second': 64.873, 'epoch': 2.0}\n",
            "{'loss': 0.6951, 'grad_norm': 0.6395981907844543, 'learning_rate': 2.2766884531590417e-05, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:37:41] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:37:41] Energy consumed for all GPUs : 0.000142 kWh. Total GPU Power : 34.11623689597992 W\n",
            "[codecarbon INFO @ 00:37:41] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:37:41] 0.000399 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6690717339515686, 'eval_accuracy': 0.6544117647058824, 'eval_f1': 0.7669421487603306, 'eval_runtime': 0.782, 'eval_samples_per_second': 521.744, 'eval_steps_per_second': 65.218, 'epoch': 3.0}\n",
            "{'loss': 0.6713, 'grad_norm': 0.38888677954673767, 'learning_rate': 9.150326797385621e-06, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:37:47] Energy consumed for RAM : 0.000113 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:37:47] Energy consumed for all GPUs : 0.000201 kWh. Total GPU Power : 33.6119245804292 W\n",
            "[codecarbon INFO @ 00:37:47] Energy consumed for all CPUs : 0.000252 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:37:47] 0.000567 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6646168828010559, 'eval_accuracy': 0.6617647058823529, 'eval_f1': 0.7766990291262136, 'eval_runtime': 0.7965, 'eval_samples_per_second': 512.257, 'eval_steps_per_second': 64.032, 'epoch': 4.0}\n",
            "{'train_runtime': 20.9821, 'train_samples_per_second': 699.262, 'train_steps_per_second': 87.503, 'train_loss': 0.6939592299118541, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:37:48] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:37:48] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:37:48] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:37:48] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:37:48] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6646168828010559, 'eval_accuracy': 0.6617647058823529, 'eval_f1': 0.7766990291262136, 'eval_runtime': 0.7695, 'eval_samples_per_second': 530.213, 'eval_steps_per_second': 66.277, 'epoch': 4.0}\n",
            "Progress: 4/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:37:49] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:37:49] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:37:49] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:37:49]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:37:49]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:37:49]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:37:49]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:37:49]   CPU count: 8\n",
            "[codecarbon INFO @ 00:37:49]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:37:49]   GPU count: 1\n",
            "[codecarbon INFO @ 00:37:49]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7343876957893372, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.7881, 'eval_samples_per_second': 517.682, 'eval_steps_per_second': 64.71, 'epoch': 1.0}\n",
            "{'loss': 0.7411, 'grad_norm': 0.38866573572158813, 'learning_rate': 2.1830065359477124e-05, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.7162315249443054, 'eval_accuracy': 0.33088235294117646, 'eval_f1': 0.09302325581395349, 'eval_runtime': 0.7704, 'eval_samples_per_second': 529.619, 'eval_steps_per_second': 66.202, 'epoch': 2.0}\n",
            "{'loss': 0.7206, 'grad_norm': 0.5770863890647888, 'learning_rate': 1.366013071895425e-05, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:38:05] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:38:05] Energy consumed for all GPUs : 0.000141 kWh. Total GPU Power : 33.73321470631191 W\n",
            "[codecarbon INFO @ 00:38:05] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:38:05] 0.000397 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.704820454120636, 'eval_accuracy': 0.3946078431372549, 'eval_f1': 0.32697547683923706, 'eval_runtime': 0.8734, 'eval_samples_per_second': 467.159, 'eval_steps_per_second': 58.395, 'epoch': 3.0}\n",
            "{'loss': 0.7048, 'grad_norm': 0.36168649792671204, 'learning_rate': 5.490196078431373e-06, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:38:11] Energy consumed for RAM : 0.000113 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:38:11] Energy consumed for all GPUs : 0.000200 kWh. Total GPU Power : 33.83920608573309 W\n",
            "[codecarbon INFO @ 00:38:11] Energy consumed for all CPUs : 0.000251 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:38:11] 0.000564 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7010163068771362, 'eval_accuracy': 0.4362745098039216, 'eval_f1': 0.41624365482233505, 'eval_runtime': 0.7815, 'eval_samples_per_second': 522.053, 'eval_steps_per_second': 65.257, 'epoch': 4.0}\n",
            "{'train_runtime': 20.9241, 'train_samples_per_second': 701.203, 'train_steps_per_second': 87.746, 'train_loss': 0.7182109890939883, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:38:12] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:38:12] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:38:12] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:38:12] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:38:12] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7010163068771362, 'eval_accuracy': 0.4362745098039216, 'eval_f1': 0.41624365482233505, 'eval_runtime': 0.7713, 'eval_samples_per_second': 528.974, 'eval_steps_per_second': 66.122, 'epoch': 4.0}\n",
            "Progress: 5/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:38:13] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:38:13] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:38:13] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:38:13]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:38:13]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:38:13]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:38:13]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:38:13]   CPU count: 8\n",
            "[codecarbon INFO @ 00:38:13]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:38:13]   GPU count: 1\n",
            "[codecarbon INFO @ 00:38:13]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6345610618591309, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8112094395280236, 'eval_runtime': 0.6794, 'eval_samples_per_second': 600.52, 'eval_steps_per_second': 38.268, 'epoch': 1.0}\n",
            "{'eval_loss': 0.622128427028656, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8123167155425219, 'eval_runtime': 0.703, 'eval_samples_per_second': 580.381, 'eval_steps_per_second': 36.985, 'epoch': 2.0}\n",
            "{'loss': 0.6546, 'grad_norm': 0.23238064348697662, 'learning_rate': 0.00013695652173913042, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.6207221746444702, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8140556368960469, 'eval_runtime': 0.6803, 'eval_samples_per_second': 599.711, 'eval_steps_per_second': 38.217, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:38:26] Energy consumed for RAM : 0.000069 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:38:26] Energy consumed for all GPUs : 0.000126 kWh. Total GPU Power : 34.9682183364436 W\n",
            "[codecarbon INFO @ 00:38:26] Energy consumed for all CPUs : 0.000153 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:38:26] 0.000347 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.620145320892334, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8140556368960469, 'eval_runtime': 0.6676, 'eval_samples_per_second': 611.174, 'eval_steps_per_second': 38.947, 'epoch': 4.0}\n",
            "{'train_runtime': 12.5735, 'train_samples_per_second': 1166.9, 'train_steps_per_second': 73.17, 'train_loss': 0.6401053387185801, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:38:27] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:38:27] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:38:27] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:38:27] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:38:27] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.620145320892334, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8140556368960469, 'eval_runtime': 0.6909, 'eval_samples_per_second': 590.509, 'eval_steps_per_second': 37.63, 'epoch': 4.0}\n",
            "Progress: 6/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:38:28] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:38:28] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:38:28] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:38:28]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:38:28]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:38:28]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:38:28]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:38:28]   CPU count: 8\n",
            "[codecarbon INFO @ 00:38:28]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:38:28]   GPU count: 1\n",
            "[codecarbon INFO @ 00:38:28]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7089972496032715, 'eval_accuracy': 0.3872549019607843, 'eval_f1': 0.2603550295857988, 'eval_runtime': 0.6815, 'eval_samples_per_second': 598.706, 'eval_steps_per_second': 38.153, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6713041663169861, 'eval_accuracy': 0.6519607843137255, 'eval_f1': 0.7625418060200669, 'eval_runtime': 0.682, 'eval_samples_per_second': 598.265, 'eval_steps_per_second': 38.125, 'epoch': 2.0}\n",
            "{'loss': 0.7052, 'grad_norm': 0.2465394139289856, 'learning_rate': 4.565217391304348e-05, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.6552615165710449, 'eval_accuracy': 0.6715686274509803, 'eval_f1': 0.7932098765432098, 'eval_runtime': 0.6981, 'eval_samples_per_second': 584.472, 'eval_steps_per_second': 37.246, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:38:41] Energy consumed for RAM : 0.000069 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:38:41] Energy consumed for all GPUs : 0.000125 kWh. Total GPU Power : 34.62276689680274 W\n",
            "[codecarbon INFO @ 00:38:41] Energy consumed for all CPUs : 0.000154 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:38:41] 0.000349 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.650761604309082, 'eval_accuracy': 0.6764705882352942, 'eval_f1': 0.7975460122699386, 'eval_runtime': 0.6676, 'eval_samples_per_second': 611.101, 'eval_steps_per_second': 38.943, 'epoch': 4.0}\n",
            "{'train_runtime': 12.6723, 'train_samples_per_second': 1157.805, 'train_steps_per_second': 72.6, 'train_loss': 0.6834866067637568, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:38:42] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:38:42] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:38:42] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:38:42] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:38:42] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.650761604309082, 'eval_accuracy': 0.6764705882352942, 'eval_f1': 0.7975460122699386, 'eval_runtime': 0.684, 'eval_samples_per_second': 596.52, 'eval_steps_per_second': 38.014, 'epoch': 4.0}\n",
            "Progress: 7/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:38:43] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:38:43] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:38:43] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:38:43]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:38:43]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:38:43]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:38:43]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:38:43]   CPU count: 8\n",
            "[codecarbon INFO @ 00:38:43]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:38:43]   GPU count: 1\n",
            "[codecarbon INFO @ 00:38:43]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7345554232597351, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6834, 'eval_samples_per_second': 597.047, 'eval_steps_per_second': 38.047, 'epoch': 1.0}\n",
            "{'eval_loss': 0.7164990305900574, 'eval_accuracy': 0.3284313725490196, 'eval_f1': 0.08053691275167785, 'eval_runtime': 0.7001, 'eval_samples_per_second': 582.802, 'eval_steps_per_second': 37.139, 'epoch': 2.0}\n",
            "{'loss': 0.7305, 'grad_norm': 0.310889333486557, 'learning_rate': 2.282608695652174e-05, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.7049254775047302, 'eval_accuracy': 0.3946078431372549, 'eval_f1': 0.32697547683923706, 'eval_runtime': 0.7083, 'eval_samples_per_second': 575.991, 'eval_steps_per_second': 36.705, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:38:56] Energy consumed for RAM : 0.000069 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:38:56] Energy consumed for all GPUs : 0.000126 kWh. Total GPU Power : 34.731653345071905 W\n",
            "[codecarbon INFO @ 00:38:56] Energy consumed for all CPUs : 0.000154 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:38:56] 0.000350 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7010124921798706, 'eval_accuracy': 0.4338235294117647, 'eval_f1': 0.4151898734177215, 'eval_runtime': 0.6787, 'eval_samples_per_second': 601.154, 'eval_steps_per_second': 38.309, 'epoch': 4.0}\n",
            "{'train_runtime': 12.6961, 'train_samples_per_second': 1155.634, 'train_steps_per_second': 72.463, 'train_loss': 0.7181151680324389, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:38:57] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:38:57] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:38:57] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:38:57] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:38:57] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7010124921798706, 'eval_accuracy': 0.4338235294117647, 'eval_f1': 0.4151898734177215, 'eval_runtime': 0.6653, 'eval_samples_per_second': 613.303, 'eval_steps_per_second': 39.083, 'epoch': 4.0}\n",
            "Progress: 8/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:38:58] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:38:58] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:38:58] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:38:58]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:38:58]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:38:58]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:38:58]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:38:58]   CPU count: 8\n",
            "[codecarbon INFO @ 00:38:58]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:38:58]   GPU count: 1\n",
            "[codecarbon INFO @ 00:38:58]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7433072328567505, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6749, 'eval_samples_per_second': 604.491, 'eval_steps_per_second': 38.522, 'epoch': 1.0}\n",
            "{'eval_loss': 0.733747124671936, 'eval_accuracy': 0.31862745098039214, 'eval_f1': 0.007142857142857143, 'eval_runtime': 0.6854, 'eval_samples_per_second': 595.275, 'eval_steps_per_second': 37.934, 'epoch': 2.0}\n",
            "{'loss': 0.7402, 'grad_norm': 0.31184670329093933, 'learning_rate': 1.3695652173913042e-05, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.727674126625061, 'eval_accuracy': 0.31862745098039214, 'eval_f1': 0.014184397163120567, 'eval_runtime': 0.6928, 'eval_samples_per_second': 588.874, 'eval_steps_per_second': 37.526, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:39:11] Energy consumed for RAM : 0.000070 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:39:11] Energy consumed for all GPUs : 0.000128 kWh. Total GPU Power : 34.84968784506074 W\n",
            "[codecarbon INFO @ 00:39:11] Energy consumed for all CPUs : 0.000156 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:39:11] 0.000353 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7255455255508423, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.014134275618374558, 'eval_runtime': 0.7313, 'eval_samples_per_second': 557.936, 'eval_steps_per_second': 35.555, 'epoch': 4.0}\n",
            "{'train_runtime': 12.7911, 'train_samples_per_second': 1147.043, 'train_steps_per_second': 71.925, 'train_loss': 0.7334772856339165, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:39:12] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:39:12] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:39:12] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:39:12] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:39:12] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7255455255508423, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.014134275618374558, 'eval_runtime': 0.6671, 'eval_samples_per_second': 611.589, 'eval_steps_per_second': 38.974, 'epoch': 4.0}\n",
            "Progress: 9/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:39:13] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:39:13] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:39:13] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:39:13]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:39:13]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:39:13]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:39:13]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:39:13]   CPU count: 8\n",
            "[codecarbon INFO @ 00:39:13]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:39:13]   GPU count: 1\n",
            "[codecarbon INFO @ 00:39:13]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6727752089500427, 'eval_accuracy': 0.6397058823529411, 'eval_f1': 0.7495741056218058, 'eval_runtime': 0.6332, 'eval_samples_per_second': 644.392, 'eval_steps_per_second': 20.532, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6352618932723999, 'eval_accuracy': 0.6911764705882353, 'eval_f1': 0.8136094674556213, 'eval_runtime': 0.614, 'eval_samples_per_second': 664.507, 'eval_steps_per_second': 21.173, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6273951530456543, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8123167155425219, 'eval_runtime': 0.6977, 'eval_samples_per_second': 584.779, 'eval_steps_per_second': 18.633, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:39:23] Energy consumed for RAM : 0.000051 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:39:23] Energy consumed for all GPUs : 0.000097 kWh. Total GPU Power : 36.286475079838276 W\n",
            "[codecarbon INFO @ 00:39:23] Energy consumed for all CPUs : 0.000113 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:39:23] 0.000261 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6257346868515015, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8123167155425219, 'eval_runtime': 0.6625, 'eval_samples_per_second': 615.848, 'eval_steps_per_second': 19.623, 'epoch': 4.0}\n",
            "{'train_runtime': 9.2044, 'train_samples_per_second': 1594.024, 'train_steps_per_second': 49.976, 'train_loss': 0.6578729380731997, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:39:23] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:39:23] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:39:23] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:39:23] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:39:23] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6257346868515015, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8123167155425219, 'eval_runtime': 0.625, 'eval_samples_per_second': 652.749, 'eval_steps_per_second': 20.798, 'epoch': 4.0}\n",
            "Progress: 10/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:39:24] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:39:24] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:39:24] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:39:24]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:39:24]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:39:25]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:39:25]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:39:25]   CPU count: 8\n",
            "[codecarbon INFO @ 00:39:25]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:39:25]   GPU count: 1\n",
            "[codecarbon INFO @ 00:39:25]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7316310405731201, 'eval_accuracy': 0.31862745098039214, 'eval_f1': 0.007142857142857143, 'eval_runtime': 0.6384, 'eval_samples_per_second': 639.127, 'eval_steps_per_second': 20.364, 'epoch': 1.0}\n",
            "{'eval_loss': 0.7107211947441101, 'eval_accuracy': 0.37254901960784315, 'eval_f1': 0.22424242424242424, 'eval_runtime': 0.6325, 'eval_samples_per_second': 645.011, 'eval_steps_per_second': 20.552, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6969713568687439, 'eval_accuracy': 0.48284313725490197, 'eval_f1': 0.5127020785219399, 'eval_runtime': 0.7868, 'eval_samples_per_second': 518.572, 'eval_steps_per_second': 16.523, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:39:34] Energy consumed for RAM : 0.000052 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:39:34] Energy consumed for all GPUs : 0.000098 kWh. Total GPU Power : 35.9416089532001 W\n",
            "[codecarbon INFO @ 00:39:34] Energy consumed for all CPUs : 0.000116 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:39:34] 0.000267 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6924538612365723, 'eval_accuracy': 0.5245098039215687, 'eval_f1': 0.5872340425531914, 'eval_runtime': 0.6295, 'eval_samples_per_second': 648.099, 'eval_steps_per_second': 20.65, 'epoch': 4.0}\n",
            "{'train_runtime': 9.4321, 'train_samples_per_second': 1555.547, 'train_steps_per_second': 48.77, 'train_loss': 0.7137894340183424, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:39:35] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:39:35] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:39:35] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:39:35] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:39:35] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6924538612365723, 'eval_accuracy': 0.5245098039215687, 'eval_f1': 0.5872340425531914, 'eval_runtime': 0.6645, 'eval_samples_per_second': 614.004, 'eval_steps_per_second': 19.564, 'epoch': 4.0}\n",
            "Progress: 11/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:39:36] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:39:36] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:39:36] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:39:36]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:39:36]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:39:36]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:39:36]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:39:36]   CPU count: 8\n",
            "[codecarbon INFO @ 00:39:36]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:39:36]   GPU count: 1\n",
            "[codecarbon INFO @ 00:39:36]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7439378499984741, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6488, 'eval_samples_per_second': 628.833, 'eval_steps_per_second': 20.036, 'epoch': 1.0}\n",
            "{'eval_loss': 0.7352198958396912, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6316, 'eval_samples_per_second': 645.99, 'eval_steps_per_second': 20.583, 'epoch': 2.0}\n",
            "{'eval_loss': 0.7295425534248352, 'eval_accuracy': 0.31862745098039214, 'eval_f1': 0.014184397163120567, 'eval_runtime': 0.6721, 'eval_samples_per_second': 607.064, 'eval_steps_per_second': 19.343, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:39:46] Energy consumed for RAM : 0.000050 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:39:46] Energy consumed for all GPUs : 0.000096 kWh. Total GPU Power : 36.256614439448214 W\n",
            "[codecarbon INFO @ 00:39:46] Energy consumed for all CPUs : 0.000112 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:39:46] 0.000259 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7275199294090271, 'eval_accuracy': 0.31862745098039214, 'eval_f1': 0.014184397163120567, 'eval_runtime': 0.6351, 'eval_samples_per_second': 642.405, 'eval_steps_per_second': 20.469, 'epoch': 4.0}\n",
            "{'train_runtime': 9.1189, 'train_samples_per_second': 1608.971, 'train_steps_per_second': 50.445, 'train_loss': 0.7354321023692255, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:39:47] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:39:47] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:39:47] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:39:47] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:39:47] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7275199294090271, 'eval_accuracy': 0.31862745098039214, 'eval_f1': 0.014184397163120567, 'eval_runtime': 0.6498, 'eval_samples_per_second': 627.918, 'eval_steps_per_second': 20.007, 'epoch': 4.0}\n",
            "Progress: 12/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:39:48] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:39:48] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:39:48] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:39:48]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:39:48]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:39:48]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:39:48]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:39:48]   CPU count: 8\n",
            "[codecarbon INFO @ 00:39:48]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:39:48]   GPU count: 1\n",
            "[codecarbon INFO @ 00:39:48]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7484992742538452, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6544, 'eval_samples_per_second': 623.43, 'eval_steps_per_second': 19.864, 'epoch': 1.0}\n",
            "{'eval_loss': 0.74362713098526, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6435, 'eval_samples_per_second': 634.08, 'eval_steps_per_second': 20.204, 'epoch': 2.0}\n",
            "{'eval_loss': 0.7405650019645691, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.619, 'eval_samples_per_second': 659.143, 'eval_steps_per_second': 21.002, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:39:57] Energy consumed for RAM : 0.000051 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:39:57] Energy consumed for all GPUs : 0.000096 kWh. Total GPU Power : 36.18713462401645 W\n",
            "[codecarbon INFO @ 00:39:57] Energy consumed for all CPUs : 0.000112 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:39:57] 0.000259 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7394840121269226, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6898, 'eval_samples_per_second': 591.484, 'eval_steps_per_second': 18.846, 'epoch': 4.0}\n",
            "{'train_runtime': 9.1213, 'train_samples_per_second': 1608.538, 'train_steps_per_second': 50.431, 'train_loss': 0.7433099497919498, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:39:58] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:39:58] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:39:58] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:39:58] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:39:58] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7394840121269226, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6206, 'eval_samples_per_second': 657.468, 'eval_steps_per_second': 20.949, 'epoch': 4.0}\n",
            "Progress: 13/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:39:59] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:39:59] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:39:59] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:39:59]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:39:59]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:39:59]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:39:59]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:39:59]   CPU count: 8\n",
            "[codecarbon INFO @ 00:39:59]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:39:59]   GPU count: 1\n",
            "[codecarbon INFO @ 00:39:59]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7153947353363037, 'eval_accuracy': 0.3382352941176471, 'eval_f1': 0.11764705882352941, 'eval_runtime': 0.603, 'eval_samples_per_second': 676.583, 'eval_steps_per_second': 11.608, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6780186295509338, 'eval_accuracy': 0.6225490196078431, 'eval_f1': 0.7230215827338129, 'eval_runtime': 0.6386, 'eval_samples_per_second': 638.881, 'eval_steps_per_second': 10.961, 'epoch': 2.0}\n",
            "{'eval_loss': 0.659702479839325, 'eval_accuracy': 0.6764705882352942, 'eval_f1': 0.7917981072555205, 'eval_runtime': 0.6035, 'eval_samples_per_second': 676.032, 'eval_steps_per_second': 11.599, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:40:07] Energy consumed for RAM : 0.000040 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:40:07] Energy consumed for all GPUs : 0.000081 kWh. Total GPU Power : 38.4669375432235 W\n",
            "[codecarbon INFO @ 00:40:07] Energy consumed for all CPUs : 0.000090 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:40:07] 0.000211 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6545944809913635, 'eval_accuracy': 0.6740196078431373, 'eval_f1': 0.794435857805255, 'eval_runtime': 0.6092, 'eval_samples_per_second': 669.74, 'eval_steps_per_second': 11.491, 'epoch': 4.0}\n",
            "{'train_runtime': 7.2061, 'train_samples_per_second': 2036.066, 'train_steps_per_second': 32.195, 'train_loss': 0.6889614894472319, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:40:08] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:40:08] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:40:08] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:40:08] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:40:08] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6545944809913635, 'eval_accuracy': 0.6740196078431373, 'eval_f1': 0.794435857805255, 'eval_runtime': 0.6264, 'eval_samples_per_second': 651.339, 'eval_steps_per_second': 11.175, 'epoch': 4.0}\n",
            "Progress: 14/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:40:09] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:40:09] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:40:09] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:40:09]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:40:09]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:40:09]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:40:09]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:40:09]   CPU count: 8\n",
            "[codecarbon INFO @ 00:40:09]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:40:09]   GPU count: 1\n",
            "[codecarbon INFO @ 00:40:09]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7431542873382568, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6231, 'eval_samples_per_second': 654.821, 'eval_steps_per_second': 11.235, 'epoch': 1.0}\n",
            "{'eval_loss': 0.7332796454429626, 'eval_accuracy': 0.31862745098039214, 'eval_f1': 0.007142857142857143, 'eval_runtime': 0.6025, 'eval_samples_per_second': 677.188, 'eval_steps_per_second': 11.618, 'epoch': 2.0}\n",
            "{'eval_loss': 0.7269538640975952, 'eval_accuracy': 0.31862745098039214, 'eval_f1': 0.014184397163120567, 'eval_runtime': 0.5905, 'eval_samples_per_second': 690.957, 'eval_steps_per_second': 11.855, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:40:16] Energy consumed for RAM : 0.000039 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:40:16] Energy consumed for all GPUs : 0.000081 kWh. Total GPU Power : 39.71334950414211 W\n",
            "[codecarbon INFO @ 00:40:16] Energy consumed for all CPUs : 0.000086 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:40:16] 0.000206 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.724665105342865, 'eval_accuracy': 0.31862745098039214, 'eval_f1': 0.02112676056338028, 'eval_runtime': 0.616, 'eval_samples_per_second': 662.315, 'eval_steps_per_second': 11.363, 'epoch': 4.0}\n",
            "{'train_runtime': 6.9321, 'train_samples_per_second': 2116.539, 'train_steps_per_second': 33.468, 'train_loss': 0.7337018374739022, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:40:17] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:40:17] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:40:17] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:40:17] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:40:17] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.724665105342865, 'eval_accuracy': 0.31862745098039214, 'eval_f1': 0.02112676056338028, 'eval_runtime': 0.6352, 'eval_samples_per_second': 642.272, 'eval_steps_per_second': 11.019, 'epoch': 4.0}\n",
            "Progress: 15/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:40:18] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:40:18] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:40:18] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:40:18]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:40:18]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:40:18]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:40:18]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:40:18]   CPU count: 8\n",
            "[codecarbon INFO @ 00:40:18]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:40:18]   GPU count: 1\n",
            "[codecarbon INFO @ 00:40:18]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7492170929908752, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6946, 'eval_samples_per_second': 587.405, 'eval_steps_per_second': 10.078, 'epoch': 1.0}\n",
            "{'eval_loss': 0.7447175979614258, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6119, 'eval_samples_per_second': 666.763, 'eval_steps_per_second': 11.44, 'epoch': 2.0}\n",
            "{'eval_loss': 0.7419718503952026, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6051, 'eval_samples_per_second': 674.225, 'eval_steps_per_second': 11.568, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:40:26] Energy consumed for RAM : 0.000039 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:40:26] Energy consumed for all GPUs : 0.000082 kWh. Total GPU Power : 39.72197186809093 W\n",
            "[codecarbon INFO @ 00:40:26] Energy consumed for all CPUs : 0.000087 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:40:26] 0.000208 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7409998774528503, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6032, 'eval_samples_per_second': 676.343, 'eval_steps_per_second': 11.604, 'epoch': 4.0}\n",
            "{'train_runtime': 6.9921, 'train_samples_per_second': 2098.366, 'train_steps_per_second': 33.18, 'train_loss': 0.7443611539643387, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:40:26] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:40:26] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:40:26] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:40:26] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:40:26] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7409998774528503, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.613, 'eval_samples_per_second': 665.628, 'eval_steps_per_second': 11.42, 'epoch': 4.0}\n",
            "Progress: 16/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:40:27] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:40:27] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:40:27] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:40:27]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:40:27]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:40:27]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:40:27]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:40:27]   CPU count: 8\n",
            "[codecarbon INFO @ 00:40:27]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:40:27]   GPU count: 1\n",
            "[codecarbon INFO @ 00:40:27]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7515774965286255, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6013, 'eval_samples_per_second': 678.477, 'eval_steps_per_second': 11.641, 'epoch': 1.0}\n",
            "{'eval_loss': 0.7489610314369202, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6023, 'eval_samples_per_second': 677.361, 'eval_steps_per_second': 11.621, 'epoch': 2.0}\n",
            "{'eval_loss': 0.7473921179771423, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6099, 'eval_samples_per_second': 668.956, 'eval_steps_per_second': 11.477, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:40:35] Energy consumed for RAM : 0.000040 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:40:35] Energy consumed for all GPUs : 0.000081 kWh. Total GPU Power : 38.81455606294067 W\n",
            "[codecarbon INFO @ 00:40:35] Energy consumed for all CPUs : 0.000088 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:40:35] 0.000209 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7468426823616028, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6267, 'eval_samples_per_second': 651.016, 'eval_steps_per_second': 11.169, 'epoch': 4.0}\n",
            "{'train_runtime': 7.0754, 'train_samples_per_second': 2073.675, 'train_steps_per_second': 32.79, 'train_loss': 0.7483966432768723, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:40:36] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:40:36] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:40:36] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:40:36] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:40:36] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7468426823616028, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6189, 'eval_samples_per_second': 659.234, 'eval_steps_per_second': 11.31, 'epoch': 4.0}\n",
            "Progress: 17/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:40:37] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:40:37] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:40:37] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:40:37]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:40:37]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:40:37]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:40:37]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:40:37]   CPU count: 8\n",
            "[codecarbon INFO @ 00:40:37]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:40:37]   GPU count: 1\n",
            "[codecarbon INFO @ 00:40:37]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7358329892158508, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.5936, 'eval_samples_per_second': 687.368, 'eval_steps_per_second': 6.739, 'epoch': 1.0}\n",
            "{'eval_loss': 0.7193669080734253, 'eval_accuracy': 0.31862745098039214, 'eval_f1': 0.04794520547945205, 'eval_runtime': 0.607, 'eval_samples_per_second': 672.2, 'eval_steps_per_second': 6.59, 'epoch': 2.0}\n",
            "{'eval_loss': 0.7078405618667603, 'eval_accuracy': 0.3897058823529412, 'eval_f1': 0.2824207492795389, 'eval_runtime': 0.5981, 'eval_samples_per_second': 682.138, 'eval_steps_per_second': 6.688, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:40:44] Energy consumed for RAM : 0.000036 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:40:44] Energy consumed for all GPUs : 0.000083 kWh. Total GPU Power : 43.55786653565792 W\n",
            "[codecarbon INFO @ 00:40:44] Energy consumed for all CPUs : 0.000081 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:40:44] 0.000200 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7036358714103699, 'eval_accuracy': 0.40441176470588236, 'eval_f1': 0.352, 'eval_runtime': 0.6076, 'eval_samples_per_second': 671.535, 'eval_steps_per_second': 6.584, 'epoch': 4.0}\n",
            "{'train_runtime': 6.4509, 'train_samples_per_second': 2274.406, 'train_steps_per_second': 17.982, 'train_loss': 0.7210499335979593, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:40:44] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:40:44] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:40:44] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:40:44] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:40:44] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7036358714103699, 'eval_accuracy': 0.40441176470588236, 'eval_f1': 0.352, 'eval_runtime': 0.6045, 'eval_samples_per_second': 674.978, 'eval_steps_per_second': 6.617, 'epoch': 4.0}\n",
            "Progress: 18/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:40:45] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:40:45] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:40:45] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:40:45]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:40:45]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:40:45]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:40:45]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:40:45]   CPU count: 8\n",
            "[codecarbon INFO @ 00:40:45]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:40:45]   GPU count: 1\n",
            "[codecarbon INFO @ 00:40:45]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7488572597503662, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.5983, 'eval_samples_per_second': 681.907, 'eval_steps_per_second': 6.685, 'epoch': 1.0}\n",
            "{'eval_loss': 0.7442406415939331, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.5833, 'eval_samples_per_second': 699.504, 'eval_steps_per_second': 6.858, 'epoch': 2.0}\n",
            "{'eval_loss': 0.7413560748100281, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.5837, 'eval_samples_per_second': 699.049, 'eval_steps_per_second': 6.853, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:40:52] Energy consumed for RAM : 0.000035 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:40:52] Energy consumed for all GPUs : 0.000087 kWh. Total GPU Power : 47.44955513258232 W\n",
            "[codecarbon INFO @ 00:40:52] Energy consumed for all CPUs : 0.000078 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:40:52] 0.000200 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.740304708480835, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6093, 'eval_samples_per_second': 669.567, 'eval_steps_per_second': 6.564, 'epoch': 4.0}\n",
            "{'train_runtime': 6.2278, 'train_samples_per_second': 2355.87, 'train_steps_per_second': 18.626, 'train_loss': 0.7438641909895272, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:40:53] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:40:53] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:40:53] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:40:53] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:40:53] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.740304708480835, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6003, 'eval_samples_per_second': 679.617, 'eval_steps_per_second': 6.663, 'epoch': 4.0}\n",
            "Progress: 19/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:40:54] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:40:54] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:40:54] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:40:54]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:40:54]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:40:54]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:40:54]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:40:54]   CPU count: 8\n",
            "[codecarbon INFO @ 00:40:54]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:40:54]   GPU count: 1\n",
            "[codecarbon INFO @ 00:40:54]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7519798278808594, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.602, 'eval_samples_per_second': 677.765, 'eval_steps_per_second': 6.645, 'epoch': 1.0}\n",
            "{'eval_loss': 0.7497408986091614, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.7223, 'eval_samples_per_second': 564.829, 'eval_steps_per_second': 5.538, 'epoch': 2.0}\n",
            "{'eval_loss': 0.7483837008476257, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.5964, 'eval_samples_per_second': 684.14, 'eval_steps_per_second': 6.707, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:41:01] Energy consumed for RAM : 0.000037 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:41:01] Energy consumed for all GPUs : 0.000083 kWh. Total GPU Power : 43.464972314822134 W\n",
            "[codecarbon INFO @ 00:41:01] Energy consumed for all CPUs : 0.000081 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:41:01] 0.000201 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7478960752487183, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.5877, 'eval_samples_per_second': 694.283, 'eval_steps_per_second': 6.807, 'epoch': 4.0}\n",
            "{'train_runtime': 6.5, 'train_samples_per_second': 2257.216, 'train_steps_per_second': 17.846, 'train_loss': 0.7490791452342066, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:41:02] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:41:02] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:41:02] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:41:02] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:41:02] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7478960752487183, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.5965, 'eval_samples_per_second': 683.966, 'eval_steps_per_second': 6.706, 'epoch': 4.0}\n",
            "Progress: 20/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:41:03] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:41:03] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:41:03] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:41:03]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:41:03]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:41:03]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:41:03]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:41:03]   CPU count: 8\n",
            "[codecarbon INFO @ 00:41:03]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:41:03]   GPU count: 1\n",
            "[codecarbon INFO @ 00:41:03]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7532194256782532, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6018, 'eval_samples_per_second': 677.953, 'eval_steps_per_second': 6.647, 'epoch': 1.0}\n",
            "{'eval_loss': 0.7518888711929321, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.5999, 'eval_samples_per_second': 680.086, 'eval_steps_per_second': 6.668, 'epoch': 2.0}\n",
            "{'eval_loss': 0.7510896325111389, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.5986, 'eval_samples_per_second': 681.647, 'eval_steps_per_second': 6.683, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:41:10] Energy consumed for RAM : 0.000036 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:41:10] Energy consumed for all GPUs : 0.000083 kWh. Total GPU Power : 44.19931094720307 W\n",
            "[codecarbon INFO @ 00:41:10] Energy consumed for all CPUs : 0.000080 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:41:10] 0.000199 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7508041262626648, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.5899, 'eval_samples_per_second': 691.621, 'eval_steps_per_second': 6.781, 'epoch': 4.0}\n",
            "{'train_runtime': 6.3798, 'train_samples_per_second': 2299.767, 'train_steps_per_second': 18.182, 'train_loss': 0.7511340174181708, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:41:10] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:41:10] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:41:10] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:41:10] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:41:10] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7508041262626648, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6064, 'eval_samples_per_second': 672.85, 'eval_steps_per_second': 6.597, 'epoch': 4.0}\n",
            "Progress: 21/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:41:11] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:41:11] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:41:11] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:41:11]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:41:11]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:41:11]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:41:11]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:41:11]   CPU count: 8\n",
            "[codecarbon INFO @ 00:41:11]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:41:11]   GPU count: 1\n",
            "[codecarbon INFO @ 00:41:11]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.620581328868866, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8135095447870778, 'eval_runtime': 0.7902, 'eval_samples_per_second': 516.298, 'eval_steps_per_second': 64.537, 'epoch': 1.0}\n",
            "{'loss': 0.6417, 'grad_norm': 0.7228365540504456, 'learning_rate': 0.00021830065359477123, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.6148348450660706, 'eval_accuracy': 0.6911764705882353, 'eval_f1': 0.8141592920353983, 'eval_runtime': 0.751, 'eval_samples_per_second': 543.283, 'eval_steps_per_second': 67.91, 'epoch': 2.0}\n",
            "{'loss': 0.6198, 'grad_norm': 0.7672398686408997, 'learning_rate': 0.00013660130718954247, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:41:27] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:41:27] Energy consumed for all GPUs : 0.000141 kWh. Total GPU Power : 33.87744383193876 W\n",
            "[codecarbon INFO @ 00:41:27] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:41:27] 0.000398 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6140172481536865, 'eval_accuracy': 0.6985294117647058, 'eval_f1': 0.8177777777777778, 'eval_runtime': 0.7593, 'eval_samples_per_second': 537.359, 'eval_steps_per_second': 67.17, 'epoch': 3.0}\n",
            "{'loss': 0.6106, 'grad_norm': 0.7074764370918274, 'learning_rate': 5.4901960784313716e-05, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:41:33] Energy consumed for RAM : 0.000113 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:41:33] Energy consumed for all GPUs : 0.000199 kWh. Total GPU Power : 33.45141360518753 W\n",
            "[codecarbon INFO @ 00:41:33] Energy consumed for all CPUs : 0.000251 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:41:33] 0.000563 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6139556169509888, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8154761904761905, 'eval_runtime': 0.7818, 'eval_samples_per_second': 521.852, 'eval_steps_per_second': 65.232, 'epoch': 4.0}\n",
            "{'train_runtime': 20.894, 'train_samples_per_second': 702.21, 'train_steps_per_second': 87.872, 'train_loss': 0.6238495820488026, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:41:34] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:41:34] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:41:34] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:41:34] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:41:34] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6139556169509888, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8154761904761905, 'eval_runtime': 0.7662, 'eval_samples_per_second': 532.477, 'eval_steps_per_second': 66.56, 'epoch': 4.0}\n",
            "Progress: 22/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:41:35] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:41:35] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:41:35] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:41:35]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:41:35]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:41:35]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:41:35]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:41:35]   CPU count: 8\n",
            "[codecarbon INFO @ 00:41:35]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:41:35]   GPU count: 1\n",
            "[codecarbon INFO @ 00:41:35]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6381560564041138, 'eval_accuracy': 0.6813725490196079, 'eval_f1': 0.8036253776435045, 'eval_runtime': 0.754, 'eval_samples_per_second': 541.127, 'eval_steps_per_second': 67.641, 'epoch': 1.0}\n",
            "{'loss': 0.6803, 'grad_norm': 0.706214189529419, 'learning_rate': 7.276688453159042e-05, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.624259889125824, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8117647058823529, 'eval_runtime': 0.7625, 'eval_samples_per_second': 535.053, 'eval_steps_per_second': 66.882, 'epoch': 2.0}\n",
            "{'loss': 0.6306, 'grad_norm': 0.6401734948158264, 'learning_rate': 4.5533769063180834e-05, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:41:50] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:41:50] Energy consumed for all GPUs : 0.000140 kWh. Total GPU Power : 33.63023722559483 W\n",
            "[codecarbon INFO @ 00:41:50] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:41:50] 0.000397 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6227477788925171, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8117647058823529, 'eval_runtime': 0.7815, 'eval_samples_per_second': 522.054, 'eval_steps_per_second': 65.257, 'epoch': 3.0}\n",
            "{'loss': 0.6215, 'grad_norm': 0.8160832524299622, 'learning_rate': 1.8300653594771242e-05, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:41:56] Energy consumed for RAM : 0.000113 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:41:56] Energy consumed for all GPUs : 0.000198 kWh. Total GPU Power : 33.54584161415704 W\n",
            "[codecarbon INFO @ 00:41:56] Energy consumed for all CPUs : 0.000251 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:41:56] 0.000561 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6221415400505066, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8117647058823529, 'eval_runtime': 0.8034, 'eval_samples_per_second': 507.828, 'eval_steps_per_second': 63.479, 'epoch': 4.0}\n",
            "{'train_runtime': 20.8427, 'train_samples_per_second': 703.939, 'train_steps_per_second': 88.088, 'train_loss': 0.6415040093050024, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:41:57] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:41:57] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:41:57] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:41:57] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:41:57] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6221415400505066, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8117647058823529, 'eval_runtime': 0.7867, 'eval_samples_per_second': 518.642, 'eval_steps_per_second': 64.83, 'epoch': 4.0}\n",
            "Progress: 23/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:41:58] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:41:58] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:41:58] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:41:58]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:41:58]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:41:58]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:41:58]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:41:58]   CPU count: 8\n",
            "[codecarbon INFO @ 00:41:58]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:41:58]   GPU count: 1\n",
            "[codecarbon INFO @ 00:41:58]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.682157576084137, 'eval_accuracy': 0.5906862745098039, 'eval_f1': 0.6843100189035917, 'eval_runtime': 0.7723, 'eval_samples_per_second': 528.302, 'eval_steps_per_second': 66.038, 'epoch': 1.0}\n",
            "{'loss': 0.7126, 'grad_norm': 0.654570460319519, 'learning_rate': 3.638344226579521e-05, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.647083580493927, 'eval_accuracy': 0.6813725490196079, 'eval_f1': 0.8012232415902141, 'eval_runtime': 0.7693, 'eval_samples_per_second': 530.381, 'eval_steps_per_second': 66.298, 'epoch': 2.0}\n",
            "{'loss': 0.6594, 'grad_norm': 0.9191074371337891, 'learning_rate': 2.2766884531590417e-05, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:42:13] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:42:13] Energy consumed for all GPUs : 0.000139 kWh. Total GPU Power : 33.45510700008918 W\n",
            "[codecarbon INFO @ 00:42:13] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:42:13] 0.000396 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6365296840667725, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8054298642533937, 'eval_runtime': 0.7662, 'eval_samples_per_second': 532.49, 'eval_steps_per_second': 66.561, 'epoch': 3.0}\n",
            "{'loss': 0.6381, 'grad_norm': 1.013505220413208, 'learning_rate': 9.150326797385621e-06, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:42:19] Energy consumed for RAM : 0.000112 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:42:19] Energy consumed for all GPUs : 0.000195 kWh. Total GPU Power : 33.26620143920222 W\n",
            "[codecarbon INFO @ 00:42:19] Energy consumed for all CPUs : 0.000249 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:42:19] 0.000556 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6337307691574097, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8054298642533937, 'eval_runtime': 0.758, 'eval_samples_per_second': 538.285, 'eval_steps_per_second': 67.286, 'epoch': 4.0}\n",
            "{'train_runtime': 20.6765, 'train_samples_per_second': 709.598, 'train_steps_per_second': 88.796, 'train_loss': 0.6648042799340873, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:42:20] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:42:20] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:42:20] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:42:20] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:42:20] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6337307691574097, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8054298642533937, 'eval_runtime': 0.7831, 'eval_samples_per_second': 521.003, 'eval_steps_per_second': 65.125, 'epoch': 4.0}\n",
            "Progress: 24/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:42:21] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:42:21] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:42:21] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:42:21]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:42:21]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:42:21]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:42:21]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:42:21]   CPU count: 8\n",
            "[codecarbon INFO @ 00:42:21]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:42:21]   GPU count: 1\n",
            "[codecarbon INFO @ 00:42:21]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7131109833717346, 'eval_accuracy': 0.3627450980392157, 'eval_f1': 0.1875, 'eval_runtime': 0.8248, 'eval_samples_per_second': 494.684, 'eval_steps_per_second': 61.835, 'epoch': 1.0}\n",
            "{'loss': 0.7292, 'grad_norm': 0.7092527747154236, 'learning_rate': 2.1830065359477124e-05, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.681006133556366, 'eval_accuracy': 0.6053921568627451, 'eval_f1': 0.6990654205607477, 'eval_runtime': 0.8915, 'eval_samples_per_second': 457.664, 'eval_steps_per_second': 57.208, 'epoch': 2.0}\n",
            "{'loss': 0.6908, 'grad_norm': 1.20039963722229, 'learning_rate': 1.366013071895425e-05, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:42:36] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:42:36] Energy consumed for all GPUs : 0.000140 kWh. Total GPU Power : 33.49941363074899 W\n",
            "[codecarbon INFO @ 00:42:36] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:42:36] 0.000397 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6656765937805176, 'eval_accuracy': 0.6519607843137255, 'eval_f1': 0.7656765676567657, 'eval_runtime': 0.7969, 'eval_samples_per_second': 511.972, 'eval_steps_per_second': 63.996, 'epoch': 3.0}\n",
            "{'loss': 0.6677, 'grad_norm': 0.753052294254303, 'learning_rate': 5.490196078431373e-06, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:42:43] Energy consumed for RAM : 0.000114 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:42:43] Energy consumed for all GPUs : 0.000198 kWh. Total GPU Power : 32.87906568622792 W\n",
            "[codecarbon INFO @ 00:42:43] Energy consumed for all CPUs : 0.000253 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:42:43] 0.000564 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6615055799484253, 'eval_accuracy': 0.6617647058823529, 'eval_f1': 0.775974025974026, 'eval_runtime': 0.8101, 'eval_samples_per_second': 503.617, 'eval_steps_per_second': 62.952, 'epoch': 4.0}\n",
            "{'train_runtime': 20.9991, 'train_samples_per_second': 698.696, 'train_steps_per_second': 87.432, 'train_loss': 0.6904817635197525, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:42:44] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:42:44] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:42:44] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:42:44] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:42:44] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6615055799484253, 'eval_accuracy': 0.6617647058823529, 'eval_f1': 0.775974025974026, 'eval_runtime': 0.7941, 'eval_samples_per_second': 513.799, 'eval_steps_per_second': 64.225, 'epoch': 4.0}\n",
            "Progress: 25/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:42:45] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:42:45] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:42:45] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:42:45]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:42:45]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:42:45]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:42:45]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:42:45]   CPU count: 8\n",
            "[codecarbon INFO @ 00:42:45]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:42:45]   GPU count: 1\n",
            "[codecarbon INFO @ 00:42:45]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.624168872833252, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8123167155425219, 'eval_runtime': 0.677, 'eval_samples_per_second': 602.69, 'eval_steps_per_second': 38.407, 'epoch': 1.0}\n",
            "{'eval_loss': 0.618809700012207, 'eval_accuracy': 0.6911764705882353, 'eval_f1': 0.8147058823529412, 'eval_runtime': 0.6689, 'eval_samples_per_second': 609.954, 'eval_steps_per_second': 38.87, 'epoch': 2.0}\n",
            "{'loss': 0.6397, 'grad_norm': 0.5458133220672607, 'learning_rate': 0.00013695652173913042, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.6176239252090454, 'eval_accuracy': 0.6911764705882353, 'eval_f1': 0.8141592920353983, 'eval_runtime': 0.6785, 'eval_samples_per_second': 601.332, 'eval_steps_per_second': 38.32, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:42:58] Energy consumed for RAM : 0.000070 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:42:58] Energy consumed for all GPUs : 0.000125 kWh. Total GPU Power : 34.39673121446719 W\n",
            "[codecarbon INFO @ 00:42:58] Energy consumed for all CPUs : 0.000155 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:42:58] 0.000349 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.616595983505249, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8153618906942393, 'eval_runtime': 0.7267, 'eval_samples_per_second': 561.422, 'eval_steps_per_second': 35.777, 'epoch': 4.0}\n",
            "{'train_runtime': 12.704, 'train_samples_per_second': 1154.915, 'train_steps_per_second': 72.418, 'train_loss': 0.6298254261846128, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:42:59] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:42:59] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:42:59] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:42:59] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:42:59] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.616595983505249, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8153618906942393, 'eval_runtime': 0.7068, 'eval_samples_per_second': 577.253, 'eval_steps_per_second': 36.786, 'epoch': 4.0}\n",
            "Progress: 26/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:43:00] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:43:00] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:43:00] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:43:00]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:43:00]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:43:00]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:43:00]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:43:00]   CPU count: 8\n",
            "[codecarbon INFO @ 00:43:00]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:43:00]   GPU count: 1\n",
            "[codecarbon INFO @ 00:43:00]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6690982580184937, 'eval_accuracy': 0.6495098039215687, 'eval_f1': 0.7596638655462185, 'eval_runtime': 0.667, 'eval_samples_per_second': 611.734, 'eval_steps_per_second': 38.983, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6363860368728638, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.806015037593985, 'eval_runtime': 0.6861, 'eval_samples_per_second': 594.69, 'eval_steps_per_second': 37.897, 'epoch': 2.0}\n",
            "{'loss': 0.6766, 'grad_norm': 0.44314324855804443, 'learning_rate': 4.565217391304348e-05, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.6290135383605957, 'eval_accuracy': 0.6911764705882353, 'eval_f1': 0.8136094674556213, 'eval_runtime': 0.7176, 'eval_samples_per_second': 568.581, 'eval_steps_per_second': 36.233, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:43:13] Energy consumed for RAM : 0.000070 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:43:13] Energy consumed for all GPUs : 0.000126 kWh. Total GPU Power : 34.4808737324744 W\n",
            "[codecarbon INFO @ 00:43:13] Energy consumed for all CPUs : 0.000155 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:43:13] 0.000350 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6274420619010925, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8112094395280236, 'eval_runtime': 0.7124, 'eval_samples_per_second': 572.707, 'eval_steps_per_second': 36.496, 'epoch': 4.0}\n",
            "{'train_runtime': 12.7237, 'train_samples_per_second': 1153.12, 'train_steps_per_second': 72.306, 'train_loss': 0.6559569980787194, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:43:14] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:43:14] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:43:14] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:43:14] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:43:14] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6274420619010925, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8112094395280236, 'eval_runtime': 0.6711, 'eval_samples_per_second': 607.916, 'eval_steps_per_second': 38.74, 'epoch': 4.0}\n",
            "Progress: 27/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:43:15] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:43:15] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:43:15] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:43:15]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:43:15]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:43:15]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:43:15]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:43:15]   CPU count: 8\n",
            "[codecarbon INFO @ 00:43:15]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:43:15]   GPU count: 1\n",
            "[codecarbon INFO @ 00:43:15]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7133082747459412, 'eval_accuracy': 0.35784313725490197, 'eval_f1': 0.1761006289308176, 'eval_runtime': 0.6771, 'eval_samples_per_second': 602.594, 'eval_steps_per_second': 38.401, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6800655126571655, 'eval_accuracy': 0.6127450980392157, 'eval_f1': 0.7074074074074074, 'eval_runtime': 0.6986, 'eval_samples_per_second': 583.989, 'eval_steps_per_second': 37.215, 'epoch': 2.0}\n",
            "{'loss': 0.7095, 'grad_norm': 0.47589099407196045, 'learning_rate': 2.282608695652174e-05, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.6642559170722961, 'eval_accuracy': 0.6593137254901961, 'eval_f1': 0.7725040916530278, 'eval_runtime': 0.666, 'eval_samples_per_second': 612.591, 'eval_steps_per_second': 39.038, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:43:28] Energy consumed for RAM : 0.000069 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:43:28] Energy consumed for all GPUs : 0.000125 kWh. Total GPU Power : 34.42683803405888 W\n",
            "[codecarbon INFO @ 00:43:28] Energy consumed for all CPUs : 0.000154 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:43:28] 0.000348 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6596514582633972, 'eval_accuracy': 0.6642156862745098, 'eval_f1': 0.7800963081861958, 'eval_runtime': 0.6865, 'eval_samples_per_second': 594.358, 'eval_steps_per_second': 37.876, 'epoch': 4.0}\n",
            "{'train_runtime': 12.6669, 'train_samples_per_second': 1158.29, 'train_steps_per_second': 72.63, 'train_loss': 0.6895348258640455, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:43:29] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:43:29] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:43:29] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:43:29] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:43:29] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6596514582633972, 'eval_accuracy': 0.6642156862745098, 'eval_f1': 0.7800963081861958, 'eval_runtime': 0.6721, 'eval_samples_per_second': 607.09, 'eval_steps_per_second': 38.687, 'epoch': 4.0}\n",
            "Progress: 28/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:43:30] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:43:30] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:43:30] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:43:30]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:43:30]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:43:30]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:43:30]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:43:30]   CPU count: 8\n",
            "[codecarbon INFO @ 00:43:30]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:43:30]   GPU count: 1\n",
            "[codecarbon INFO @ 00:43:30]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7314130663871765, 'eval_accuracy': 0.31862745098039214, 'eval_f1': 0.007142857142857143, 'eval_runtime': 0.6971, 'eval_samples_per_second': 585.249, 'eval_steps_per_second': 37.295, 'epoch': 1.0}\n",
            "{'eval_loss': 0.7117631435394287, 'eval_accuracy': 0.37254901960784315, 'eval_f1': 0.2147239263803681, 'eval_runtime': 0.6613, 'eval_samples_per_second': 616.955, 'eval_steps_per_second': 39.316, 'epoch': 2.0}\n",
            "{'loss': 0.7275, 'grad_norm': 0.5806406140327454, 'learning_rate': 1.3695652173913042e-05, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.6996377110481262, 'eval_accuracy': 0.4534313725490196, 'eval_f1': 0.45742092457420924, 'eval_runtime': 0.7014, 'eval_samples_per_second': 581.707, 'eval_steps_per_second': 37.07, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:43:43] Energy consumed for RAM : 0.000069 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:43:43] Energy consumed for all GPUs : 0.000124 kWh. Total GPU Power : 34.38376200310638 W\n",
            "[codecarbon INFO @ 00:43:43] Energy consumed for all CPUs : 0.000153 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:43:43] 0.000345 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6956103444099426, 'eval_accuracy': 0.5073529411764706, 'eval_f1': 0.5503355704697986, 'eval_runtime': 0.6813, 'eval_samples_per_second': 598.873, 'eval_steps_per_second': 38.163, 'epoch': 4.0}\n",
            "{'train_runtime': 12.5644, 'train_samples_per_second': 1167.743, 'train_steps_per_second': 73.223, 'train_loss': 0.7141179955523947, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:43:44] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:43:44] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:43:44] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:43:44] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:43:44] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6956103444099426, 'eval_accuracy': 0.5073529411764706, 'eval_f1': 0.5503355704697986, 'eval_runtime': 0.6877, 'eval_samples_per_second': 593.323, 'eval_steps_per_second': 37.81, 'epoch': 4.0}\n",
            "Progress: 29/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:43:45] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:43:45] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:43:45] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:43:45]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:43:45]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:43:45]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:43:45]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:43:45]   CPU count: 8\n",
            "[codecarbon INFO @ 00:43:45]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:43:45]   GPU count: 1\n",
            "[codecarbon INFO @ 00:43:45]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6342222690582275, 'eval_accuracy': 0.6813725490196079, 'eval_f1': 0.8059701492537313, 'eval_runtime': 0.7294, 'eval_samples_per_second': 559.393, 'eval_steps_per_second': 17.824, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6231908798217773, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8100147275405007, 'eval_runtime': 0.621, 'eval_samples_per_second': 657.003, 'eval_steps_per_second': 20.934, 'epoch': 2.0}\n",
            "{'eval_loss': 0.621665358543396, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8112094395280236, 'eval_runtime': 0.609, 'eval_samples_per_second': 669.972, 'eval_steps_per_second': 21.347, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:43:54] Energy consumed for RAM : 0.000049 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:43:54] Energy consumed for all GPUs : 0.000092 kWh. Total GPU Power : 35.709747929653695 W\n",
            "[codecarbon INFO @ 00:43:54] Energy consumed for all CPUs : 0.000110 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:43:54] 0.000251 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6211062669754028, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8106508875739645, 'eval_runtime': 0.6359, 'eval_samples_per_second': 641.64, 'eval_steps_per_second': 20.444, 'epoch': 4.0}\n",
            "{'train_runtime': 8.921, 'train_samples_per_second': 1644.663, 'train_steps_per_second': 51.564, 'train_loss': 0.6405872510827106, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:43:55] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:43:55] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:43:55] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:43:55] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:43:55] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6211062669754028, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8106508875739645, 'eval_runtime': 0.6201, 'eval_samples_per_second': 657.963, 'eval_steps_per_second': 20.964, 'epoch': 4.0}\n",
            "Progress: 30/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:43:56] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:43:56] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:43:56] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:43:56]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:43:56]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:43:56]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:43:56]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:43:56]   CPU count: 8\n",
            "[codecarbon INFO @ 00:43:56]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:43:56]   GPU count: 1\n",
            "[codecarbon INFO @ 00:43:56]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.70732182264328, 'eval_accuracy': 0.39705882352941174, 'eval_f1': 0.3050847457627119, 'eval_runtime': 0.6325, 'eval_samples_per_second': 645.086, 'eval_steps_per_second': 20.554, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6700288653373718, 'eval_accuracy': 0.6397058823529411, 'eval_f1': 0.751269035532995, 'eval_runtime': 0.6811, 'eval_samples_per_second': 599.039, 'eval_steps_per_second': 19.087, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6537978053092957, 'eval_accuracy': 0.6740196078431373, 'eval_f1': 0.7937984496124031, 'eval_runtime': 0.6386, 'eval_samples_per_second': 638.92, 'eval_steps_per_second': 20.358, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:44:06] Energy consumed for RAM : 0.000049 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:44:06] Energy consumed for all GPUs : 0.000093 kWh. Total GPU Power : 35.977118161568164 W\n",
            "[codecarbon INFO @ 00:44:06] Energy consumed for all CPUs : 0.000110 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:44:06] 0.000253 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6494660973548889, 'eval_accuracy': 0.6715686274509803, 'eval_f1': 0.7938461538461539, 'eval_runtime': 0.6179, 'eval_samples_per_second': 660.33, 'eval_steps_per_second': 21.04, 'epoch': 4.0}\n",
            "{'train_runtime': 8.9256, 'train_samples_per_second': 1643.812, 'train_steps_per_second': 51.537, 'train_loss': 0.6832222980001699, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:44:06] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:44:06] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:44:06] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:44:06] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:44:06] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6494660973548889, 'eval_accuracy': 0.6715686274509803, 'eval_f1': 0.7938461538461539, 'eval_runtime': 0.6496, 'eval_samples_per_second': 628.074, 'eval_steps_per_second': 20.012, 'epoch': 4.0}\n",
            "Progress: 31/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:44:07] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:44:07] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:44:07] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:44:07]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:44:07]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:44:07]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:44:07]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:44:07]   CPU count: 8\n",
            "[codecarbon INFO @ 00:44:07]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:44:07]   GPU count: 1\n",
            "[codecarbon INFO @ 00:44:07]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7328468561172485, 'eval_accuracy': 0.31862745098039214, 'eval_f1': 0.007142857142857143, 'eval_runtime': 0.6316, 'eval_samples_per_second': 646.006, 'eval_steps_per_second': 20.584, 'epoch': 1.0}\n",
            "{'eval_loss': 0.7145857214927673, 'eval_accuracy': 0.34558823529411764, 'eval_f1': 0.13592233009708737, 'eval_runtime': 0.6544, 'eval_samples_per_second': 623.438, 'eval_steps_per_second': 19.864, 'epoch': 2.0}\n",
            "{'eval_loss': 0.7027550339698792, 'eval_accuracy': 0.41911764705882354, 'eval_f1': 0.381201044386423, 'eval_runtime': 0.6278, 'eval_samples_per_second': 649.905, 'eval_steps_per_second': 20.708, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:44:17] Energy consumed for RAM : 0.000050 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:44:17] Energy consumed for all GPUs : 0.000093 kWh. Total GPU Power : 35.77360854734722 W\n",
            "[codecarbon INFO @ 00:44:17] Energy consumed for all CPUs : 0.000111 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:44:17] 0.000253 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.698790431022644, 'eval_accuracy': 0.45588235294117646, 'eval_f1': 0.4714285714285714, 'eval_runtime': 0.6248, 'eval_samples_per_second': 652.982, 'eval_steps_per_second': 20.806, 'epoch': 4.0}\n",
            "{'train_runtime': 8.9784, 'train_samples_per_second': 1634.14, 'train_steps_per_second': 51.234, 'train_loss': 0.7170496401579484, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:44:18] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:44:18] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:44:18] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:44:18] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:44:18] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.698790431022644, 'eval_accuracy': 0.45588235294117646, 'eval_f1': 0.4714285714285714, 'eval_runtime': 0.6386, 'eval_samples_per_second': 638.947, 'eval_steps_per_second': 20.359, 'epoch': 4.0}\n",
            "Progress: 32/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:44:19] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:44:19] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:44:19] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:44:19]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:44:19]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:44:19]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:44:19]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:44:19]   CPU count: 8\n",
            "[codecarbon INFO @ 00:44:19]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:44:19]   GPU count: 1\n",
            "[codecarbon INFO @ 00:44:19]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7420257329940796, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6243, 'eval_samples_per_second': 653.576, 'eval_steps_per_second': 20.825, 'epoch': 1.0}\n",
            "{'eval_loss': 0.7321144342422485, 'eval_accuracy': 0.31862745098039214, 'eval_f1': 0.007142857142857143, 'eval_runtime': 0.6207, 'eval_samples_per_second': 657.275, 'eval_steps_per_second': 20.943, 'epoch': 2.0}\n",
            "{'eval_loss': 0.7257580757141113, 'eval_accuracy': 0.31862745098039214, 'eval_f1': 0.02112676056338028, 'eval_runtime': 0.6906, 'eval_samples_per_second': 590.777, 'eval_steps_per_second': 18.824, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:44:28] Energy consumed for RAM : 0.000049 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:44:28] Energy consumed for all GPUs : 0.000093 kWh. Total GPU Power : 36.07139259932601 W\n",
            "[codecarbon INFO @ 00:44:28] Energy consumed for all CPUs : 0.000110 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:44:28] 0.000252 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.723508894443512, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.021052631578947368, 'eval_runtime': 0.6377, 'eval_samples_per_second': 639.771, 'eval_steps_per_second': 20.385, 'epoch': 4.0}\n",
            "{'train_runtime': 8.8928, 'train_samples_per_second': 1649.866, 'train_steps_per_second': 51.727, 'train_loss': 0.7325950290845789, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:44:29] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:44:29] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:44:29] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:44:29] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:44:29] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.723508894443512, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.021052631578947368, 'eval_runtime': 0.6377, 'eval_samples_per_second': 639.836, 'eval_steps_per_second': 20.387, 'epoch': 4.0}\n",
            "Progress: 33/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:44:30] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:44:30] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:44:30] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:44:30]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:44:30]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:44:30]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:44:30]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:44:30]   CPU count: 8\n",
            "[codecarbon INFO @ 00:44:30]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:44:30]   GPU count: 1\n",
            "[codecarbon INFO @ 00:44:30]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6763866543769836, 'eval_accuracy': 0.6225490196078431, 'eval_f1': 0.725, 'eval_runtime': 0.6035, 'eval_samples_per_second': 676.063, 'eval_steps_per_second': 11.599, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6373472213745117, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8072289156626506, 'eval_runtime': 0.6126, 'eval_samples_per_second': 665.974, 'eval_steps_per_second': 11.426, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6285027861595154, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8112094395280236, 'eval_runtime': 0.5955, 'eval_samples_per_second': 685.166, 'eval_steps_per_second': 11.755, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:44:37] Energy consumed for RAM : 0.000039 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:44:37] Energy consumed for all GPUs : 0.000080 kWh. Total GPU Power : 39.08494990175138 W\n",
            "[codecarbon INFO @ 00:44:37] Energy consumed for all CPUs : 0.000087 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:44:37] 0.000206 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6271914839744568, 'eval_accuracy': 0.6813725490196079, 'eval_f1': 0.8088235294117647, 'eval_runtime': 0.6003, 'eval_samples_per_second': 679.656, 'eval_steps_per_second': 11.661, 'epoch': 4.0}\n",
            "{'train_runtime': 6.9897, 'train_samples_per_second': 2099.097, 'train_steps_per_second': 33.192, 'train_loss': 0.6588426787277748, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:44:38] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:44:38] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:44:38] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:44:38] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:44:38] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6271914839744568, 'eval_accuracy': 0.6813725490196079, 'eval_f1': 0.8088235294117647, 'eval_runtime': 0.615, 'eval_samples_per_second': 663.365, 'eval_steps_per_second': 11.381, 'epoch': 4.0}\n",
            "Progress: 34/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:44:39] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:44:39] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:44:39] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:44:39]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:44:39]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:44:39]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:44:39]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:44:39]   CPU count: 8\n",
            "[codecarbon INFO @ 00:44:39]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:44:39]   GPU count: 1\n",
            "[codecarbon INFO @ 00:44:39]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.731223464012146, 'eval_accuracy': 0.31862745098039214, 'eval_f1': 0.007142857142857143, 'eval_runtime': 0.6003, 'eval_samples_per_second': 679.704, 'eval_steps_per_second': 11.662, 'epoch': 1.0}\n",
            "{'eval_loss': 0.7103810906410217, 'eval_accuracy': 0.375, 'eval_f1': 0.23423423423423423, 'eval_runtime': 0.594, 'eval_samples_per_second': 686.858, 'eval_steps_per_second': 11.784, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6972783207893372, 'eval_accuracy': 0.4803921568627451, 'eval_f1': 0.5092592592592593, 'eval_runtime': 0.6027, 'eval_samples_per_second': 676.95, 'eval_steps_per_second': 11.614, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:44:47] Energy consumed for RAM : 0.000038 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:44:47] Energy consumed for all GPUs : 0.000079 kWh. Total GPU Power : 39.20586054649846 W\n",
            "[codecarbon INFO @ 00:44:47] Energy consumed for all CPUs : 0.000085 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:44:47] 0.000202 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6927284002304077, 'eval_accuracy': 0.5220588235294118, 'eval_f1': 0.587737843551797, 'eval_runtime': 0.61, 'eval_samples_per_second': 668.808, 'eval_steps_per_second': 11.475, 'epoch': 4.0}\n",
            "{'train_runtime': 6.8597, 'train_samples_per_second': 2138.863, 'train_steps_per_second': 33.821, 'train_loss': 0.7135580654801994, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:44:47] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:44:47] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:44:47] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:44:47] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:44:47] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6927284002304077, 'eval_accuracy': 0.5220588235294118, 'eval_f1': 0.587737843551797, 'eval_runtime': 0.5996, 'eval_samples_per_second': 680.45, 'eval_steps_per_second': 11.674, 'epoch': 4.0}\n",
            "Progress: 35/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:44:48] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:44:48] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:44:48] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:44:48]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:44:48]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:44:48]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:44:48]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:44:48]   CPU count: 8\n",
            "[codecarbon INFO @ 00:44:48]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:44:48]   GPU count: 1\n",
            "[codecarbon INFO @ 00:44:48]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7434484958648682, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6505, 'eval_samples_per_second': 627.19, 'eval_steps_per_second': 10.761, 'epoch': 1.0}\n",
            "{'eval_loss': 0.7342860102653503, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6273, 'eval_samples_per_second': 650.356, 'eval_steps_per_second': 11.158, 'epoch': 2.0}\n",
            "{'eval_loss': 0.7285972833633423, 'eval_accuracy': 0.31862745098039214, 'eval_f1': 0.014184397163120567, 'eval_runtime': 0.6138, 'eval_samples_per_second': 664.752, 'eval_steps_per_second': 11.405, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:44:56] Energy consumed for RAM : 0.000039 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:44:56] Energy consumed for all GPUs : 0.000080 kWh. Total GPU Power : 38.92488236175845 W\n",
            "[codecarbon INFO @ 00:44:56] Energy consumed for all CPUs : 0.000088 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:44:56] 0.000207 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7265555262565613, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.014134275618374558, 'eval_runtime': 0.6458, 'eval_samples_per_second': 631.804, 'eval_steps_per_second': 10.84, 'epoch': 4.0}\n",
            "{'train_runtime': 7.0374, 'train_samples_per_second': 2084.871, 'train_steps_per_second': 32.967, 'train_loss': 0.7346628123316271, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:44:57] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:44:57] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:44:57] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:44:57] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:44:57] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7265555262565613, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.014134275618374558, 'eval_runtime': 0.6047, 'eval_samples_per_second': 674.667, 'eval_steps_per_second': 11.575, 'epoch': 4.0}\n",
            "Progress: 36/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:44:58] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:44:58] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:44:58] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:44:58]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:44:58]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:44:58]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:44:58]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:44:58]   CPU count: 8\n",
            "[codecarbon INFO @ 00:44:58]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:44:58]   GPU count: 1\n",
            "[codecarbon INFO @ 00:44:58]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7481318712234497, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6405, 'eval_samples_per_second': 637.0, 'eval_steps_per_second': 10.929, 'epoch': 1.0}\n",
            "{'eval_loss': 0.7428916692733765, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.593, 'eval_samples_per_second': 688.083, 'eval_steps_per_second': 11.805, 'epoch': 2.0}\n",
            "{'eval_loss': 0.739730179309845, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.5969, 'eval_samples_per_second': 683.51, 'eval_steps_per_second': 11.727, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:45:05] Energy consumed for RAM : 0.000039 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:45:05] Energy consumed for all GPUs : 0.000080 kWh. Total GPU Power : 38.670007993757444 W\n",
            "[codecarbon INFO @ 00:45:05] Energy consumed for all CPUs : 0.000088 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:45:05] 0.000207 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7386116981506348, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6112, 'eval_samples_per_second': 667.527, 'eval_steps_per_second': 11.453, 'epoch': 4.0}\n",
            "{'train_runtime': 7.0579, 'train_samples_per_second': 2078.811, 'train_steps_per_second': 32.871, 'train_loss': 0.7426524984425512, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:45:06] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:45:06] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:45:06] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:45:06] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:45:06] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7386116981506348, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.614, 'eval_samples_per_second': 664.445, 'eval_steps_per_second': 11.4, 'epoch': 4.0}\n",
            "Progress: 37/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:45:07] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:45:07] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:45:07] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:45:07]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:45:07]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:45:07]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:45:07]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:45:07]   CPU count: 8\n",
            "[codecarbon INFO @ 00:45:07]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:45:07]   GPU count: 1\n",
            "[codecarbon INFO @ 00:45:07]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7163118720054626, 'eval_accuracy': 0.3284313725490196, 'eval_f1': 0.09271523178807947, 'eval_runtime': 0.5911, 'eval_samples_per_second': 690.275, 'eval_steps_per_second': 6.767, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6824800372123718, 'eval_accuracy': 0.5882352941176471, 'eval_f1': 0.6818181818181818, 'eval_runtime': 0.6002, 'eval_samples_per_second': 679.805, 'eval_steps_per_second': 6.665, 'epoch': 2.0}\n",
            "{'eval_loss': 0.664183497428894, 'eval_accuracy': 0.6617647058823529, 'eval_f1': 0.7737704918032787, 'eval_runtime': 0.5907, 'eval_samples_per_second': 690.705, 'eval_steps_per_second': 6.772, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:45:14] Energy consumed for RAM : 0.000035 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:45:14] Energy consumed for all GPUs : 0.000086 kWh. Total GPU Power : 46.48853038935658 W\n",
            "[codecarbon INFO @ 00:45:14] Energy consumed for all CPUs : 0.000078 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:45:14] 0.000200 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.659213662147522, 'eval_accuracy': 0.6593137254901961, 'eval_f1': 0.7768860353130016, 'eval_runtime': 0.6177, 'eval_samples_per_second': 660.501, 'eval_steps_per_second': 6.475, 'epoch': 4.0}\n",
            "{'train_runtime': 6.2617, 'train_samples_per_second': 2343.128, 'train_steps_per_second': 18.525, 'train_loss': 0.6922296326735924, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:45:14] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:45:14] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:45:14] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:45:14] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:45:14] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.659213662147522, 'eval_accuracy': 0.6593137254901961, 'eval_f1': 0.7768860353130016, 'eval_runtime': 0.6169, 'eval_samples_per_second': 661.419, 'eval_steps_per_second': 6.484, 'epoch': 4.0}\n",
            "Progress: 38/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:45:16] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:45:16] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:45:16] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:45:16]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:45:16]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:45:16]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:45:16]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:45:16]   CPU count: 8\n",
            "[codecarbon INFO @ 00:45:16]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:45:16]   GPU count: 1\n",
            "[codecarbon INFO @ 00:45:16]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7427352666854858, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.5988, 'eval_samples_per_second': 681.321, 'eval_steps_per_second': 6.68, 'epoch': 1.0}\n",
            "{'eval_loss': 0.7333709597587585, 'eval_accuracy': 0.31862745098039214, 'eval_f1': 0.007142857142857143, 'eval_runtime': 0.5961, 'eval_samples_per_second': 684.5, 'eval_steps_per_second': 6.711, 'epoch': 2.0}\n",
            "{'eval_loss': 0.7272953987121582, 'eval_accuracy': 0.31862745098039214, 'eval_f1': 0.014184397163120567, 'eval_runtime': 0.6761, 'eval_samples_per_second': 603.452, 'eval_steps_per_second': 5.916, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:45:23] Energy consumed for RAM : 0.000036 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:45:23] Energy consumed for all GPUs : 0.000086 kWh. Total GPU Power : 45.53016034688332 W\n",
            "[codecarbon INFO @ 00:45:23] Energy consumed for all CPUs : 0.000080 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:45:23] 0.000203 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7250537276268005, 'eval_accuracy': 0.31862745098039214, 'eval_f1': 0.02112676056338028, 'eval_runtime': 0.623, 'eval_samples_per_second': 654.847, 'eval_steps_per_second': 6.42, 'epoch': 4.0}\n",
            "{'train_runtime': 6.3888, 'train_samples_per_second': 2296.52, 'train_steps_per_second': 18.157, 'train_loss': 0.7337716858962486, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:45:23] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:45:23] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:45:23] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:45:23] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:45:23] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7250537276268005, 'eval_accuracy': 0.31862745098039214, 'eval_f1': 0.02112676056338028, 'eval_runtime': 0.5934, 'eval_samples_per_second': 687.544, 'eval_steps_per_second': 6.741, 'epoch': 4.0}\n",
            "Progress: 39/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:45:24] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:45:24] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:45:24] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:45:24]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:45:24]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:45:24]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:45:24]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:45:24]   CPU count: 8\n",
            "[codecarbon INFO @ 00:45:24]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:45:24]   GPU count: 1\n",
            "[codecarbon INFO @ 00:45:24]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7489240765571594, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.5858, 'eval_samples_per_second': 696.539, 'eval_steps_per_second': 6.829, 'epoch': 1.0}\n",
            "{'eval_loss': 0.7444689273834229, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.617, 'eval_samples_per_second': 661.31, 'eval_steps_per_second': 6.483, 'epoch': 2.0}\n",
            "{'eval_loss': 0.7417362928390503, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.7677, 'eval_samples_per_second': 531.448, 'eval_steps_per_second': 5.21, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:45:31] Energy consumed for RAM : 0.000037 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:45:31] Energy consumed for all GPUs : 0.000086 kWh. Total GPU Power : 44.83050634706457 W\n",
            "[codecarbon INFO @ 00:45:31] Energy consumed for all CPUs : 0.000082 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:45:31] 0.000205 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7407467365264893, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.598, 'eval_samples_per_second': 682.272, 'eval_steps_per_second': 6.689, 'epoch': 4.0}\n",
            "{'train_runtime': 6.5289, 'train_samples_per_second': 2247.248, 'train_steps_per_second': 17.767, 'train_loss': 0.7440924808896822, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:45:32] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:45:32] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:45:32] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:45:32] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:45:32] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7407467365264893, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.5858, 'eval_samples_per_second': 696.511, 'eval_steps_per_second': 6.829, 'epoch': 4.0}\n",
            "Progress: 40/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:45:33] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:45:33] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:45:33] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:45:33]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:45:33]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:45:33]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:45:33]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:45:33]   CPU count: 8\n",
            "[codecarbon INFO @ 00:45:33]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:45:33]   GPU count: 1\n",
            "[codecarbon INFO @ 00:45:33]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7513824105262756, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.5895, 'eval_samples_per_second': 692.088, 'eval_steps_per_second': 6.785, 'epoch': 1.0}\n",
            "{'eval_loss': 0.7487399578094482, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.7636, 'eval_samples_per_second': 534.303, 'eval_steps_per_second': 5.238, 'epoch': 2.0}\n",
            "{'eval_loss': 0.7471480965614319, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6038, 'eval_samples_per_second': 675.712, 'eval_steps_per_second': 6.625, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:45:40] Energy consumed for RAM : 0.000038 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:45:40] Energy consumed for all GPUs : 0.000085 kWh. Total GPU Power : 42.543956545846015 W\n",
            "[codecarbon INFO @ 00:45:40] Energy consumed for all CPUs : 0.000085 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:45:40] 0.000207 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7465769648551941, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.7887, 'eval_samples_per_second': 517.332, 'eval_steps_per_second': 5.072, 'epoch': 4.0}\n",
            "{'train_runtime': 6.7731, 'train_samples_per_second': 2166.223, 'train_steps_per_second': 17.127, 'train_loss': 0.7481302064040611, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:45:41] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:45:41] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:45:41] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:45:41] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:45:41] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7465769648551941, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6026, 'eval_samples_per_second': 677.064, 'eval_steps_per_second': 6.638, 'epoch': 4.0}\n",
            "Progress: 41/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:45:42] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:45:42] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:45:42] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:45:42]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:45:42]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:45:42]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:45:42]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:45:42]   CPU count: 8\n",
            "[codecarbon INFO @ 00:45:42]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:45:42]   GPU count: 1\n",
            "[codecarbon INFO @ 00:45:42]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6193325519561768, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8106508875739645, 'eval_runtime': 0.7657, 'eval_samples_per_second': 532.84, 'eval_steps_per_second': 66.605, 'epoch': 1.0}\n",
            "{'loss': 0.6324, 'grad_norm': 1.3378976583480835, 'learning_rate': 0.00021830065359477123, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.6141953468322754, 'eval_accuracy': 0.6911764705882353, 'eval_f1': 0.8136094674556213, 'eval_runtime': 0.818, 'eval_samples_per_second': 498.78, 'eval_steps_per_second': 62.347, 'epoch': 2.0}\n",
            "{'loss': 0.6168, 'grad_norm': 1.0803943872451782, 'learning_rate': 0.00013660130718954247, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:45:57] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:45:57] Energy consumed for all GPUs : 0.000141 kWh. Total GPU Power : 33.82153104256307 W\n",
            "[codecarbon INFO @ 00:45:57] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:45:57] 0.000398 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6115539073944092, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8137108792846498, 'eval_runtime': 0.7643, 'eval_samples_per_second': 533.809, 'eval_steps_per_second': 66.726, 'epoch': 3.0}\n",
            "{'loss': 0.6074, 'grad_norm': 1.0607064962387085, 'learning_rate': 5.4901960784313716e-05, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:46:04] Energy consumed for RAM : 0.000113 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:46:04] Energy consumed for all GPUs : 0.000199 kWh. Total GPU Power : 33.07955711997491 W\n",
            "[codecarbon INFO @ 00:46:04] Energy consumed for all CPUs : 0.000252 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:46:04] 0.000563 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6117095947265625, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8149253731343283, 'eval_runtime': 0.8135, 'eval_samples_per_second': 501.531, 'eval_steps_per_second': 62.691, 'epoch': 4.0}\n",
            "{'train_runtime': 20.9084, 'train_samples_per_second': 701.728, 'train_steps_per_second': 87.812, 'train_loss': 0.6192736324401722, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:46:04] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:46:04] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:46:04] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:46:04] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:46:04] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6117095947265625, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8149253731343283, 'eval_runtime': 0.787, 'eval_samples_per_second': 518.449, 'eval_steps_per_second': 64.806, 'epoch': 4.0}\n",
            "Progress: 42/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:46:06] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:46:06] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:46:06] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:46:06]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:46:06]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:46:06]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:46:06]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:46:06]   CPU count: 8\n",
            "[codecarbon INFO @ 00:46:06]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:46:06]   GPU count: 1\n",
            "[codecarbon INFO @ 00:46:06]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6260072588920593, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8112094395280236, 'eval_runtime': 0.7575, 'eval_samples_per_second': 538.603, 'eval_steps_per_second': 67.325, 'epoch': 1.0}\n",
            "{'loss': 0.6573, 'grad_norm': 1.369666576385498, 'learning_rate': 7.276688453159042e-05, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.6214091777801514, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8112094395280236, 'eval_runtime': 0.7874, 'eval_samples_per_second': 518.159, 'eval_steps_per_second': 64.77, 'epoch': 2.0}\n",
            "{'loss': 0.6242, 'grad_norm': 1.100629210472107, 'learning_rate': 4.5533769063180834e-05, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:46:21] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:46:21] Energy consumed for all GPUs : 0.000139 kWh. Total GPU Power : 33.40529358209621 W\n",
            "[codecarbon INFO @ 00:46:21] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:46:21] 0.000396 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6196784973144531, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8106508875739645, 'eval_runtime': 0.7783, 'eval_samples_per_second': 524.211, 'eval_steps_per_second': 65.526, 'epoch': 3.0}\n",
            "{'loss': 0.6158, 'grad_norm': 1.744248390197754, 'learning_rate': 1.8300653594771242e-05, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:46:27] Energy consumed for RAM : 0.000113 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:46:27] Energy consumed for all GPUs : 0.000198 kWh. Total GPU Power : 33.337175067239926 W\n",
            "[codecarbon INFO @ 00:46:27] Energy consumed for all CPUs : 0.000252 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:46:27] 0.000563 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6194533705711365, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8106508875739645, 'eval_runtime': 0.7808, 'eval_samples_per_second': 522.573, 'eval_steps_per_second': 65.322, 'epoch': 4.0}\n",
            "{'train_runtime': 20.943, 'train_samples_per_second': 700.568, 'train_steps_per_second': 87.666, 'train_loss': 0.6312798061661731, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:46:28] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:46:28] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:46:28] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:46:28] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:46:28] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6194533705711365, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8106508875739645, 'eval_runtime': 0.7602, 'eval_samples_per_second': 536.698, 'eval_steps_per_second': 67.087, 'epoch': 4.0}\n",
            "Progress: 43/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:46:29] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:46:29] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:46:29] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:46:29]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:46:29]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:46:29]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:46:29]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:46:29]   CPU count: 8\n",
            "[codecarbon INFO @ 00:46:29]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:46:29]   GPU count: 1\n",
            "[codecarbon INFO @ 00:46:29]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6472150087356567, 'eval_accuracy': 0.6764705882352942, 'eval_f1': 0.7962962962962963, 'eval_runtime': 0.7884, 'eval_samples_per_second': 517.521, 'eval_steps_per_second': 64.69, 'epoch': 1.0}\n",
            "{'loss': 0.687, 'grad_norm': 1.2276611328125, 'learning_rate': 3.638344226579521e-05, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.6276898384094238, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.808955223880597, 'eval_runtime': 0.8142, 'eval_samples_per_second': 501.087, 'eval_steps_per_second': 62.636, 'epoch': 2.0}\n",
            "{'loss': 0.6356, 'grad_norm': 1.2310816049575806, 'learning_rate': 2.2766884531590417e-05, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:46:44] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:46:44] Energy consumed for all GPUs : 0.000138 kWh. Total GPU Power : 33.15113112623667 W\n",
            "[codecarbon INFO @ 00:46:44] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:46:44] 0.000395 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6248787641525269, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8106508875739645, 'eval_runtime': 0.7968, 'eval_samples_per_second': 512.024, 'eval_steps_per_second': 64.003, 'epoch': 3.0}\n",
            "{'loss': 0.6236, 'grad_norm': 1.6799287796020508, 'learning_rate': 9.150326797385621e-06, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:46:51] Energy consumed for RAM : 0.000116 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:46:51] Energy consumed for all GPUs : 0.000200 kWh. Total GPU Power : 33.02647922706703 W\n",
            "[codecarbon INFO @ 00:46:51] Energy consumed for all CPUs : 0.000257 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:46:51] 0.000573 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6242032051086426, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8106508875739645, 'eval_runtime': 0.7759, 'eval_samples_per_second': 525.85, 'eval_steps_per_second': 65.731, 'epoch': 4.0}\n",
            "{'train_runtime': 21.3532, 'train_samples_per_second': 687.111, 'train_steps_per_second': 85.983, 'train_loss': 0.6455370834450317, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:46:52] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:46:52] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:46:52] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:46:52] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:46:52] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6242032051086426, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8106508875739645, 'eval_runtime': 0.7566, 'eval_samples_per_second': 539.236, 'eval_steps_per_second': 67.405, 'epoch': 4.0}\n",
            "Progress: 44/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:46:53] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:46:53] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:46:53] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:46:53]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:46:53]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:46:53]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:46:53]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:46:53]   CPU count: 8\n",
            "[codecarbon INFO @ 00:46:53]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:46:53]   GPU count: 1\n",
            "[codecarbon INFO @ 00:46:53]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6795805096626282, 'eval_accuracy': 0.6102941176470589, 'eval_f1': 0.7050092764378478, 'eval_runtime': 0.7741, 'eval_samples_per_second': 527.07, 'eval_steps_per_second': 65.884, 'epoch': 1.0}\n",
            "{'loss': 0.7097, 'grad_norm': 1.2643060684204102, 'learning_rate': 2.1830065359477124e-05, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.6471513509750366, 'eval_accuracy': 0.678921568627451, 'eval_f1': 0.7975270479134466, 'eval_runtime': 0.801, 'eval_samples_per_second': 509.36, 'eval_steps_per_second': 63.67, 'epoch': 2.0}\n",
            "{'loss': 0.6588, 'grad_norm': 1.692984938621521, 'learning_rate': 1.366013071895425e-05, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:47:08] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:47:08] Energy consumed for all GPUs : 0.000138 kWh. Total GPU Power : 33.081250460907455 W\n",
            "[codecarbon INFO @ 00:47:08] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:47:08] 0.000395 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6367414593696594, 'eval_accuracy': 0.6813725490196079, 'eval_f1': 0.8024316109422492, 'eval_runtime': 0.8248, 'eval_samples_per_second': 494.657, 'eval_steps_per_second': 61.832, 'epoch': 3.0}\n",
            "{'loss': 0.638, 'grad_norm': 1.8873090744018555, 'learning_rate': 5.490196078431373e-06, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:47:14] Energy consumed for RAM : 0.000113 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:47:14] Energy consumed for all GPUs : 0.000196 kWh. Total GPU Power : 33.43304895003105 W\n",
            "[codecarbon INFO @ 00:47:14] Energy consumed for all CPUs : 0.000251 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:47:14] 0.000559 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6340346932411194, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8048411497730711, 'eval_runtime': 0.772, 'eval_samples_per_second': 528.505, 'eval_steps_per_second': 66.063, 'epoch': 4.0}\n",
            "{'train_runtime': 20.8437, 'train_samples_per_second': 703.905, 'train_steps_per_second': 88.084, 'train_loss': 0.6638304267833436, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:47:15] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:47:15] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:47:15] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:47:15] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:47:15] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6340346932411194, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8048411497730711, 'eval_runtime': 0.7865, 'eval_samples_per_second': 518.725, 'eval_steps_per_second': 64.841, 'epoch': 4.0}\n",
            "Progress: 45/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:47:16] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:47:16] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:47:16] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:47:16]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:47:16]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:47:16]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:47:16]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:47:16]   CPU count: 8\n",
            "[codecarbon INFO @ 00:47:16]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:47:16]   GPU count: 1\n",
            "[codecarbon INFO @ 00:47:16]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6213349103927612, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8135095447870778, 'eval_runtime': 0.6891, 'eval_samples_per_second': 592.107, 'eval_steps_per_second': 37.732, 'epoch': 1.0}\n",
            "{'eval_loss': 0.617218554019928, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8118518518518518, 'eval_runtime': 0.6587, 'eval_samples_per_second': 619.356, 'eval_steps_per_second': 39.469, 'epoch': 2.0}\n",
            "{'loss': 0.6285, 'grad_norm': 1.0690110921859741, 'learning_rate': 0.00013695652173913042, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.6154178380966187, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.808955223880597, 'eval_runtime': 0.6644, 'eval_samples_per_second': 614.111, 'eval_steps_per_second': 39.135, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:47:29] Energy consumed for RAM : 0.000069 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:47:29] Energy consumed for all GPUs : 0.000123 kWh. Total GPU Power : 34.28767561680778 W\n",
            "[codecarbon INFO @ 00:47:29] Energy consumed for all CPUs : 0.000153 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:47:29] 0.000345 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6154399514198303, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.808955223880597, 'eval_runtime': 0.6656, 'eval_samples_per_second': 613.0, 'eval_steps_per_second': 39.064, 'epoch': 4.0}\n",
            "{'train_runtime': 12.5727, 'train_samples_per_second': 1166.969, 'train_steps_per_second': 73.174, 'train_loss': 0.6220071212105129, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:47:30] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:47:30] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:47:30] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:47:30] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:47:30] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6154399514198303, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.808955223880597, 'eval_runtime': 0.6753, 'eval_samples_per_second': 604.173, 'eval_steps_per_second': 38.501, 'epoch': 4.0}\n",
            "Progress: 46/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:47:31] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:47:31] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:47:31] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:47:31]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:47:31]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:47:31]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:47:31]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:47:31]   CPU count: 8\n",
            "[codecarbon INFO @ 00:47:31]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:47:31]   GPU count: 1\n",
            "[codecarbon INFO @ 00:47:31]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6353374719619751, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8072289156626506, 'eval_runtime': 0.6749, 'eval_samples_per_second': 604.576, 'eval_steps_per_second': 38.527, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6242235898971558, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8117647058823529, 'eval_runtime': 0.6727, 'eval_samples_per_second': 606.483, 'eval_steps_per_second': 38.648, 'epoch': 2.0}\n",
            "{'loss': 0.6529, 'grad_norm': 0.7545903921127319, 'learning_rate': 4.565217391304348e-05, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.623149037361145, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8117647058823529, 'eval_runtime': 0.6836, 'eval_samples_per_second': 596.801, 'eval_steps_per_second': 38.031, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:47:44] Energy consumed for RAM : 0.000069 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:47:44] Energy consumed for all GPUs : 0.000124 kWh. Total GPU Power : 34.37074766040996 W\n",
            "[codecarbon INFO @ 00:47:44] Energy consumed for all CPUs : 0.000153 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:47:44] 0.000345 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6225054860115051, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8117647058823529, 'eval_runtime': 0.6976, 'eval_samples_per_second': 584.899, 'eval_steps_per_second': 37.273, 'epoch': 4.0}\n",
            "{'train_runtime': 12.5596, 'train_samples_per_second': 1168.191, 'train_steps_per_second': 73.251, 'train_loss': 0.639190673828125, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:47:45] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:47:45] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:47:45] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:47:45] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:47:45] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6225054860115051, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8117647058823529, 'eval_runtime': 0.669, 'eval_samples_per_second': 609.858, 'eval_steps_per_second': 38.864, 'epoch': 4.0}\n",
            "Progress: 47/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:47:46] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:47:46] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:47:46] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:47:46]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:47:46]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:47:46]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:47:46]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:47:46]   CPU count: 8\n",
            "[codecarbon INFO @ 00:47:46]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:47:46]   GPU count: 1\n",
            "[codecarbon INFO @ 00:47:46]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.675983726978302, 'eval_accuracy': 0.6200980392156863, 'eval_f1': 0.7217235188509874, 'eval_runtime': 0.6659, 'eval_samples_per_second': 612.715, 'eval_steps_per_second': 39.046, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6429818868637085, 'eval_accuracy': 0.6764705882352942, 'eval_f1': 0.7981651376146789, 'eval_runtime': 0.6677, 'eval_samples_per_second': 611.093, 'eval_steps_per_second': 38.942, 'epoch': 2.0}\n",
            "{'loss': 0.6813, 'grad_norm': 0.8136300444602966, 'learning_rate': 2.282608695652174e-05, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.6336894035339355, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.806015037593985, 'eval_runtime': 0.6827, 'eval_samples_per_second': 597.618, 'eval_steps_per_second': 38.083, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:47:59] Energy consumed for RAM : 0.000069 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:47:59] Energy consumed for all GPUs : 0.000124 kWh. Total GPU Power : 34.39373109290323 W\n",
            "[codecarbon INFO @ 00:47:59] Energy consumed for all CPUs : 0.000153 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:47:59] 0.000347 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6315215826034546, 'eval_accuracy': 0.6813725490196079, 'eval_f1': 0.8048048048048048, 'eval_runtime': 0.6721, 'eval_samples_per_second': 607.043, 'eval_steps_per_second': 38.684, 'epoch': 4.0}\n",
            "{'train_runtime': 12.611, 'train_samples_per_second': 1163.427, 'train_steps_per_second': 72.952, 'train_loss': 0.6606088721233866, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:48:00] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:48:00] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:48:00] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:48:00] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:48:00] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6315215826034546, 'eval_accuracy': 0.6813725490196079, 'eval_f1': 0.8048048048048048, 'eval_runtime': 0.6716, 'eval_samples_per_second': 607.541, 'eval_steps_per_second': 38.716, 'epoch': 4.0}\n",
            "Progress: 48/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:48:01] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:48:01] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:48:01] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:48:01]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:48:01]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:48:01]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:48:01]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:48:01]   CPU count: 8\n",
            "[codecarbon INFO @ 00:48:01]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:48:01]   GPU count: 1\n",
            "[codecarbon INFO @ 00:48:01]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7071996331214905, 'eval_accuracy': 0.3872549019607843, 'eval_f1': 0.3016759776536313, 'eval_runtime': 0.6669, 'eval_samples_per_second': 611.782, 'eval_steps_per_second': 38.986, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6741295456886292, 'eval_accuracy': 0.6200980392156863, 'eval_f1': 0.7266313932980599, 'eval_runtime': 0.7037, 'eval_samples_per_second': 579.827, 'eval_steps_per_second': 36.95, 'epoch': 2.0}\n",
            "{'loss': 0.7047, 'grad_norm': 0.9193987846374512, 'learning_rate': 1.3695652173913042e-05, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.6598029136657715, 'eval_accuracy': 0.6666666666666666, 'eval_f1': 0.7792207792207793, 'eval_runtime': 0.6814, 'eval_samples_per_second': 598.789, 'eval_steps_per_second': 38.158, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:48:14] Energy consumed for RAM : 0.000070 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:48:14] Energy consumed for all GPUs : 0.000125 kWh. Total GPU Power : 34.187471312447485 W\n",
            "[codecarbon INFO @ 00:48:14] Energy consumed for all CPUs : 0.000155 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:48:14] 0.000350 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6556361317634583, 'eval_accuracy': 0.6666666666666666, 'eval_f1': 0.7834394904458599, 'eval_runtime': 0.6884, 'eval_samples_per_second': 592.676, 'eval_steps_per_second': 37.769, 'epoch': 4.0}\n",
            "{'train_runtime': 12.7686, 'train_samples_per_second': 1149.071, 'train_steps_per_second': 72.052, 'train_loss': 0.6849991508152173, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:48:15] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:48:15] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:48:15] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:48:15] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:48:15] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6556361317634583, 'eval_accuracy': 0.6666666666666666, 'eval_f1': 0.7834394904458599, 'eval_runtime': 0.6826, 'eval_samples_per_second': 597.681, 'eval_steps_per_second': 38.087, 'epoch': 4.0}\n",
            "Progress: 49/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:48:16] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:48:16] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:48:16] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:48:16]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:48:16]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:48:16]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:48:16]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:48:16]   CPU count: 8\n",
            "[codecarbon INFO @ 00:48:16]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:48:16]   GPU count: 1\n",
            "[codecarbon INFO @ 00:48:16]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6239275336265564, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8100147275405007, 'eval_runtime': 0.6389, 'eval_samples_per_second': 638.637, 'eval_steps_per_second': 20.349, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6179218292236328, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8083209509658247, 'eval_runtime': 0.6356, 'eval_samples_per_second': 641.943, 'eval_steps_per_second': 20.454, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6173927187919617, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8083209509658247, 'eval_runtime': 0.6326, 'eval_samples_per_second': 644.92, 'eval_steps_per_second': 20.549, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:48:26] Energy consumed for RAM : 0.000050 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:48:26] Energy consumed for all GPUs : 0.000094 kWh. Total GPU Power : 35.49121818207034 W\n",
            "[codecarbon INFO @ 00:48:26] Energy consumed for all CPUs : 0.000112 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:48:26] 0.000256 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.616874635219574, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8095238095238095, 'eval_runtime': 0.8037, 'eval_samples_per_second': 507.648, 'eval_steps_per_second': 16.175, 'epoch': 4.0}\n",
            "{'train_runtime': 9.1061, 'train_samples_per_second': 1611.236, 'train_steps_per_second': 50.516, 'train_loss': 0.62912365457286, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:48:26] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:48:26] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:48:26] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:48:26] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:48:26] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.616874635219574, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8095238095238095, 'eval_runtime': 0.627, 'eval_samples_per_second': 650.688, 'eval_steps_per_second': 20.733, 'epoch': 4.0}\n",
            "Progress: 50/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:48:28] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:48:28] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:48:28] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:48:28]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:48:28]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:48:28]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:48:28]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:48:28]   CPU count: 8\n",
            "[codecarbon INFO @ 00:48:28]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:48:28]   GPU count: 1\n",
            "[codecarbon INFO @ 00:48:28]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6638776063919067, 'eval_accuracy': 0.6617647058823529, 'eval_f1': 0.7730263157894737, 'eval_runtime': 0.6429, 'eval_samples_per_second': 634.634, 'eval_steps_per_second': 20.221, 'epoch': 1.0}\n",
            "{'eval_loss': 0.632932186126709, 'eval_accuracy': 0.6813725490196079, 'eval_f1': 0.8048048048048048, 'eval_runtime': 0.6285, 'eval_samples_per_second': 649.187, 'eval_steps_per_second': 20.685, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6279576420783997, 'eval_accuracy': 0.678921568627451, 'eval_f1': 0.8053491827637445, 'eval_runtime': 0.6273, 'eval_samples_per_second': 650.392, 'eval_steps_per_second': 20.723, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:48:37] Energy consumed for RAM : 0.000050 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:48:37] Energy consumed for all GPUs : 0.000093 kWh. Total GPU Power : 35.617418797550506 W\n",
            "[codecarbon INFO @ 00:48:37] Energy consumed for all CPUs : 0.000111 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:48:37] 0.000253 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.626919150352478, 'eval_accuracy': 0.6813725490196079, 'eval_f1': 0.8071216617210683, 'eval_runtime': 0.712, 'eval_samples_per_second': 573.027, 'eval_steps_per_second': 18.258, 'epoch': 4.0}\n",
            "{'train_runtime': 8.9998, 'train_samples_per_second': 1630.251, 'train_steps_per_second': 51.112, 'train_loss': 0.6539457901664402, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:48:38] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:48:38] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:48:38] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:48:38] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:48:38] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.626919150352478, 'eval_accuracy': 0.6813725490196079, 'eval_f1': 0.8071216617210683, 'eval_runtime': 0.6367, 'eval_samples_per_second': 640.776, 'eval_steps_per_second': 20.417, 'epoch': 4.0}\n",
            "Progress: 51/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:48:39] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:48:39] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:48:39] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:48:39]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:48:39]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:48:39]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:48:39]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:48:39]   CPU count: 8\n",
            "[codecarbon INFO @ 00:48:39]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:48:39]   GPU count: 1\n",
            "[codecarbon INFO @ 00:48:39]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7091423273086548, 'eval_accuracy': 0.3872549019607843, 'eval_f1': 0.2774566473988439, 'eval_runtime': 0.6366, 'eval_samples_per_second': 640.869, 'eval_steps_per_second': 20.42, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6751417517662048, 'eval_accuracy': 0.6176470588235294, 'eval_f1': 0.7214285714285714, 'eval_runtime': 0.6299, 'eval_samples_per_second': 647.736, 'eval_steps_per_second': 20.639, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6593069434165955, 'eval_accuracy': 0.6593137254901961, 'eval_f1': 0.7739837398373983, 'eval_runtime': 0.6198, 'eval_samples_per_second': 658.248, 'eval_steps_per_second': 20.974, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:48:48] Energy consumed for RAM : 0.000049 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:48:48] Energy consumed for all GPUs : 0.000093 kWh. Total GPU Power : 36.00965644073915 W\n",
            "[codecarbon INFO @ 00:48:48] Energy consumed for all CPUs : 0.000109 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:48:48] 0.000251 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6549235582351685, 'eval_accuracy': 0.6666666666666666, 'eval_f1': 0.7848101265822784, 'eval_runtime': 0.6468, 'eval_samples_per_second': 630.841, 'eval_steps_per_second': 20.1, 'epoch': 4.0}\n",
            "{'train_runtime': 8.8956, 'train_samples_per_second': 1649.355, 'train_steps_per_second': 51.711, 'train_loss': 0.6867035575534987, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:48:49] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:48:49] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:48:49] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:48:49] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:48:49] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6549235582351685, 'eval_accuracy': 0.6666666666666666, 'eval_f1': 0.7848101265822784, 'eval_runtime': 0.6254, 'eval_samples_per_second': 652.361, 'eval_steps_per_second': 20.786, 'epoch': 4.0}\n",
            "Progress: 52/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:48:50] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:48:50] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:48:50] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:48:50]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:48:50]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:48:50]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:48:50]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:48:50]   CPU count: 8\n",
            "[codecarbon INFO @ 00:48:50]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:48:50]   GPU count: 1\n",
            "[codecarbon INFO @ 00:48:50]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.728518545627594, 'eval_accuracy': 0.31862745098039214, 'eval_f1': 0.014184397163120567, 'eval_runtime': 0.6403, 'eval_samples_per_second': 637.239, 'eval_steps_per_second': 20.304, 'epoch': 1.0}\n",
            "{'eval_loss': 0.7078663110733032, 'eval_accuracy': 0.39705882352941174, 'eval_f1': 0.3050847457627119, 'eval_runtime': 0.64, 'eval_samples_per_second': 637.53, 'eval_steps_per_second': 20.313, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6949083209037781, 'eval_accuracy': 0.5171568627450981, 'eval_f1': 0.567032967032967, 'eval_runtime': 0.633, 'eval_samples_per_second': 644.517, 'eval_steps_per_second': 20.536, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:49:00] Energy consumed for RAM : 0.000049 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:49:00] Energy consumed for all GPUs : 0.000092 kWh. Total GPU Power : 35.63298443491875 W\n",
            "[codecarbon INFO @ 00:49:00] Energy consumed for all CPUs : 0.000110 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:49:00] 0.000251 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6907250881195068, 'eval_accuracy': 0.5269607843137255, 'eval_f1': 0.5970772442588727, 'eval_runtime': 0.6326, 'eval_samples_per_second': 644.968, 'eval_steps_per_second': 20.55, 'epoch': 4.0}\n",
            "{'train_runtime': 8.889, 'train_samples_per_second': 1650.578, 'train_steps_per_second': 51.749, 'train_loss': 0.7114541095236073, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:49:00] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:49:00] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:49:00] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:49:00] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:49:00] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6907250881195068, 'eval_accuracy': 0.5269607843137255, 'eval_f1': 0.5970772442588727, 'eval_runtime': 0.6738, 'eval_samples_per_second': 605.492, 'eval_steps_per_second': 19.293, 'epoch': 4.0}\n",
            "Progress: 53/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:49:01] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:49:01] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:49:01] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:49:01]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:49:01]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:49:01]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:49:01]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:49:01]   CPU count: 8\n",
            "[codecarbon INFO @ 00:49:01]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:49:01]   GPU count: 1\n",
            "[codecarbon INFO @ 00:49:01]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.63508141040802, 'eval_accuracy': 0.678921568627451, 'eval_f1': 0.8030075187969925, 'eval_runtime': 0.6077, 'eval_samples_per_second': 671.409, 'eval_steps_per_second': 11.519, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6230634450912476, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8117647058823529, 'eval_runtime': 0.6279, 'eval_samples_per_second': 649.763, 'eval_steps_per_second': 11.148, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6212981939315796, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.812960235640648, 'eval_runtime': 0.6113, 'eval_samples_per_second': 667.42, 'eval_steps_per_second': 11.451, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:49:09] Energy consumed for RAM : 0.000039 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:49:09] Energy consumed for all GPUs : 0.000080 kWh. Total GPU Power : 39.06159397218882 W\n",
            "[codecarbon INFO @ 00:49:09] Energy consumed for all CPUs : 0.000087 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:49:09] 0.000207 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6209790706634521, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8124076809453471, 'eval_runtime': 0.6269, 'eval_samples_per_second': 650.84, 'eval_steps_per_second': 11.166, 'epoch': 4.0}\n",
            "{'train_runtime': 7.0064, 'train_samples_per_second': 2094.094, 'train_steps_per_second': 33.113, 'train_loss': 0.6399523636390423, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:49:10] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:49:10] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:49:10] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:49:10] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:49:10] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6209790706634521, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8124076809453471, 'eval_runtime': 0.642, 'eval_samples_per_second': 635.477, 'eval_steps_per_second': 10.903, 'epoch': 4.0}\n",
            "Progress: 54/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:49:11] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:49:11] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:49:11] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:49:11]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:49:11]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:49:11]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:49:11]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:49:11]   CPU count: 8\n",
            "[codecarbon INFO @ 00:49:11]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:49:11]   GPU count: 1\n",
            "[codecarbon INFO @ 00:49:11]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7055407762527466, 'eval_accuracy': 0.3946078431372549, 'eval_f1': 0.32697547683923706, 'eval_runtime': 0.6268, 'eval_samples_per_second': 650.875, 'eval_steps_per_second': 11.167, 'epoch': 1.0}\n",
            "{'eval_loss': 0.667824387550354, 'eval_accuracy': 0.6495098039215687, 'eval_f1': 0.7596638655462185, 'eval_runtime': 0.6035, 'eval_samples_per_second': 676.056, 'eval_steps_per_second': 11.599, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6515154242515564, 'eval_accuracy': 0.678921568627451, 'eval_f1': 0.7968992248062016, 'eval_runtime': 0.6082, 'eval_samples_per_second': 670.793, 'eval_steps_per_second': 11.509, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:49:18] Energy consumed for RAM : 0.000039 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:49:18] Energy consumed for all GPUs : 0.000079 kWh. Total GPU Power : 38.420510181642335 W\n",
            "[codecarbon INFO @ 00:49:18] Energy consumed for all CPUs : 0.000088 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:49:18] 0.000207 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6472551226615906, 'eval_accuracy': 0.6691176470588235, 'eval_f1': 0.7919876733436055, 'eval_runtime': 0.6089, 'eval_samples_per_second': 670.086, 'eval_steps_per_second': 11.497, 'epoch': 4.0}\n",
            "{'train_runtime': 7.0196, 'train_samples_per_second': 2090.159, 'train_steps_per_second': 33.051, 'train_loss': 0.6809917318409887, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:49:19] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:49:19] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:49:19] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:49:19] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:49:19] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6472551226615906, 'eval_accuracy': 0.6691176470588235, 'eval_f1': 0.7919876733436055, 'eval_runtime': 0.5925, 'eval_samples_per_second': 688.636, 'eval_steps_per_second': 11.815, 'epoch': 4.0}\n",
            "Progress: 55/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:49:20] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:49:20] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:49:20] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:49:20]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:49:20]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:49:20]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:49:20]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:49:20]   CPU count: 8\n",
            "[codecarbon INFO @ 00:49:20]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:49:20]   GPU count: 1\n",
            "[codecarbon INFO @ 00:49:20]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7314233779907227, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0071174377224199285, 'eval_runtime': 0.6395, 'eval_samples_per_second': 637.964, 'eval_steps_per_second': 10.945, 'epoch': 1.0}\n",
            "{'eval_loss': 0.7119145393371582, 'eval_accuracy': 0.3700980392156863, 'eval_f1': 0.2188449848024316, 'eval_runtime': 0.6154, 'eval_samples_per_second': 663.014, 'eval_steps_per_second': 11.375, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6999610662460327, 'eval_accuracy': 0.45098039215686275, 'eval_f1': 0.4563106796116505, 'eval_runtime': 0.6017, 'eval_samples_per_second': 678.119, 'eval_steps_per_second': 11.634, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:49:28] Energy consumed for RAM : 0.000042 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:49:28] Energy consumed for all GPUs : 0.000082 kWh. Total GPU Power : 37.50112075951135 W\n",
            "[codecarbon INFO @ 00:49:28] Energy consumed for all CPUs : 0.000092 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:49:28] 0.000216 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6958010196685791, 'eval_accuracy': 0.5024509803921569, 'eval_f1': 0.5417607223476298, 'eval_runtime': 0.6146, 'eval_samples_per_second': 663.86, 'eval_steps_per_second': 11.39, 'epoch': 4.0}\n",
            "{'train_runtime': 7.428, 'train_samples_per_second': 1975.237, 'train_steps_per_second': 31.233, 'train_loss': 0.7149119541562837, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:49:29] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:49:29] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:49:29] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:49:29] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:49:29] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6958010196685791, 'eval_accuracy': 0.5024509803921569, 'eval_f1': 0.5417607223476298, 'eval_runtime': 0.6203, 'eval_samples_per_second': 657.775, 'eval_steps_per_second': 11.285, 'epoch': 4.0}\n",
            "Progress: 56/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:49:30] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:49:30] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:49:30] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:49:30]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:49:30]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:49:30]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:49:30]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:49:30]   CPU count: 8\n",
            "[codecarbon INFO @ 00:49:30]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:49:30]   GPU count: 1\n",
            "[codecarbon INFO @ 00:49:30]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7410643100738525, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6155, 'eval_samples_per_second': 662.908, 'eval_steps_per_second': 11.373, 'epoch': 1.0}\n",
            "{'eval_loss': 0.7301908731460571, 'eval_accuracy': 0.31862745098039214, 'eval_f1': 0.014184397163120567, 'eval_runtime': 0.6081, 'eval_samples_per_second': 670.94, 'eval_steps_per_second': 11.511, 'epoch': 2.0}\n",
            "{'eval_loss': 0.7235295176506042, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.021052631578947368, 'eval_runtime': 0.639, 'eval_samples_per_second': 638.526, 'eval_steps_per_second': 10.955, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:49:38] Energy consumed for RAM : 0.000041 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:49:38] Energy consumed for all GPUs : 0.000082 kWh. Total GPU Power : 38.50851135469349 W\n",
            "[codecarbon INFO @ 00:49:38] Energy consumed for all CPUs : 0.000091 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:49:38] 0.000213 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7211607098579407, 'eval_accuracy': 0.32107843137254904, 'eval_f1': 0.048109965635738834, 'eval_runtime': 0.6161, 'eval_samples_per_second': 662.279, 'eval_steps_per_second': 11.363, 'epoch': 4.0}\n",
            "{'train_runtime': 7.2517, 'train_samples_per_second': 2023.256, 'train_steps_per_second': 31.993, 'train_loss': 0.7309564393142174, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:49:38] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:49:38] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:49:38] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:49:38] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:49:38] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7211607098579407, 'eval_accuracy': 0.32107843137254904, 'eval_f1': 0.048109965635738834, 'eval_runtime': 0.5965, 'eval_samples_per_second': 683.959, 'eval_steps_per_second': 11.735, 'epoch': 4.0}\n",
            "Progress: 57/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:49:39] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:49:39] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:49:39] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:49:39]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:49:39]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:49:39]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:49:39]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:49:39]   CPU count: 8\n",
            "[codecarbon INFO @ 00:49:39]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:49:39]   GPU count: 1\n",
            "[codecarbon INFO @ 00:49:39]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6770764589309692, 'eval_accuracy': 0.6151960784313726, 'eval_f1': 0.7160940325497287, 'eval_runtime': 0.592, 'eval_samples_per_second': 689.219, 'eval_steps_per_second': 6.757, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6389957666397095, 'eval_accuracy': 0.6813725490196079, 'eval_f1': 0.803030303030303, 'eval_runtime': 0.6098, 'eval_samples_per_second': 669.028, 'eval_steps_per_second': 6.559, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6299777030944824, 'eval_accuracy': 0.6764705882352942, 'eval_f1': 0.8041543026706232, 'eval_runtime': 0.6445, 'eval_samples_per_second': 633.058, 'eval_steps_per_second': 6.206, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:49:46] Energy consumed for RAM : 0.000036 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:49:46] Energy consumed for all GPUs : 0.000087 kWh. Total GPU Power : 46.222271866623124 W\n",
            "[codecarbon INFO @ 00:49:46] Energy consumed for all CPUs : 0.000080 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:49:46] 0.000202 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6287346482276917, 'eval_accuracy': 0.678921568627451, 'eval_f1': 0.8059259259259259, 'eval_runtime': 0.6101, 'eval_samples_per_second': 668.796, 'eval_steps_per_second': 6.557, 'epoch': 4.0}\n",
            "{'train_runtime': 6.3693, 'train_samples_per_second': 2303.566, 'train_steps_per_second': 18.212, 'train_loss': 0.6597818177321861, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:49:47] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:49:47] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:49:47] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:49:47] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:49:47] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6287346482276917, 'eval_accuracy': 0.678921568627451, 'eval_f1': 0.8059259259259259, 'eval_runtime': 0.614, 'eval_samples_per_second': 664.443, 'eval_steps_per_second': 6.514, 'epoch': 4.0}\n",
            "Progress: 58/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:49:48] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:49:48] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:49:48] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:49:48]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:49:48]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:49:48]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:49:48]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:49:48]   CPU count: 8\n",
            "[codecarbon INFO @ 00:49:48]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:49:48]   GPU count: 1\n",
            "[codecarbon INFO @ 00:49:48]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.730250358581543, 'eval_accuracy': 0.31862745098039214, 'eval_f1': 0.014184397163120567, 'eval_runtime': 0.6006, 'eval_samples_per_second': 679.36, 'eval_steps_per_second': 6.66, 'epoch': 1.0}\n",
            "{'eval_loss': 0.7101346254348755, 'eval_accuracy': 0.38235294117647056, 'eval_f1': 0.25, 'eval_runtime': 0.61, 'eval_samples_per_second': 668.854, 'eval_steps_per_second': 6.557, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6969529986381531, 'eval_accuracy': 0.47794117647058826, 'eval_f1': 0.5080831408775982, 'eval_runtime': 0.5897, 'eval_samples_per_second': 691.899, 'eval_steps_per_second': 6.783, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:49:55] Energy consumed for RAM : 0.000036 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:49:55] Energy consumed for all GPUs : 0.000084 kWh. Total GPU Power : 45.14421522673298 W\n",
            "[codecarbon INFO @ 00:49:55] Energy consumed for all CPUs : 0.000079 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:49:55] 0.000199 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.692425012588501, 'eval_accuracy': 0.5245098039215687, 'eval_f1': 0.5907172995780591, 'eval_runtime': 0.5872, 'eval_samples_per_second': 694.832, 'eval_steps_per_second': 6.812, 'epoch': 4.0}\n",
            "{'train_runtime': 6.2989, 'train_samples_per_second': 2329.29, 'train_steps_per_second': 18.416, 'train_loss': 0.7133568073141163, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:49:56] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:49:56] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:49:56] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:49:56] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:49:56] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.692425012588501, 'eval_accuracy': 0.5245098039215687, 'eval_f1': 0.5907172995780591, 'eval_runtime': 0.6079, 'eval_samples_per_second': 671.13, 'eval_steps_per_second': 6.58, 'epoch': 4.0}\n",
            "Progress: 59/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:49:57] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:49:57] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:49:57] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:49:57]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:49:57]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:49:57]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:49:57]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:49:57]   CPU count: 8\n",
            "[codecarbon INFO @ 00:49:57]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:49:57]   GPU count: 1\n",
            "[codecarbon INFO @ 00:49:57]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7427722811698914, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.5958, 'eval_samples_per_second': 684.782, 'eval_steps_per_second': 6.714, 'epoch': 1.0}\n",
            "{'eval_loss': 0.7336492538452148, 'eval_accuracy': 0.31862745098039214, 'eval_f1': 0.007142857142857143, 'eval_runtime': 0.6005, 'eval_samples_per_second': 679.426, 'eval_steps_per_second': 6.661, 'epoch': 2.0}\n",
            "{'eval_loss': 0.7278839349746704, 'eval_accuracy': 0.31862745098039214, 'eval_f1': 0.014184397163120567, 'eval_runtime': 0.5964, 'eval_samples_per_second': 684.145, 'eval_steps_per_second': 6.707, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:50:04] Energy consumed for RAM : 0.000036 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:50:04] Energy consumed for all GPUs : 0.000082 kWh. Total GPU Power : 43.57602072021971 W\n",
            "[codecarbon INFO @ 00:50:04] Energy consumed for all CPUs : 0.000080 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:50:04] 0.000199 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7257861495018005, 'eval_accuracy': 0.31862745098039214, 'eval_f1': 0.02112676056338028, 'eval_runtime': 0.6048, 'eval_samples_per_second': 674.563, 'eval_steps_per_second': 6.613, 'epoch': 4.0}\n",
            "{'train_runtime': 6.4164, 'train_samples_per_second': 2286.658, 'train_steps_per_second': 18.079, 'train_loss': 0.734076006659146, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:50:04] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:50:04] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:50:04] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:50:04] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:50:04] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7257861495018005, 'eval_accuracy': 0.31862745098039214, 'eval_f1': 0.02112676056338028, 'eval_runtime': 0.6082, 'eval_samples_per_second': 670.793, 'eval_steps_per_second': 6.576, 'epoch': 4.0}\n",
            "Progress: 60/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:50:05] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:50:05] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:50:05] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:50:05]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:50:05]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:50:05]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:50:05]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:50:05]   CPU count: 8\n",
            "[codecarbon INFO @ 00:50:05]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:50:05]   GPU count: 1\n",
            "[codecarbon INFO @ 00:50:05]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7476850152015686, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.5952, 'eval_samples_per_second': 685.439, 'eval_steps_per_second': 6.72, 'epoch': 1.0}\n",
            "{'eval_loss': 0.7423667311668396, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6008, 'eval_samples_per_second': 679.069, 'eval_steps_per_second': 6.658, 'epoch': 2.0}\n",
            "{'eval_loss': 0.7391296625137329, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.599, 'eval_samples_per_second': 681.096, 'eval_steps_per_second': 6.677, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:50:12] Energy consumed for RAM : 0.000036 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:50:12] Energy consumed for all GPUs : 0.000084 kWh. Total GPU Power : 45.12239660650929 W\n",
            "[codecarbon INFO @ 00:50:12] Energy consumed for all CPUs : 0.000079 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:50:12] 0.000198 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7379646897315979, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.5977, 'eval_samples_per_second': 682.565, 'eval_steps_per_second': 6.692, 'epoch': 4.0}\n",
            "{'train_runtime': 6.2968, 'train_samples_per_second': 2330.086, 'train_steps_per_second': 18.422, 'train_loss': 0.742138961265827, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:50:13] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:50:13] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:50:13] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:50:13] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:50:13] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7379646897315979, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.0, 'eval_runtime': 0.6015, 'eval_samples_per_second': 678.322, 'eval_steps_per_second': 6.65, 'epoch': 4.0}\n",
            "Progress: 61/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:50:14] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:50:14] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:50:14] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:50:14]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:50:14]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:50:14]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:50:14]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:50:14]   CPU count: 8\n",
            "[codecarbon INFO @ 00:50:14]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:50:14]   GPU count: 1\n",
            "[codecarbon INFO @ 00:50:14]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6182043552398682, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8137108792846498, 'eval_runtime': 0.7694, 'eval_samples_per_second': 530.318, 'eval_steps_per_second': 66.29, 'epoch': 1.0}\n",
            "{'loss': 0.628, 'grad_norm': 2.2053592205047607, 'learning_rate': 0.00021830065359477123, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.6170656681060791, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8142644873699851, 'eval_runtime': 0.7857, 'eval_samples_per_second': 519.289, 'eval_steps_per_second': 64.911, 'epoch': 2.0}\n",
            "{'loss': 0.6151, 'grad_norm': 1.6207077503204346, 'learning_rate': 0.00013660130718954247, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:50:29] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:50:29] Energy consumed for all GPUs : 0.000141 kWh. Total GPU Power : 33.73361091704586 W\n",
            "[codecarbon INFO @ 00:50:29] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:50:29] 0.000398 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6087647676467896, 'eval_accuracy': 0.6985294117647058, 'eval_f1': 0.8161434977578476, 'eval_runtime': 0.7781, 'eval_samples_per_second': 524.344, 'eval_steps_per_second': 65.543, 'epoch': 3.0}\n",
            "{'loss': 0.6069, 'grad_norm': 2.1913321018218994, 'learning_rate': 5.4901960784313716e-05, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:50:35] Energy consumed for RAM : 0.000112 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:50:35] Energy consumed for all GPUs : 0.000196 kWh. Total GPU Power : 33.167288815093855 W\n",
            "[codecarbon INFO @ 00:50:35] Energy consumed for all CPUs : 0.000249 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:50:35] 0.000557 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6106576919555664, 'eval_accuracy': 0.7009803921568627, 'eval_f1': 0.817910447761194, 'eval_runtime': 0.7674, 'eval_samples_per_second': 531.644, 'eval_steps_per_second': 66.456, 'epoch': 4.0}\n",
            "{'train_runtime': 20.6788, 'train_samples_per_second': 709.52, 'train_steps_per_second': 88.787, 'train_loss': 0.6170322692472171, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:50:36] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:50:36] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:50:36] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:50:36] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:50:36] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6106576919555664, 'eval_accuracy': 0.7009803921568627, 'eval_f1': 0.817910447761194, 'eval_runtime': 0.7595, 'eval_samples_per_second': 537.171, 'eval_steps_per_second': 67.146, 'epoch': 4.0}\n",
            "Progress: 62/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:50:37] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:50:37] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:50:37] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:50:37]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:50:37]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:50:37]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:50:37]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:50:37]   CPU count: 8\n",
            "[codecarbon INFO @ 00:50:37]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:50:37]   GPU count: 1\n",
            "[codecarbon INFO @ 00:50:37]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6228213310241699, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8100147275405007, 'eval_runtime': 0.7657, 'eval_samples_per_second': 532.831, 'eval_steps_per_second': 66.604, 'epoch': 1.0}\n",
            "{'loss': 0.6405, 'grad_norm': 3.7907638549804688, 'learning_rate': 7.276688453159042e-05, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.6217585802078247, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8100890207715133, 'eval_runtime': 0.9272, 'eval_samples_per_second': 440.024, 'eval_steps_per_second': 55.003, 'epoch': 2.0}\n",
            "{'loss': 0.6198, 'grad_norm': 1.9368984699249268, 'learning_rate': 4.5533769063180834e-05, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:50:52] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:50:52] Energy consumed for all GPUs : 0.000139 kWh. Total GPU Power : 33.26562812691236 W\n",
            "[codecarbon INFO @ 00:50:52] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:50:52] 0.000396 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6203659176826477, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8112927191679049, 'eval_runtime': 0.7867, 'eval_samples_per_second': 518.63, 'eval_steps_per_second': 64.829, 'epoch': 3.0}\n",
            "{'loss': 0.6113, 'grad_norm': 3.403404474258423, 'learning_rate': 1.8300653594771242e-05, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:50:59] Energy consumed for RAM : 0.000114 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:50:59] Energy consumed for all GPUs : 0.000198 kWh. Total GPU Power : 32.92696806127652 W\n",
            "[codecarbon INFO @ 00:50:59] Energy consumed for all CPUs : 0.000254 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:50:59] 0.000566 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6207820773124695, 'eval_accuracy': 0.6911764705882353, 'eval_f1': 0.8130563798219584, 'eval_runtime': 0.8179, 'eval_samples_per_second': 498.824, 'eval_steps_per_second': 62.353, 'epoch': 4.0}\n",
            "{'train_runtime': 21.0852, 'train_samples_per_second': 695.844, 'train_steps_per_second': 87.075, 'train_loss': 0.6237521784497762, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:51:00] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:51:00] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:51:00] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:51:00] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:51:00] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6207820773124695, 'eval_accuracy': 0.6911764705882353, 'eval_f1': 0.8130563798219584, 'eval_runtime': 0.792, 'eval_samples_per_second': 515.152, 'eval_steps_per_second': 64.394, 'epoch': 4.0}\n",
            "Progress: 63/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:51:01] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:51:01] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:51:01] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:51:01]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:51:01]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:51:01]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:51:01]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:51:01]   CPU count: 8\n",
            "[codecarbon INFO @ 00:51:01]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:51:01]   GPU count: 1\n",
            "[codecarbon INFO @ 00:51:01]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6279866695404053, 'eval_accuracy': 0.6813725490196079, 'eval_f1': 0.8065476190476191, 'eval_runtime': 0.7529, 'eval_samples_per_second': 541.871, 'eval_steps_per_second': 67.734, 'epoch': 1.0}\n",
            "{'loss': 0.6596, 'grad_norm': 2.7273144721984863, 'learning_rate': 3.638344226579521e-05, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.6230160593986511, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8112094395280236, 'eval_runtime': 0.7625, 'eval_samples_per_second': 535.104, 'eval_steps_per_second': 66.888, 'epoch': 2.0}\n",
            "{'loss': 0.6252, 'grad_norm': 2.179733991622925, 'learning_rate': 2.2766884531590417e-05, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:51:16] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:51:16] Energy consumed for all GPUs : 0.000139 kWh. Total GPU Power : 33.361091961675235 W\n",
            "[codecarbon INFO @ 00:51:16] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:51:16] 0.000396 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6214218735694885, 'eval_accuracy': 0.6813725490196079, 'eval_f1': 0.8076923076923077, 'eval_runtime': 0.8017, 'eval_samples_per_second': 508.923, 'eval_steps_per_second': 63.615, 'epoch': 3.0}\n",
            "{'loss': 0.6169, 'grad_norm': 3.2059597969055176, 'learning_rate': 9.150326797385621e-06, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:51:22] Energy consumed for RAM : 0.000113 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:51:22] Energy consumed for all GPUs : 0.000196 kWh. Total GPU Power : 32.91187544976504 W\n",
            "[codecarbon INFO @ 00:51:22] Energy consumed for all CPUs : 0.000251 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:51:22] 0.000560 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6208617091178894, 'eval_accuracy': 0.6813725490196079, 'eval_f1': 0.8076923076923077, 'eval_runtime': 0.7758, 'eval_samples_per_second': 525.928, 'eval_steps_per_second': 65.741, 'epoch': 4.0}\n",
            "{'train_runtime': 20.8623, 'train_samples_per_second': 703.278, 'train_steps_per_second': 88.006, 'train_loss': 0.6325367530706402, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:51:23] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:51:23] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:51:23] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:51:23] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:51:23] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6208617091178894, 'eval_accuracy': 0.6813725490196079, 'eval_f1': 0.8076923076923077, 'eval_runtime': 0.7662, 'eval_samples_per_second': 532.515, 'eval_steps_per_second': 66.564, 'epoch': 4.0}\n",
            "Progress: 64/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:51:24] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:51:24] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:51:24] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:51:24]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:51:24]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:51:24]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:51:24]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:51:24]   CPU count: 8\n",
            "[codecarbon INFO @ 00:51:24]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:51:24]   GPU count: 1\n",
            "[codecarbon INFO @ 00:51:24]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6419795751571655, 'eval_accuracy': 0.6715686274509803, 'eval_f1': 0.7944785276073619, 'eval_runtime': 0.7684, 'eval_samples_per_second': 530.979, 'eval_steps_per_second': 66.372, 'epoch': 1.0}\n",
            "{'loss': 0.6811, 'grad_norm': 2.7547547817230225, 'learning_rate': 2.1830065359477124e-05, 'epoch': 1.0893246187363834}\n",
            "{'eval_loss': 0.6268711686134338, 'eval_accuracy': 0.678921568627451, 'eval_f1': 0.8047690014903129, 'eval_runtime': 0.8068, 'eval_samples_per_second': 505.671, 'eval_steps_per_second': 63.209, 'epoch': 2.0}\n",
            "{'loss': 0.6326, 'grad_norm': 2.427765130996704, 'learning_rate': 1.366013071895425e-05, 'epoch': 2.178649237472767}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:51:39] Energy consumed for RAM : 0.000080 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:51:39] Energy consumed for all GPUs : 0.000138 kWh. Total GPU Power : 33.04212439205099 W\n",
            "[codecarbon INFO @ 00:51:39] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:51:39] 0.000395 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6250705122947693, 'eval_accuracy': 0.6813725490196079, 'eval_f1': 0.8071216617210683, 'eval_runtime': 0.8283, 'eval_samples_per_second': 492.564, 'eval_steps_per_second': 61.57, 'epoch': 3.0}\n",
            "{'loss': 0.6224, 'grad_norm': 3.3797361850738525, 'learning_rate': 5.490196078431373e-06, 'epoch': 3.2679738562091503}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:51:46] Energy consumed for RAM : 0.000113 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:51:46] Energy consumed for all GPUs : 0.000195 kWh. Total GPU Power : 32.991968771681705 W\n",
            "[codecarbon INFO @ 00:51:46] Energy consumed for all CPUs : 0.000251 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:51:46] 0.000558 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6244771480560303, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8088888888888889, 'eval_runtime': 0.7693, 'eval_samples_per_second': 530.332, 'eval_steps_per_second': 66.291, 'epoch': 4.0}\n",
            "{'train_runtime': 20.8641, 'train_samples_per_second': 703.216, 'train_steps_per_second': 87.998, 'train_loss': 0.6426295195269949, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:51:46] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:51:46] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:51:46] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:51:46] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:51:46] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6244771480560303, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8088888888888889, 'eval_runtime': 0.7649, 'eval_samples_per_second': 533.402, 'eval_steps_per_second': 66.675, 'epoch': 4.0}\n",
            "Progress: 65/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:51:48] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:51:48] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:51:48] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:51:48]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:51:48]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:51:48]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:51:48]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:51:48]   CPU count: 8\n",
            "[codecarbon INFO @ 00:51:48]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:51:48]   GPU count: 1\n",
            "[codecarbon INFO @ 00:51:48]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6205220818519592, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8071748878923767, 'eval_runtime': 0.6792, 'eval_samples_per_second': 600.694, 'eval_steps_per_second': 38.28, 'epoch': 1.0}\n",
            "{'eval_loss': 0.616158127784729, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8083209509658247, 'eval_runtime': 0.8401, 'eval_samples_per_second': 485.658, 'eval_steps_per_second': 30.949, 'epoch': 2.0}\n",
            "{'loss': 0.6226, 'grad_norm': 1.530529260635376, 'learning_rate': 0.00013695652173913042, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.6115254163742065, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.808955223880597, 'eval_runtime': 0.6866, 'eval_samples_per_second': 594.207, 'eval_steps_per_second': 37.866, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:52:01] Energy consumed for RAM : 0.000069 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:52:01] Energy consumed for all GPUs : 0.000124 kWh. Total GPU Power : 34.1620794080338 W\n",
            "[codecarbon INFO @ 00:52:01] Energy consumed for all CPUs : 0.000154 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:52:01] 0.000348 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6119776964187622, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8138138138138138, 'eval_runtime': 0.6699, 'eval_samples_per_second': 609.068, 'eval_steps_per_second': 38.813, 'epoch': 4.0}\n",
            "{'train_runtime': 12.698, 'train_samples_per_second': 1155.46, 'train_steps_per_second': 72.452, 'train_loss': 0.618353039285411, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:52:01] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:52:01] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:52:01] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:52:01] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:52:01] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6119776964187622, 'eval_accuracy': 0.696078431372549, 'eval_f1': 0.8138138138138138, 'eval_runtime': 0.6733, 'eval_samples_per_second': 605.965, 'eval_steps_per_second': 38.615, 'epoch': 4.0}\n",
            "Progress: 66/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:52:03] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:52:03] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:52:03] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:52:03]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:52:03]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:52:03]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:52:03]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:52:03]   CPU count: 8\n",
            "[codecarbon INFO @ 00:52:03]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:52:03]   GPU count: 1\n",
            "[codecarbon INFO @ 00:52:03]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6253524422645569, 'eval_accuracy': 0.6813725490196079, 'eval_f1': 0.8082595870206489, 'eval_runtime': 0.6749, 'eval_samples_per_second': 604.508, 'eval_steps_per_second': 38.523, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6199919581413269, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8118518518518518, 'eval_runtime': 0.6531, 'eval_samples_per_second': 624.73, 'eval_steps_per_second': 39.811, 'epoch': 2.0}\n",
            "{'loss': 0.6374, 'grad_norm': 1.7236007452011108, 'learning_rate': 4.565217391304348e-05, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.6193457841873169, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8100890207715133, 'eval_runtime': 0.6726, 'eval_samples_per_second': 606.612, 'eval_steps_per_second': 38.657, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:52:16] Energy consumed for RAM : 0.000069 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:52:16] Energy consumed for all GPUs : 0.000123 kWh. Total GPU Power : 34.27439631961637 W\n",
            "[codecarbon INFO @ 00:52:16] Energy consumed for all CPUs : 0.000153 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:52:16] 0.000344 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6186457872390747, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8100890207715133, 'eval_runtime': 0.6872, 'eval_samples_per_second': 593.725, 'eval_steps_per_second': 37.835, 'epoch': 4.0}\n",
            "{'train_runtime': 12.5326, 'train_samples_per_second': 1170.705, 'train_steps_per_second': 73.408, 'train_loss': 0.6281957211701766, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:52:16] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:52:16] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:52:16] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:52:16] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:52:16] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6186457872390747, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8100890207715133, 'eval_runtime': 0.6778, 'eval_samples_per_second': 601.982, 'eval_steps_per_second': 38.362, 'epoch': 4.0}\n",
            "Progress: 67/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:52:18] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:52:18] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:52:18] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:52:18]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:52:18]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:52:18]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:52:18]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:52:18]   CPU count: 8\n",
            "[codecarbon INFO @ 00:52:18]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:52:18]   GPU count: 1\n",
            "[codecarbon INFO @ 00:52:18]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.639605700969696, 'eval_accuracy': 0.6813725490196079, 'eval_f1': 0.803030303030303, 'eval_runtime': 0.6582, 'eval_samples_per_second': 619.859, 'eval_steps_per_second': 39.501, 'epoch': 1.0}\n",
            "{'eval_loss': 0.626078188419342, 'eval_accuracy': 0.678921568627451, 'eval_f1': 0.8059259259259259, 'eval_runtime': 0.6878, 'eval_samples_per_second': 593.2, 'eval_steps_per_second': 37.802, 'epoch': 2.0}\n",
            "{'loss': 0.6557, 'grad_norm': 1.6036125421524048, 'learning_rate': 2.282608695652174e-05, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.6246790289878845, 'eval_accuracy': 0.6813725490196079, 'eval_f1': 0.8076923076923077, 'eval_runtime': 0.69, 'eval_samples_per_second': 591.333, 'eval_steps_per_second': 37.683, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:52:31] Energy consumed for RAM : 0.000069 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:52:31] Energy consumed for all GPUs : 0.000123 kWh. Total GPU Power : 34.10489433430555 W\n",
            "[codecarbon INFO @ 00:52:31] Energy consumed for all CPUs : 0.000153 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:52:31] 0.000345 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6240548491477966, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8088888888888889, 'eval_runtime': 0.6847, 'eval_samples_per_second': 595.888, 'eval_steps_per_second': 37.973, 'epoch': 4.0}\n",
            "{'train_runtime': 12.5864, 'train_samples_per_second': 1165.701, 'train_steps_per_second': 73.095, 'train_loss': 0.6412724038828974, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:52:32] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:52:32] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:52:32] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:52:32] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:52:32] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6240548491477966, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8088888888888889, 'eval_runtime': 0.6759, 'eval_samples_per_second': 603.631, 'eval_steps_per_second': 38.467, 'epoch': 4.0}\n",
            "Progress: 68/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:52:33] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:52:33] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:52:33] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:52:33]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:52:33]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:52:33]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:52:33]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:52:33]   CPU count: 8\n",
            "[codecarbon INFO @ 00:52:33]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:52:33]   GPU count: 1\n",
            "[codecarbon INFO @ 00:52:33]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6692159175872803, 'eval_accuracy': 0.6323529411764706, 'eval_f1': 0.7440273037542662, 'eval_runtime': 0.6783, 'eval_samples_per_second': 601.544, 'eval_steps_per_second': 38.334, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6392573118209839, 'eval_accuracy': 0.6740196078431373, 'eval_f1': 0.7975646879756468, 'eval_runtime': 0.6668, 'eval_samples_per_second': 611.848, 'eval_steps_per_second': 38.99, 'epoch': 2.0}\n",
            "{'loss': 0.6764, 'grad_norm': 1.692399263381958, 'learning_rate': 1.3695652173913042e-05, 'epoch': 2.1739130434782608}\n",
            "{'eval_loss': 0.6317211985588074, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8072289156626506, 'eval_runtime': 0.6749, 'eval_samples_per_second': 604.498, 'eval_steps_per_second': 38.522, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:52:46] Energy consumed for RAM : 0.000069 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:52:46] Energy consumed for all GPUs : 0.000124 kWh. Total GPU Power : 34.11194450688526 W\n",
            "[codecarbon INFO @ 00:52:46] Energy consumed for all CPUs : 0.000154 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:52:46] 0.000347 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6300677061080933, 'eval_accuracy': 0.6813725490196079, 'eval_f1': 0.8048048048048048, 'eval_runtime': 0.7118, 'eval_samples_per_second': 573.2, 'eval_steps_per_second': 36.527, 'epoch': 4.0}\n",
            "{'train_runtime': 12.6734, 'train_samples_per_second': 1157.699, 'train_steps_per_second': 72.593, 'train_loss': 0.6568264505137568, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:52:47] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:52:47] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:52:47] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:52:47] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:52:47] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6300677061080933, 'eval_accuracy': 0.6813725490196079, 'eval_f1': 0.8048048048048048, 'eval_runtime': 0.6597, 'eval_samples_per_second': 618.498, 'eval_steps_per_second': 39.414, 'epoch': 4.0}\n",
            "Progress: 69/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:52:48] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:52:48] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:52:48] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:52:48]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:52:48]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:52:48]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:52:48]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:52:48]   CPU count: 8\n",
            "[codecarbon INFO @ 00:52:48]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:52:48]   GPU count: 1\n",
            "[codecarbon INFO @ 00:52:48]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6195806860923767, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8088888888888889, 'eval_runtime': 0.6238, 'eval_samples_per_second': 654.101, 'eval_steps_per_second': 20.841, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6146361827850342, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8131539611360239, 'eval_runtime': 0.6133, 'eval_samples_per_second': 665.248, 'eval_steps_per_second': 21.197, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6122263669967651, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8131539611360239, 'eval_runtime': 0.627, 'eval_samples_per_second': 650.699, 'eval_steps_per_second': 20.733, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:52:57] Energy consumed for RAM : 0.000049 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:52:57] Energy consumed for all GPUs : 0.000091 kWh. Total GPU Power : 35.66890423211038 W\n",
            "[codecarbon INFO @ 00:52:57] Energy consumed for all CPUs : 0.000108 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:52:57] 0.000248 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6116700768470764, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8131539611360239, 'eval_runtime': 0.6285, 'eval_samples_per_second': 649.142, 'eval_steps_per_second': 20.683, 'epoch': 4.0}\n",
            "{'train_runtime': 8.7932, 'train_samples_per_second': 1668.564, 'train_steps_per_second': 52.313, 'train_loss': 0.6209388401197351, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:52:58] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:52:58] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:52:58] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:52:58] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:52:58] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6116700768470764, 'eval_accuracy': 0.6936274509803921, 'eval_f1': 0.8131539611360239, 'eval_runtime': 0.6342, 'eval_samples_per_second': 643.297, 'eval_steps_per_second': 20.497, 'epoch': 4.0}\n",
            "Progress: 70/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:52:59] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:52:59] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:52:59] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:52:59]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:52:59]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:52:59]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:52:59]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:52:59]   CPU count: 8\n",
            "[codecarbon INFO @ 00:52:59]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:52:59]   GPU count: 1\n",
            "[codecarbon INFO @ 00:52:59]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6302370429039001, 'eval_accuracy': 0.6764705882352942, 'eval_f1': 0.8023952095808383, 'eval_runtime': 0.6266, 'eval_samples_per_second': 651.136, 'eval_steps_per_second': 20.747, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6229985356330872, 'eval_accuracy': 0.6813725490196079, 'eval_f1': 0.8071216617210683, 'eval_runtime': 0.6326, 'eval_samples_per_second': 644.936, 'eval_steps_per_second': 20.549, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6220377683639526, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8083209509658247, 'eval_runtime': 0.655, 'eval_samples_per_second': 622.935, 'eval_steps_per_second': 19.848, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:53:08] Energy consumed for RAM : 0.000050 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:53:08] Energy consumed for all GPUs : 0.000093 kWh. Total GPU Power : 35.7360392984688 W\n",
            "[codecarbon INFO @ 00:53:08] Energy consumed for all CPUs : 0.000110 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:53:08] 0.000253 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.621662437915802, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8083209509658247, 'eval_runtime': 0.6309, 'eval_samples_per_second': 646.653, 'eval_steps_per_second': 20.604, 'epoch': 4.0}\n",
            "{'train_runtime': 8.9651, 'train_samples_per_second': 1636.562, 'train_steps_per_second': 51.31, 'train_loss': 0.6369611657184103, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:53:09] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:53:09] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:53:09] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:53:09] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:53:09] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.621662437915802, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8083209509658247, 'eval_runtime': 0.6264, 'eval_samples_per_second': 651.391, 'eval_steps_per_second': 20.755, 'epoch': 4.0}\n",
            "Progress: 71/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:53:10] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:53:10] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:53:10] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:53:10]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:53:10]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:53:10]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:53:10]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:53:10]   CPU count: 8\n",
            "[codecarbon INFO @ 00:53:10]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:53:10]   GPU count: 1\n",
            "[codecarbon INFO @ 00:53:10]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6681362986564636, 'eval_accuracy': 0.6372549019607843, 'eval_f1': 0.75, 'eval_runtime': 0.6147, 'eval_samples_per_second': 663.731, 'eval_steps_per_second': 21.148, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6364061236381531, 'eval_accuracy': 0.6813725490196079, 'eval_f1': 0.803030303030303, 'eval_runtime': 0.6269, 'eval_samples_per_second': 650.799, 'eval_steps_per_second': 20.736, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6300840973854065, 'eval_accuracy': 0.678921568627451, 'eval_f1': 0.8035982008995503, 'eval_runtime': 0.6237, 'eval_samples_per_second': 654.194, 'eval_steps_per_second': 20.844, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:53:19] Energy consumed for RAM : 0.000049 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:53:19] Energy consumed for all GPUs : 0.000091 kWh. Total GPU Power : 35.47412611174285 W\n",
            "[codecarbon INFO @ 00:53:19] Energy consumed for all CPUs : 0.000109 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:53:19] 0.000249 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6289051175117493, 'eval_accuracy': 0.6740196078431373, 'eval_f1': 0.8011958146487295, 'eval_runtime': 0.6266, 'eval_samples_per_second': 651.108, 'eval_steps_per_second': 20.746, 'epoch': 4.0}\n",
            "{'train_runtime': 8.841, 'train_samples_per_second': 1659.549, 'train_steps_per_second': 52.031, 'train_loss': 0.656402587890625, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:53:20] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:53:20] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:53:20] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:53:20] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:53:20] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6289051175117493, 'eval_accuracy': 0.6740196078431373, 'eval_f1': 0.8011958146487295, 'eval_runtime': 0.6397, 'eval_samples_per_second': 637.771, 'eval_steps_per_second': 20.321, 'epoch': 4.0}\n",
            "Progress: 72/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:53:21] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:53:21] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:53:21] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:53:21]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:53:21]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:53:21]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:53:21]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:53:21]   CPU count: 8\n",
            "[codecarbon INFO @ 00:53:21]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:53:21]   GPU count: 1\n",
            "[codecarbon INFO @ 00:53:21]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7016777992248535, 'eval_accuracy': 0.4387254901960784, 'eval_f1': 0.42317380352644834, 'eval_runtime': 0.644, 'eval_samples_per_second': 633.545, 'eval_steps_per_second': 20.186, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6666895747184753, 'eval_accuracy': 0.6446078431372549, 'eval_f1': 0.7571189279731994, 'eval_runtime': 0.6478, 'eval_samples_per_second': 629.832, 'eval_steps_per_second': 20.068, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6520344614982605, 'eval_accuracy': 0.6642156862745098, 'eval_f1': 0.7849293563579278, 'eval_runtime': 0.6127, 'eval_samples_per_second': 665.952, 'eval_steps_per_second': 21.219, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:53:31] Energy consumed for RAM : 0.000049 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:53:31] Energy consumed for all GPUs : 0.000092 kWh. Total GPU Power : 35.768409813529466 W\n",
            "[codecarbon INFO @ 00:53:31] Energy consumed for all CPUs : 0.000109 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:53:31] 0.000250 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6481372117996216, 'eval_accuracy': 0.6764705882352942, 'eval_f1': 0.7956656346749226, 'eval_runtime': 0.635, 'eval_samples_per_second': 642.54, 'eval_steps_per_second': 20.473, 'epoch': 4.0}\n",
            "{'train_runtime': 8.8668, 'train_samples_per_second': 1654.703, 'train_steps_per_second': 51.879, 'train_loss': 0.6802549279254416, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:53:31] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:53:31] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:53:31] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:53:31] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:53:31] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6481372117996216, 'eval_accuracy': 0.6764705882352942, 'eval_f1': 0.7956656346749226, 'eval_runtime': 0.6602, 'eval_samples_per_second': 618.008, 'eval_steps_per_second': 19.691, 'epoch': 4.0}\n",
            "Progress: 73/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:53:32] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:53:32] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:53:32] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:53:32]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:53:32]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:53:32]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:53:32]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:53:32]   CPU count: 8\n",
            "[codecarbon INFO @ 00:53:32]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:53:32]   GPU count: 1\n",
            "[codecarbon INFO @ 00:53:32]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6219944953918457, 'eval_accuracy': 0.6862745098039216, 'eval_f1': 0.8117647058823529, 'eval_runtime': 0.6111, 'eval_samples_per_second': 667.614, 'eval_steps_per_second': 11.454, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6164452433586121, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8112927191679049, 'eval_runtime': 0.6095, 'eval_samples_per_second': 669.439, 'eval_steps_per_second': 11.485, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6156122088432312, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8112927191679049, 'eval_runtime': 0.5966, 'eval_samples_per_second': 683.825, 'eval_steps_per_second': 11.732, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:53:40] Energy consumed for RAM : 0.000039 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:53:40] Energy consumed for all GPUs : 0.000080 kWh. Total GPU Power : 38.7830550377466 W\n",
            "[codecarbon INFO @ 00:53:40] Energy consumed for all CPUs : 0.000087 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:53:40] 0.000206 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.614994466304779, 'eval_accuracy': 0.6911764705882353, 'eval_f1': 0.8125, 'eval_runtime': 0.6426, 'eval_samples_per_second': 634.878, 'eval_steps_per_second': 10.893, 'epoch': 4.0}\n",
            "{'train_runtime': 7.0092, 'train_samples_per_second': 2093.261, 'train_steps_per_second': 33.1, 'train_loss': 0.6275649235166353, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:53:41] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:53:41] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:53:41] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:53:41] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:53:41] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.614994466304779, 'eval_accuracy': 0.6911764705882353, 'eval_f1': 0.8125, 'eval_runtime': 0.5949, 'eval_samples_per_second': 685.859, 'eval_steps_per_second': 11.767, 'epoch': 4.0}\n",
            "Progress: 74/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:53:42] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:53:42] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:53:42] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:53:42]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:53:42]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:53:42]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:53:42]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:53:42]   CPU count: 8\n",
            "[codecarbon INFO @ 00:53:42]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:53:42]   GPU count: 1\n",
            "[codecarbon INFO @ 00:53:42]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.661069929599762, 'eval_accuracy': 0.6593137254901961, 'eval_f1': 0.7732463295269169, 'eval_runtime': 0.6561, 'eval_samples_per_second': 621.813, 'eval_steps_per_second': 10.668, 'epoch': 1.0}\n",
            "{'eval_loss': 0.630786657333374, 'eval_accuracy': 0.678921568627451, 'eval_f1': 0.8035982008995503, 'eval_runtime': 0.6014, 'eval_samples_per_second': 678.453, 'eval_steps_per_second': 11.64, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6263507604598999, 'eval_accuracy': 0.6813725490196079, 'eval_f1': 0.8071216617210683, 'eval_runtime': 0.6057, 'eval_samples_per_second': 673.565, 'eval_steps_per_second': 11.556, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:53:49] Energy consumed for RAM : 0.000039 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:53:49] Energy consumed for all GPUs : 0.000080 kWh. Total GPU Power : 38.77010390437323 W\n",
            "[codecarbon INFO @ 00:53:49] Energy consumed for all CPUs : 0.000087 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:53:49] 0.000206 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.625779926776886, 'eval_accuracy': 0.6813725490196079, 'eval_f1': 0.8071216617210683, 'eval_runtime': 0.6198, 'eval_samples_per_second': 658.266, 'eval_steps_per_second': 11.294, 'epoch': 4.0}\n",
            "{'train_runtime': 7.0132, 'train_samples_per_second': 2092.044, 'train_steps_per_second': 33.08, 'train_loss': 0.6516202729323815, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:53:50] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:53:50] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:53:50] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:53:50] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:53:50] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.625779926776886, 'eval_accuracy': 0.6813725490196079, 'eval_f1': 0.8071216617210683, 'eval_runtime': 0.6061, 'eval_samples_per_second': 673.131, 'eval_steps_per_second': 11.549, 'epoch': 4.0}\n",
            "Progress: 75/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:53:51] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:53:51] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:53:51] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:53:51]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:53:51]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:53:51]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:53:51]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:53:51]   CPU count: 8\n",
            "[codecarbon INFO @ 00:53:51]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:53:51]   GPU count: 1\n",
            "[codecarbon INFO @ 00:53:51]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7068928480148315, 'eval_accuracy': 0.3897058823529412, 'eval_f1': 0.31024930747922436, 'eval_runtime': 0.6246, 'eval_samples_per_second': 653.187, 'eval_steps_per_second': 11.207, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6701672077178955, 'eval_accuracy': 0.6274509803921569, 'eval_f1': 0.738831615120275, 'eval_runtime': 0.63, 'eval_samples_per_second': 647.654, 'eval_steps_per_second': 11.112, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6536798477172852, 'eval_accuracy': 0.6642156862745098, 'eval_f1': 0.7828843106180665, 'eval_runtime': 0.63, 'eval_samples_per_second': 647.637, 'eval_steps_per_second': 11.111, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:53:59] Energy consumed for RAM : 0.000040 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:53:59] Energy consumed for all GPUs : 0.000079 kWh. Total GPU Power : 37.99320546327209 W\n",
            "[codecarbon INFO @ 00:53:59] Energy consumed for all CPUs : 0.000088 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:53:59] 0.000207 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6493740677833557, 'eval_accuracy': 0.6764705882352942, 'eval_f1': 0.794392523364486, 'eval_runtime': 0.5971, 'eval_samples_per_second': 683.28, 'eval_steps_per_second': 11.723, 'epoch': 4.0}\n",
            "{'train_runtime': 7.089, 'train_samples_per_second': 2069.68, 'train_steps_per_second': 32.727, 'train_loss': 0.6826194237018454, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:53:59] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:53:59] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:53:59] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:53:59] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:53:59] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6493740677833557, 'eval_accuracy': 0.6764705882352942, 'eval_f1': 0.794392523364486, 'eval_runtime': 0.5893, 'eval_samples_per_second': 692.356, 'eval_steps_per_second': 11.879, 'epoch': 4.0}\n",
            "Progress: 76/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:54:00] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:54:00] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:54:00] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:54:00]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:54:00]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:54:00]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:54:00]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:54:00]   CPU count: 8\n",
            "[codecarbon INFO @ 00:54:00]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:54:00]   GPU count: 1\n",
            "[codecarbon INFO @ 00:54:00]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.7269788980484009, 'eval_accuracy': 0.3161764705882353, 'eval_f1': 0.014134275618374558, 'eval_runtime': 0.6172, 'eval_samples_per_second': 661.004, 'eval_steps_per_second': 11.341, 'epoch': 1.0}\n",
            "{'eval_loss': 0.7038365602493286, 'eval_accuracy': 0.4117647058823529, 'eval_f1': 0.36507936507936506, 'eval_runtime': 0.6077, 'eval_samples_per_second': 671.403, 'eval_steps_per_second': 11.519, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6900749802589417, 'eval_accuracy': 0.5318627450980392, 'eval_f1': 0.6061855670103092, 'eval_runtime': 0.5978, 'eval_samples_per_second': 682.467, 'eval_steps_per_second': 11.709, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:54:08] Energy consumed for RAM : 0.000040 kWh. RAM Power : 19.122615337371826 W\n",
            "[codecarbon INFO @ 00:54:08] Energy consumed for all GPUs : 0.000079 kWh. Total GPU Power : 38.05151167735616 W\n",
            "[codecarbon INFO @ 00:54:08] Energy consumed for all CPUs : 0.000088 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 00:54:08] 0.000206 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6855593919754028, 'eval_accuracy': 0.5759803921568627, 'eval_f1': 0.6587771203155819, 'eval_runtime': 0.6235, 'eval_samples_per_second': 654.386, 'eval_steps_per_second': 11.227, 'epoch': 4.0}\n",
            "{'train_runtime': 7.0668, 'train_samples_per_second': 2076.191, 'train_steps_per_second': 32.83, 'train_loss': 0.7082098599137931, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 00:54:09] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 00:54:09] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 00:54:09] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 00:54:09] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 00:54:09] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6855593919754028, 'eval_accuracy': 0.5759803921568627, 'eval_f1': 0.6587771203155819, 'eval_runtime': 0.6245, 'eval_samples_per_second': 653.281, 'eval_steps_per_second': 11.208, 'epoch': 4.0}\n",
            "Progress: 77/2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 00:54:10] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 00:54:10] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:54:10] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 00:54:10]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 00:54:10]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 00:54:10]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 00:54:10]   Available RAM : 50.994 GB\n",
            "[codecarbon INFO @ 00:54:10]   CPU count: 8\n",
            "[codecarbon INFO @ 00:54:10]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 00:54:10]   GPU count: 1\n",
            "[codecarbon INFO @ 00:54:10]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.6343888640403748, 'eval_accuracy': 0.678921568627451, 'eval_f1': 0.8035982008995503, 'eval_runtime': 0.5949, 'eval_samples_per_second': 685.809, 'eval_steps_per_second': 6.724, 'epoch': 1.0}\n",
            "{'eval_loss': 0.6240852475166321, 'eval_accuracy': 0.6887254901960784, 'eval_f1': 0.8135095447870778, 'eval_runtime': 0.593, 'eval_samples_per_second': 688.009, 'eval_steps_per_second': 6.745, 'epoch': 2.0}\n",
            "{'eval_loss': 0.6218690276145935, 'eval_accuracy': 0.6838235294117647, 'eval_f1': 0.8100147275405007, 'eval_runtime': 0.6113, 'eval_samples_per_second': 667.44, 'eval_steps_per_second': 6.544, 'epoch': 3.0}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMK0dIkt6OQAfKsX7rNImuW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "804b53b329504efeb233589079c2ed65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_396b380cfdf94988ade70dbff20cf1d5",
              "IPY_MODEL_94b4fba6eb90479fb4312afad8bde284",
              "IPY_MODEL_04a00fc856934552afbbd3139d5169d0"
            ],
            "layout": "IPY_MODEL_1d25ea923d8c4b719b81fc6eea74a0d1"
          }
        },
        "396b380cfdf94988ade70dbff20cf1d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f789c228671340ae93054f5ff479d311",
            "placeholder": "",
            "style": "IPY_MODEL_2ef9c6682df149dba78844ff1016c7de",
            "value": "README.md:100%"
          }
        },
        "94b4fba6eb90479fb4312afad8bde284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f69f6f89237941f389552123d2803206",
            "max": 35296,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aac4fce82f6143299899757cba7ae048",
            "value": 35296
          }
        },
        "04a00fc856934552afbbd3139d5169d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69eb831fc04345fd835e8ed7836a1286",
            "placeholder": "",
            "style": "IPY_MODEL_f86a1a083f54444aa3d62a091d6c4e2b",
            "value": "35.3k/35.3k[00:00&lt;00:00,2.72MB/s]"
          }
        },
        "1d25ea923d8c4b719b81fc6eea74a0d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f789c228671340ae93054f5ff479d311": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ef9c6682df149dba78844ff1016c7de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f69f6f89237941f389552123d2803206": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aac4fce82f6143299899757cba7ae048": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69eb831fc04345fd835e8ed7836a1286": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f86a1a083f54444aa3d62a091d6c4e2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1825bf597b4407d895dc24f59fc7fbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca30609b4aee40a282cb76b71049b073",
              "IPY_MODEL_8a07bde9e50b40378e0fb9e3cd598641",
              "IPY_MODEL_01843e15de8846fab8639cd670da3013"
            ],
            "layout": "IPY_MODEL_ff269a6b3e544b618f491c096eee1880"
          }
        },
        "ca30609b4aee40a282cb76b71049b073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f14de9da40fd40d69f6b436f9331c206",
            "placeholder": "",
            "style": "IPY_MODEL_e5cc459b69be4ea6a8e7097981a9925a",
            "value": "train-00000-of-00001.parquet:100%"
          }
        },
        "8a07bde9e50b40378e0fb9e3cd598641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1333795e33d4803af634f1b4da13a3f",
            "max": 649281,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed4068ab1e894bc3a323d4fe62e9fdcb",
            "value": 649281
          }
        },
        "01843e15de8846fab8639cd670da3013": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db5170b092f241e5aca61256ab56fb56",
            "placeholder": "",
            "style": "IPY_MODEL_50d4d353925345f4bb7c11d6d3921ec6",
            "value": "649k/649k[00:00&lt;00:00,18.8MB/s]"
          }
        },
        "ff269a6b3e544b618f491c096eee1880": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f14de9da40fd40d69f6b436f9331c206": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5cc459b69be4ea6a8e7097981a9925a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1333795e33d4803af634f1b4da13a3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed4068ab1e894bc3a323d4fe62e9fdcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db5170b092f241e5aca61256ab56fb56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50d4d353925345f4bb7c11d6d3921ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ecad5d0437e4617b4a4f6e08f8eb01d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d4866d2ce6e4c8bae8fb58cd6d2fd11",
              "IPY_MODEL_e162354030ad4e7ebd5a199feb8cf685",
              "IPY_MODEL_9c6217d4e1e14fca9cd85c9162af4c65"
            ],
            "layout": "IPY_MODEL_df51cf89f5ef401ab93c10806181ddbf"
          }
        },
        "2d4866d2ce6e4c8bae8fb58cd6d2fd11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_768ad98eb23e4a4e989d89bc88c52040",
            "placeholder": "",
            "style": "IPY_MODEL_2d3850717de64656bef125069a06bece",
            "value": "validation-00000-of-00001.parquet:100%"
          }
        },
        "e162354030ad4e7ebd5a199feb8cf685": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d791c475485c4da8b082b231e46e20aa",
            "max": 75678,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d90985ba6594c28b56d9aed37f2e2cf",
            "value": 75678
          }
        },
        "9c6217d4e1e14fca9cd85c9162af4c65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9bfa850e825499aa89ebb8ed2558cf2",
            "placeholder": "",
            "style": "IPY_MODEL_d64ad46a4c984ffc876534688ea19f17",
            "value": "75.7k/75.7k[00:00&lt;00:00,5.49MB/s]"
          }
        },
        "df51cf89f5ef401ab93c10806181ddbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "768ad98eb23e4a4e989d89bc88c52040": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d3850717de64656bef125069a06bece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d791c475485c4da8b082b231e46e20aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d90985ba6594c28b56d9aed37f2e2cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b9bfa850e825499aa89ebb8ed2558cf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d64ad46a4c984ffc876534688ea19f17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4fe003aecb914f118eff0d26fecb8262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f69b5b6ab3b74036b444fb700b69d1e8",
              "IPY_MODEL_7496dd11e92b4ec79759f087fb19b5c3",
              "IPY_MODEL_0eb27a7e21bf46fbb065c81e7555c227"
            ],
            "layout": "IPY_MODEL_6bf17e9300784020b362a1cf54b1230b"
          }
        },
        "f69b5b6ab3b74036b444fb700b69d1e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_026cd300f50a4016929e1c343c475fd4",
            "placeholder": "",
            "style": "IPY_MODEL_d6597f21cfe14788b3dc4ed469f9343b",
            "value": "test-00000-of-00001.parquet:100%"
          }
        },
        "7496dd11e92b4ec79759f087fb19b5c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b41f230e5664c38a6be6121abfecd07",
            "max": 308441,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_598bf45ca0014737babe10f57145e36b",
            "value": 308441
          }
        },
        "0eb27a7e21bf46fbb065c81e7555c227": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_537fd778509c40259ad7045ab5e87b2a",
            "placeholder": "",
            "style": "IPY_MODEL_6911a1f9c0d54420a4837024ab90cd59",
            "value": "308k/308k[00:00&lt;00:00,21.5MB/s]"
          }
        },
        "6bf17e9300784020b362a1cf54b1230b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "026cd300f50a4016929e1c343c475fd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6597f21cfe14788b3dc4ed469f9343b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b41f230e5664c38a6be6121abfecd07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "598bf45ca0014737babe10f57145e36b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "537fd778509c40259ad7045ab5e87b2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6911a1f9c0d54420a4837024ab90cd59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce1701d92fd745889ba20dd483573658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98e559bf85c94659b8367ec5f02ff12d",
              "IPY_MODEL_ca6df7952f2941c0b66d6897b94cc905",
              "IPY_MODEL_56e6d95353cd471db726fde6b7b00763"
            ],
            "layout": "IPY_MODEL_87657695861a42e99587444803e38366"
          }
        },
        "98e559bf85c94659b8367ec5f02ff12d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f19c764a6414475a67bf8421e26e56e",
            "placeholder": "",
            "style": "IPY_MODEL_f74df151926d4bfab855628b27bf70aa",
            "value": "Generatingtrainsplit:100%"
          }
        },
        "ca6df7952f2941c0b66d6897b94cc905": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ee46b807c7f4626be081655b1540d33",
            "max": 3668,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d2eaf63de034e149cbdadc733a58549",
            "value": 3668
          }
        },
        "56e6d95353cd471db726fde6b7b00763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93f011392d4a41579de29f2990ed35b4",
            "placeholder": "",
            "style": "IPY_MODEL_b5b63d09e98b44bda64484ea4832a59f",
            "value": "3668/3668[00:00&lt;00:00,72804.27examples/s]"
          }
        },
        "87657695861a42e99587444803e38366": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f19c764a6414475a67bf8421e26e56e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f74df151926d4bfab855628b27bf70aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ee46b807c7f4626be081655b1540d33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d2eaf63de034e149cbdadc733a58549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "93f011392d4a41579de29f2990ed35b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5b63d09e98b44bda64484ea4832a59f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37df508495df4ece897ee3cd9ce3118a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69f4753709a14ff7be835d120655ae1d",
              "IPY_MODEL_2c58876d7e7344c48576e0268b69110f",
              "IPY_MODEL_770aa953df094b17a05714b3aa6eb20f"
            ],
            "layout": "IPY_MODEL_1d9d273598f6484ebff3e0df00a79c12"
          }
        },
        "69f4753709a14ff7be835d120655ae1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da7fb36a79904acba29e2de9a1e0a1b1",
            "placeholder": "",
            "style": "IPY_MODEL_5c5b35d007bb46e7826a19bba3fbd055",
            "value": "Generatingvalidationsplit:100%"
          }
        },
        "2c58876d7e7344c48576e0268b69110f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_482881cc049a4c10ac5ea63565a382c0",
            "max": 408,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_edaf269847d54972a49ce50a95c107fa",
            "value": 408
          }
        },
        "770aa953df094b17a05714b3aa6eb20f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eaa012f0012b4e8a822ea78d30e95b1d",
            "placeholder": "",
            "style": "IPY_MODEL_ef49c17c008d43faa275b3e67d1c9281",
            "value": "408/408[00:00&lt;00:00,22942.12examples/s]"
          }
        },
        "1d9d273598f6484ebff3e0df00a79c12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da7fb36a79904acba29e2de9a1e0a1b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c5b35d007bb46e7826a19bba3fbd055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "482881cc049a4c10ac5ea63565a382c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edaf269847d54972a49ce50a95c107fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eaa012f0012b4e8a822ea78d30e95b1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef49c17c008d43faa275b3e67d1c9281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "292f94028c2b4d7b91d783a76aa159dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04d6884f9e8a4a75bd69ff808099e4f8",
              "IPY_MODEL_a0c1d06cf4b141df99cc211e244cbb39",
              "IPY_MODEL_9e02431a63bb4b10a7207198c5ed0174"
            ],
            "layout": "IPY_MODEL_43e10977bf1744f5a0ce43c24b906c56"
          }
        },
        "04d6884f9e8a4a75bd69ff808099e4f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_728ab324b19a4c73ae5808ff8e8ea2e8",
            "placeholder": "",
            "style": "IPY_MODEL_38e2a9fb3dc04b6e8caaa7c9a5eddd83",
            "value": "Generatingtestsplit:100%"
          }
        },
        "a0c1d06cf4b141df99cc211e244cbb39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c93760786efc4ba99fa830aa732fb4bb",
            "max": 1725,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f30d2e02f9af4a059562d5d92da5b388",
            "value": 1725
          }
        },
        "9e02431a63bb4b10a7207198c5ed0174": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efe7214652f54bcbbd1b211251f162de",
            "placeholder": "",
            "style": "IPY_MODEL_d88b1e868f354dcc97a2402a2a69b63b",
            "value": "1725/1725[00:00&lt;00:00,89579.71examples/s]"
          }
        },
        "43e10977bf1744f5a0ce43c24b906c56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "728ab324b19a4c73ae5808ff8e8ea2e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38e2a9fb3dc04b6e8caaa7c9a5eddd83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c93760786efc4ba99fa830aa732fb4bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f30d2e02f9af4a059562d5d92da5b388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "efe7214652f54bcbbd1b211251f162de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d88b1e868f354dcc97a2402a2a69b63b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3cb3b64b68f3415ea6b22a35d309601d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e080d05948f45f29354b9cd594fa7dc",
              "IPY_MODEL_d6ccc2eca81e449493c7e0239748a1bd",
              "IPY_MODEL_9b691433dee74b53ac18961c23b28556"
            ],
            "layout": "IPY_MODEL_9005bed315264832ab0def8139a8be0d"
          }
        },
        "6e080d05948f45f29354b9cd594fa7dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_303bac65625c41b1a0299636413651c3",
            "placeholder": "",
            "style": "IPY_MODEL_76462d3f73d043bcba868389fcd34309",
            "value": "config.json:100%"
          }
        },
        "d6ccc2eca81e449493c7e0239748a1bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_096ad02ab12848409b2d330fe663ae0a",
            "max": 285,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b6bf7ab7812490badd56be4a6a85e8f",
            "value": 285
          }
        },
        "9b691433dee74b53ac18961c23b28556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77e5fd7eb0d9428591e9a85d5be13e27",
            "placeholder": "",
            "style": "IPY_MODEL_b4992a80a3974230a6819beef87f7972",
            "value": "285/285[00:00&lt;00:00,23.1kB/s]"
          }
        },
        "9005bed315264832ab0def8139a8be0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "303bac65625c41b1a0299636413651c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76462d3f73d043bcba868389fcd34309": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "096ad02ab12848409b2d330fe663ae0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b6bf7ab7812490badd56be4a6a85e8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77e5fd7eb0d9428591e9a85d5be13e27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4992a80a3974230a6819beef87f7972": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a6625e2e9c7458eb2a0e14964019233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fdf3abb5388d4a829d587f094fbfa802",
              "IPY_MODEL_0d75f0e6567549cdbeb3d4f35790b112",
              "IPY_MODEL_544623f02e354c459d75c2814ea31d46"
            ],
            "layout": "IPY_MODEL_cd6ca0f33b204bd7acfbad2de4f2aa3a"
          }
        },
        "fdf3abb5388d4a829d587f094fbfa802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f9a06c11f3e441aa967dfa3a5abe22c",
            "placeholder": "",
            "style": "IPY_MODEL_5a2f8ea1e34f439a88ef2241e450625f",
            "value": "vocab.txt:100%"
          }
        },
        "0d75f0e6567549cdbeb3d4f35790b112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4924bd18ade04843bd616daaf617704e",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d7a6f65cb84e4e508efa08397ee2a94f",
            "value": 231508
          }
        },
        "544623f02e354c459d75c2814ea31d46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afc8d9b254374df99eb6c83ad921ffd7",
            "placeholder": "",
            "style": "IPY_MODEL_186b5f028dab4350a78e5723ccf0d288",
            "value": "232k/232k[00:00&lt;00:00,14.5MB/s]"
          }
        },
        "cd6ca0f33b204bd7acfbad2de4f2aa3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f9a06c11f3e441aa967dfa3a5abe22c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a2f8ea1e34f439a88ef2241e450625f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4924bd18ade04843bd616daaf617704e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7a6f65cb84e4e508efa08397ee2a94f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "afc8d9b254374df99eb6c83ad921ffd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "186b5f028dab4350a78e5723ccf0d288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21c3933e7e9149998e7826c15cc56f7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_61f277dc7c5949089d657f8f6a4edf66",
              "IPY_MODEL_60687a4363134796829d217b31405954",
              "IPY_MODEL_5c03a916f95d47a1a927213d6797ea2a"
            ],
            "layout": "IPY_MODEL_7e43f7a554b14c69b8b85e88241baaaa"
          }
        },
        "61f277dc7c5949089d657f8f6a4edf66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_740c768fe3844738b29b8512a7c2dcd9",
            "placeholder": "",
            "style": "IPY_MODEL_39dd1c4ff4d345c6a4ef9e1f4a2f9779",
            "value": "Map:100%"
          }
        },
        "60687a4363134796829d217b31405954": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6790abc9363045b8b7a1fa9bffb9b6c5",
            "max": 3668,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13aa7b3b188c454eafd6856499454007",
            "value": 3668
          }
        },
        "5c03a916f95d47a1a927213d6797ea2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7af1cf4362ff461dba4799eac83c1b9c",
            "placeholder": "",
            "style": "IPY_MODEL_797f65625b2043f1af0ece3cc1ede67b",
            "value": "3668/3668[00:00&lt;00:00,6856.17examples/s]"
          }
        },
        "7e43f7a554b14c69b8b85e88241baaaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "740c768fe3844738b29b8512a7c2dcd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39dd1c4ff4d345c6a4ef9e1f4a2f9779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6790abc9363045b8b7a1fa9bffb9b6c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13aa7b3b188c454eafd6856499454007": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7af1cf4362ff461dba4799eac83c1b9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "797f65625b2043f1af0ece3cc1ede67b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "854d4a1a596541f188ef4056557e8ee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ee9933bd6ca4303a583e7da77b88b95",
              "IPY_MODEL_8d52ffb1a2e94bd58141f07ce05bfd95",
              "IPY_MODEL_f8bf90b227d544f2823a83a2ff6d1357"
            ],
            "layout": "IPY_MODEL_f9890775891d40a59c577b17da0d7c84"
          }
        },
        "0ee9933bd6ca4303a583e7da77b88b95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1460c3364a4940df8f47f9f4b607ca01",
            "placeholder": "",
            "style": "IPY_MODEL_f4f58d1bfb1e4a7f85e3d92f1f0d29cc",
            "value": "Map:100%"
          }
        },
        "8d52ffb1a2e94bd58141f07ce05bfd95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afc31f897bff43f3a74823c1844ff35e",
            "max": 408,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a5acd83adeb4b9eaad6cce967daf2ba",
            "value": 408
          }
        },
        "f8bf90b227d544f2823a83a2ff6d1357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f233fd208c343c19a2cbbdf2566e827",
            "placeholder": "",
            "style": "IPY_MODEL_63ebfc4053e14e27b6116a32cc994b1c",
            "value": "408/408[00:00&lt;00:00,7592.58examples/s]"
          }
        },
        "f9890775891d40a59c577b17da0d7c84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1460c3364a4940df8f47f9f4b607ca01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4f58d1bfb1e4a7f85e3d92f1f0d29cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afc31f897bff43f3a74823c1844ff35e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a5acd83adeb4b9eaad6cce967daf2ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f233fd208c343c19a2cbbdf2566e827": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63ebfc4053e14e27b6116a32cc994b1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bab4da1c3d6a41a4bb567e69ffea75e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7262b9bd0f8348bcb116ad53f8a975bf",
              "IPY_MODEL_a8fd40a1893541f88e25baccb60006b5",
              "IPY_MODEL_158fdc15fbf34667ab5acc6e866af725"
            ],
            "layout": "IPY_MODEL_9d433bec88e44d949bf1f1451060acce"
          }
        },
        "7262b9bd0f8348bcb116ad53f8a975bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c73e73c59bb444d9bdaedc30a1c645c",
            "placeholder": "",
            "style": "IPY_MODEL_0bf2aa7acd064c06a702ed625aded2fc",
            "value": "Map:100%"
          }
        },
        "a8fd40a1893541f88e25baccb60006b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_060c092e11964359a586533efcf6b7cb",
            "max": 1725,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da7a74c024d641aa94c8babdbe72bd20",
            "value": 1725
          }
        },
        "158fdc15fbf34667ab5acc6e866af725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed7a33d877ce436983622c91768e851b",
            "placeholder": "",
            "style": "IPY_MODEL_8afa01f06f43477fa3e978aaf56e162b",
            "value": "1725/1725[00:00&lt;00:00,11760.00examples/s]"
          }
        },
        "9d433bec88e44d949bf1f1451060acce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c73e73c59bb444d9bdaedc30a1c645c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bf2aa7acd064c06a702ed625aded2fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "060c092e11964359a586533efcf6b7cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da7a74c024d641aa94c8babdbe72bd20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed7a33d877ce436983622c91768e851b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8afa01f06f43477fa3e978aaf56e162b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}